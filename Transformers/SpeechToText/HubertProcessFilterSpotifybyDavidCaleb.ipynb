{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_audio_data(data_name, split=\"train[:100]\"):\n",
    "    data = load_dataset(data_name, split=split)\n",
    "    print(f\"Dataset structure: {data}\")\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the data\n",
    "# data = load_dataset(\"charris/hubert_process_filter_spotify\", split=\"train[:100]\")\n",
    "# # Check the structure dataset\n",
    "# print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select audio files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_audio(data, num_files=5):\n",
    "    audio_files = data[:num_files]['audio']\n",
    "    print(f\"Selected {num_files} audio files\")\n",
    "    return audio_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the first audio files\n",
    "# audio_files = data[:5]['audio']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the model and processor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Wav2Vec2 model and processor for speech-to-text\n",
    "def load_model_and_processor(model_name=\"facebook/wav2vec2-large-960h\"):\n",
    "    processor = Wav2Vec2Processor.from_pretrained(model_name)\n",
    "    model = Wav2Vec2ForCTC.from_pretrained(model_name)\n",
    "    print(\"Model and processor loaded\")\n",
    "    return processor, model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Audio transcription function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transcribe an audio file using the Wav2Vec2 model.\n",
    "def transcribe_audio(audio_file, processor, model):\n",
    "    # Preprocess the audio\n",
    "    input_values = processor(audio_file['array'], return_tensors=\"pt\", sampling_rate=audio_file['sampling_rate']).input_values\n",
    "    \n",
    "    # Obtain the logits from the model\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_values).logits\n",
    "    \n",
    "    # Decode the logits to text\n",
    "    predicted_ids = torch.argmax(logits, dim=-1)\n",
    "    transcription = processor.decode(predicted_ids[0])\n",
    "    \n",
    "    return transcription"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transcribe and save the selected audio files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transcribe a list of audio files.\n",
    "def transcribe_audio_files(audio_file, processor, model):\n",
    "    transcriptions = []\n",
    "    for audio_file in audio_files:\n",
    "        transcription = transcribe_audio(audio_file, processor, model)\n",
    "        transcriptions.append(transcription)\n",
    "        print(f\"Transcription: {transcription}\")\n",
    "    return transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the transcriptions to a text file\n",
    "def save_transcriptions(transcriptions, file_name=\"transcriptions.txt\"):\n",
    "    with open(\"transcriptions.txt\", \"w\") as file:\n",
    "        for i, transcription in enumerate(transcriptions):\n",
    "            file.write(f\"Audio {i+1}: {transcription}\\n\")\n",
    "        print(f\"Transcription saved to {file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset structure: Dataset({\n",
      "    features: ['audio', 'transcription', 'input_values', 'input_length', 'labels'],\n",
      "    num_rows: 100\n",
      "})\n",
      "Selected 5 audio files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-large-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and processor loaded\n",
      "Transcription: ABOUT PEOPLE HAVING A URINATE ON THEMSELVES LIKE BECAUSE THERE WAS NO SPACE I COULD ALMOST FEEL THE ILLNESS IN THE SICKNESS AND BUT I ALSO LOVE HOW IN THAT SAME THING IN THAT IMAGE SREE HE WAS LIKE MY WANCS ALL TO KNOW THAT OUR ANCESTORS DID FIGHT BACK AND HE SAID A LOT OF TIMES I HAVE PEOPLE NOT HOW MY PERNT A LIKE WHY DIDN'T OUR ANCESTORS FIGHT AND LIKE GET ANGRY ABOUT THEM HE'S LIKE NODEY DID I WANT SHE KNOW MANY PEOPLE LOST THEIR LIFE AT THIS CASTLE TRYING TO FIGHT BACK AH TO ME THAT WAS THE MOST\n",
      "Transcription: SO LONG STORY SHORT I AM JUST GOING THROUGH A VERY INTERESTING PHASE RIGHT NOW AND MY MENTAL HEALTH IS VERY INTERESTING BUT I HAVE SUCH AMAZING PEOPLE AROUND ME I HAVE SO MANY SAFE SPACES AM AND SO I'M GETTING THE HEALP THAT I NEED AND IT'S GLORIOUS BUT I'VE JUST REALIZED THAT CREATING HAS BECOME SO DIFFICULT AND WHEN I WAS YOUNGER WHEN I HAD MOMENTS WHEN MY MENTAL HEALTH WAS AM WEIGHING ME DOWN ALT WAS JUST A LOT OR IF WHEN I WAS DEPRESSED\n",
      "Transcription: I GOING TO DO AND OUT OF ALL THE COLLEGES AND UNIVERSITIES THAT I GOT ACCEPTED INTO O MY UNDERGRADUAL UNIVERSITY UNIVERSITY OF ILLINOIS WAS THE ONE OF THE FIRST ONES THAT ACCEPTED ME AND KIND OF HAD THEY STUFFED TOGETHER YOU KNOW THAT IT WAS JUST A SMOOTH TRANSITIONING PROCESS I GOT IN I GOT MY FINANCIAL LAGED LETTER I GOT YOU KNOW T WHICH JUST ALL VERY EASY PRIMARILY BECAUSE I WAS ALREADY LIVING IN SPRINGFIELD AT THE TIME\n",
      "Transcription: I GO MA HIM TO SLEEP O FOG AN OUSE FOLK AN FIND O EARLY AN JORNEY I FELL A GIVE HIK O LIKE O SPIN OFF YOU KNOW THAT YOUR HAPPY DAYS A WORL OF RITY SUR HA HA HA HA HA HA HA HAO A SPIN OF YET A R YA YE YE SO SO NO THANK YOU GO FOR A OM THINK YOU NONO SHURED US HOW TO DO IT AND TEY WER A AS BRAKING AS UP A FISHAT IM A REMERGUISE NO FATHER NO PROBLEMS THING FIND IT EVERYWHERE RIGHT OH YES ALL RIG GUISE THANK YOU GUISE'LL SINK IS\n",
      "Transcription: LISTEN TOYOM  YOU  HAN'T A POPULAR POCKHASE FOR NO REASON AT ALL YES SO MY THING IS THAT I ALWAYS SAY THIS EDITING IS YOUR BEST FRIEND I'M NOT SAYING THAT YOU NEED TO DO ONLY SHORT FOR MA AUDIO BUT I'M JUST SAYING THAT IF YOU CAN CUT OUT ALL THE YOU KNO AND SILLERY BITS THAT YOU JUST FEEL LIKE DISDISTIS DOESN'T NEED TO BE THERE THIS IS THE REAL CORPS OF WHERE THE SHOW IS AND COME UP WITH FINE STUFF LIKE TAKE ADVANTAGE OF LIKE THE MEDIUM IN WHATEVER WAY YOU CAN MI I ALWAYS FE\n",
      "Transcription saved to transcriptions.txt\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Step 1: Load the dataset\n",
    "    dataset = load_audio_data(\"charris/hubert_process_filter_spotify\", split=\"train[:100]\")\n",
    "    \n",
    "    # Step 2: Select audio files\n",
    "    audio_files = select_audio(dataset, num_files=5)\n",
    "    \n",
    "    # Step 3: Load the model and processor\n",
    "    processor, model = load_model_and_processor()\n",
    "    \n",
    "    # Step 4: Transcribe audio files\n",
    "    transcriptions = transcribe_audio_files(audio_files, processor, model)\n",
    "    \n",
    "    # Step 5: Save transcriptions to a file\n",
    "    save_transcriptions(transcriptions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
