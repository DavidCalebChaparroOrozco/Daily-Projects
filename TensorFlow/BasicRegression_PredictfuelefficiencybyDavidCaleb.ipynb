{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow==2.16.1"
      ],
      "metadata": {
        "id": "28sBNqNgGHut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing necessary libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "sns.set_style('darkgrid')\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "id": "1vf5e-MmB4qw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The Auto MPG Dataset"
      ],
      "metadata": {
        "id": "wWhUt3MsDqKb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the data\n",
        "url = 'http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data'\n",
        "column_names = ['MPG', 'Cylinders', 'Displacement', 'Horsepower', 'Weight',\n",
        "                'Acceleration', 'Model Year', 'Origin']\n",
        "\n",
        "# Load the dataset\n",
        "raw_dataset = pd.read_csv(url, names=column_names,\n",
        "                          na_values='?', comment='\\t',\n",
        "                          sep=' ', skipinitialspace=True)"
      ],
      "metadata": {
        "id": "jrW1KD3jDlZD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a copy of the dataset\n",
        "data = raw_dataset.copy()\n",
        "data.head()"
      ],
      "metadata": {
        "id": "dmycCmnZDwgz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clean the data"
      ],
      "metadata": {
        "id": "JL2pGkA7D1Lr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the unknowns values\n",
        "data.isna().sum()"
      ],
      "metadata": {
        "id": "pU1EWIi6D2pi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop rows with missing values\n",
        "data = data.dropna()"
      ],
      "metadata": {
        "id": "eA3MCGF-D5KC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Map 'Origin' column to country names\n",
        "data['Origin'] = data['Origin'].map({1: 'USA', 2: 'Europe', 3: 'Japan'})\n",
        "data.head()"
      ],
      "metadata": {
        "id": "mfvkoIobD9cq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert categorical 'Origin' column to one-hot encoding\n",
        "data = pd.get_dummies(data, columns=['Origin'], prefix='', prefix_sep='')\n",
        "data.head()"
      ],
      "metadata": {
        "id": "7bkxS0L8EDs6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split the data into training and test sets"
      ],
      "metadata": {
        "id": "Gt4RcPEaEazR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample 80% of the data for training\n",
        "train_dataset = data.sample(frac=0.8, random_state=0)\n",
        "\n",
        "# Sample the remaining 20% for testing\n",
        "test_dataset = data.drop(train_dataset.index)"
      ],
      "metadata": {
        "id": "WafthS3JEN3i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inspect the data"
      ],
      "metadata": {
        "id": "BmYCeVI7Ek1a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create pair plots of selected features\n",
        "sns.pairplot(train_dataset[['MPG', 'Cylinders', 'Displacement', 'Weight']], diag_kind='kde')"
      ],
      "metadata": {
        "id": "aWBtbixwEklQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display summary statistics of the training dataset\n",
        "train_dataset.describe().transpose()"
      ],
      "metadata": {
        "id": "g_B1rXm6EwLf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split features from labels"
      ],
      "metadata": {
        "id": "m3XtIX1vE64o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate the 'MPG' column as labels\n",
        "train_features = train_dataset.copy()\n",
        "test_features = test_dataset.copy()\n",
        "\n",
        "train_labels = train_features.pop('MPG')\n",
        "test_labels = test_features.pop('MPG')"
      ],
      "metadata": {
        "id": "WZLNrlAmE1qI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Normalization"
      ],
      "metadata": {
        "id": "gOBeedTsE-Xv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display mean and standard deviation of the training dataset\n",
        "train_dataset.describe().transpose()[['mean', 'std']]"
      ],
      "metadata": {
        "id": "7x-T_ihZE9LA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The Normalization layer"
      ],
      "metadata": {
        "id": "LY3fZ-7wFEA_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a normalization layer\n",
        "normalizer = tf.keras.layers.Normalization(axis=-1)"
      ],
      "metadata": {
        "id": "ttxTczoxFGdA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adapt the normalizer to the training features\n",
        "normalizer.adapt(np.array(train_features))"
      ],
      "metadata": {
        "id": "mDYw7UIHFK22"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the mean values after normalization\n",
        "print(normalizer.mean.numpy())"
      ],
      "metadata": {
        "id": "dHdOaWXyF28W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example of the first row before and after normalization\n",
        "first = np.array(train_features[:1])\n",
        "\n",
        "with np.printoptions(precision=2, suppress=True):\n",
        "  print('First example:', first)\n",
        "  print()\n",
        "  print('Normalized:', normalizer(first).numpy())"
      ],
      "metadata": {
        "id": "xSnCAXyAGu08"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Linear regression"
      ],
      "metadata": {
        "id": "aN5y-X2aG1IS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract 'Horsepower' column as numpy array\n",
        "horsepower = np.array(train_features['Horsepower'])\n",
        "\n",
        "# Create a normalization layer for \"Horsepower\"\n",
        "horsepower_normalizer = layers.Normalization(input_shape=[1,], axis=None)\n",
        "horsepower_normalizer.adapt(horsepower)"
      ],
      "metadata": {
        "id": "hebM3J3gG3Zi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build a linear regression model for \"Horsepower\"\n",
        "horsepower_model = tf.keras.Sequential([\n",
        "    horsepower_normalizer,\n",
        "    layers.Dense(units=1)\n",
        "])\n",
        "\n",
        "# Display model summary\n",
        "horsepower_model.summary()"
      ],
      "metadata": {
        "id": "z3fwVLNiG69S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict the first 10 values of 'Horsepower'\n",
        "horsepower_model.predict(horsepower[:10])"
      ],
      "metadata": {
        "id": "3WK0C4-dG_Bb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model with Adam optimizer and mean absolute error loss\n",
        "horsepower_model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.1),\n",
        "    loss='mean_absolute_error')"
      ],
      "metadata": {
        "id": "NODsty6KHBi0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "history = horsepower_model.fit(\n",
        "    train_features['Horsepower'],\n",
        "    train_labels,\n",
        "    epochs=100,\n",
        "    # Suppress logging.\n",
        "    verbose=0,\n",
        "    # Calculate validation results on 20% of the training data.\n",
        "    validation_split = 0.2)"
      ],
      "metadata": {
        "id": "H_heKqrBHDW6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert training history to DataFrame and display the last few rows\n",
        "hist = pd.DataFrame(history.history)\n",
        "hist['epoch'] = history.epoch\n",
        "hist.tail()"
      ],
      "metadata": {
        "id": "-SyDUN5rHGwx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to plot training loss\n",
        "def plot_loss(history):\n",
        "  plt.plot(history.history['loss'], label='loss')\n",
        "  plt.plot(history.history['val_loss'], label='val_loss')\n",
        "  plt.ylim([0, 10])\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Error [MPG]')\n",
        "  plt.legend()\n",
        "  plt.grid(True)"
      ],
      "metadata": {
        "id": "kGeYCv_3HKDx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_loss(history)"
      ],
      "metadata": {
        "id": "8IOCehiFHL-j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test set\n",
        "test_results = {}\n",
        "\n",
        "test_results['horsepower_model'] = horsepower_model.evaluate(\n",
        "    test_features['Horsepower'],\n",
        "    test_labels, verbose=0)"
      ],
      "metadata": {
        "id": "zm6VJjP-HOkB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate predictions for a range of 'Horsepower' values\n",
        "x = tf.linspace(0.0, 250, 251)\n",
        "y = horsepower_model.predict(x)"
      ],
      "metadata": {
        "id": "obd5yKKXHRFZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to plot 'Horsepower' vs 'MPG' predictions\n",
        "def plot_horsepower(x, y):\n",
        "  plt.scatter(train_features['Horsepower'], train_labels, label='Data')\n",
        "  plt.plot(x, y, color='k', label='Predictions')\n",
        "  plt.xlabel('Horsepower')\n",
        "  plt.ylabel('MPG')\n",
        "  plt.legend()"
      ],
      "metadata": {
        "id": "LeSLJ1icHVBp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_horsepower(x, y)"
      ],
      "metadata": {
        "id": "VlmA7KIeHYxJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Linear regression with multiple inputs"
      ],
      "metadata": {
        "id": "rBGLFn48Hbix"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build a linear regression model with multiple inputs\n",
        "linear_model = tf.keras.Sequential([\n",
        "    normalizer,\n",
        "    layers.Dense(units=1)\n",
        "])"
      ],
      "metadata": {
        "id": "Ex6nEZTMHg84"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict the first 10 examples\n",
        "linear_model.predict(train_features[:10])"
      ],
      "metadata": {
        "id": "D6CoU0EiHiq5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the kernel (weights) of the dense layer\n",
        "linear_model.layers[1].kernel"
      ],
      "metadata": {
        "id": "kPmO8f_CHnsI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "linear_model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.1),\n",
        "    loss='mean_absolute_error')"
      ],
      "metadata": {
        "id": "_DBN5ZJ-Hp2Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "history = linear_model.fit(\n",
        "    train_features,\n",
        "    train_labels,\n",
        "    epochs=100,\n",
        "    # Suppress logging.\n",
        "    verbose=0,\n",
        "    # Calculate validation results on 20% of the training data.\n",
        "    validation_split = 0.2)"
      ],
      "metadata": {
        "id": "7JIrp3oCHsyQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training loss\n",
        "plot_loss(history)"
      ],
      "metadata": {
        "id": "IVOgSw7jHu-o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test set\n",
        "test_results['linear_model'] = linear_model.evaluate(\n",
        "    test_features, test_labels, verbose=0)"
      ],
      "metadata": {
        "id": "df5YCAoDHyLS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Regression with a deep neural network (DNN)"
      ],
      "metadata": {
        "id": "LLasRpWOH0iv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to build and compile a DNN model\n",
        "def build_and_compile_model(norm):\n",
        "  model = keras.Sequential([\n",
        "      norm,\n",
        "      layers.Dense(64, activation='relu'),\n",
        "      layers.Dense(64, activation='relu'),\n",
        "      layers.Dense(1)\n",
        "  ])\n",
        "\n",
        "  model.compile(loss='mean_absolute_error',\n",
        "                optimizer=tf.keras.optimizers.Adam(0.001))\n",
        "  return model"
      ],
      "metadata": {
        "id": "tmgswxy9H243"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Regression using a DNN and a single input"
      ],
      "metadata": {
        "id": "y_0cJeleORYX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build and compile a DNN model for 'Horsepower'\n",
        "dnn_horsepower_model = build_and_compile_model(horsepower_normalizer)"
      ],
      "metadata": {
        "id": "WE6BQ-s4H45n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display model summary\n",
        "dnn_horsepower_model.summary()"
      ],
      "metadata": {
        "id": "6bKRE3guH62f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "history = dnn_horsepower_model.fit(\n",
        "    train_features['Horsepower'],\n",
        "    train_labels,\n",
        "    validation_split=0.2,\n",
        "    verbose=0, epochs=100)"
      ],
      "metadata": {
        "id": "5yIYd1UYH9vH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training loss\n",
        "plot_loss(history)"
      ],
      "metadata": {
        "id": "68hMOLqMH_Cf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate predictions for a range of 'Horsepower' values\n",
        "x = tf.linspace(0.0, 250, 251)\n",
        "y = dnn_horsepower_model.predict(x)"
      ],
      "metadata": {
        "id": "wnBUXT01IDGH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot 'Horsepower' vs 'MPG' predictions\n",
        "plot_horsepower(x, y)"
      ],
      "metadata": {
        "id": "VqPV8_t7IG5H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test set\n",
        "test_results['dnn_horsepower_model'] = dnn_horsepower_model.evaluate(\n",
        "    test_features['Horsepower'], test_labels,\n",
        "    verbose=0)"
      ],
      "metadata": {
        "id": "uot5PF3NIJDW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Regression using a DNN and multiple inputs"
      ],
      "metadata": {
        "id": "22-5dXZtIKwe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build and compile a DNN model with multiple inputs\n",
        "dnn_model = build_and_compile_model(normalizer)\n",
        "dnn_model.summary()"
      ],
      "metadata": {
        "id": "iC0oz5zIINxO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "history = dnn_model.fit(\n",
        "    train_features,\n",
        "    train_labels,\n",
        "    validation_split=0.2,\n",
        "    verbose=0, epochs=100)"
      ],
      "metadata": {
        "id": "FaVxUqvfISvv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training loss\n",
        "plot_loss(history)"
      ],
      "metadata": {
        "id": "NOqhzx_VIU5O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test set\n",
        "test_results['dnn_model'] = dnn_model.evaluate(test_features, test_labels, verbose=0)"
      ],
      "metadata": {
        "id": "lgAviv6_OqDP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Performance"
      ],
      "metadata": {
        "id": "FjvLZKYlIZaf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the test results as a DataFrame\n",
        "pd.DataFrame(test_results, index=['Mean absolute error [MPG]']).T"
      ],
      "metadata": {
        "id": "GX6VqNyCIYB4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Make predictions"
      ],
      "metadata": {
        "id": "YdDkVWC_IkbX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict MPG values for the test set\n",
        "test_predictions = dnn_model.predict(test_features).flatten()\n",
        "\n",
        "# Plot true vs predicted MPG values\n",
        "a = plt.axes(aspect='equal')\n",
        "plt.scatter(test_labels, test_predictions)\n",
        "plt.xlabel('True Values [MPG]')\n",
        "plt.ylabel('Predictions [MPG]')\n",
        "lims = [0, 50]\n",
        "plt.xlim(lims)\n",
        "plt.ylim(lims)\n",
        "_ = plt.plot(lims, lims)"
      ],
      "metadata": {
        "id": "bzJfvcZIIfJe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot prediction error histogram\n",
        "error = test_predictions - test_labels\n",
        "plt.hist(error, bins=25)\n",
        "plt.xlabel('Prediction Error [MPG]')\n",
        "_ = plt.ylabel('Count')"
      ],
      "metadata": {
        "id": "gyQGkLuYIhxm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the DNN model\n",
        "dnn_model.save('dnn_model.keras')"
      ],
      "metadata": {
        "id": "vLHBxW8DIpYd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the saved model\n",
        "reloaded = tf.keras.models.load_model('dnn_model.keras')\n",
        "\n",
        "# Evaluate the reloaded model on the test set\n",
        "test_results['reloaded'] = reloaded.evaluate(\n",
        "    test_features, test_labels, verbose=0)"
      ],
      "metadata": {
        "id": "Y3y_oQ0vIquf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the final test results\n",
        "pd.DataFrame(test_results, index=['Mean absolute error [MPG]']).T"
      ],
      "metadata": {
        "id": "aXHUL3KHIskN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}