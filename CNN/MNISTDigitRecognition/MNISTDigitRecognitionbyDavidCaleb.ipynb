{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb86d2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4865741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Check for GPU availability\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c8748b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN model\n",
    "class MNISTClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MNISTClassifier, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7761e415",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess MNIST dataset\n",
    "def load_mnist_data(batch_size=64):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "    \n",
    "    # Download and load training data\n",
    "    full_dataset = datasets.MNIST('data', train=True, download=True, transform=transform)\n",
    "    \n",
    "    # Split into train and validation sets (80/20)\n",
    "    train_size = int(0.8 * len(full_dataset))\n",
    "    val_size = len(full_dataset) - train_size\n",
    "    train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74aadfa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function\n",
    "def train_model(model, train_loader, val_loader, epochs=10, learning_rate=0.001):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    model.to(device)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        \n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item() * images.size(0)\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item() * images.size(0)\n",
    "                \n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        # Print statistics\n",
    "        train_loss = train_loss / len(train_loader.dataset)\n",
    "        val_loss = val_loss / len(val_loader.dataset)\n",
    "        accuracy = 100 * correct / total\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{epochs} - \"\n",
    "                f\"Train Loss: {train_loss:.4f} - \"\n",
    "                f\"Val Loss: {val_loss:.4f} - \"\n",
    "                f\"Val Accuracy: {accuracy:.2f}%\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1746d176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess sketchpad input for the model\n",
    "def preprocess_image(input_data):    \n",
    "    # Extract image from dictionary (handles newer Gradio versions)\n",
    "    if isinstance(input_data, dict):\n",
    "        if 'image' in input_data:\n",
    "            image = input_data['image']\n",
    "        elif 'composite' in input_data:\n",
    "            image = input_data['composite']\n",
    "        else:\n",
    "            raise ValueError(\"Dictionary input missing image data\")\n",
    "    elif isinstance(input_data, np.ndarray):\n",
    "        image = input_data\n",
    "    else:\n",
    "        try:\n",
    "            image = np.array(input_data)\n",
    "        except:\n",
    "            raise ValueError(f\"Unsupported input type: {type(input_data)}\")\n",
    "    \n",
    "    print(f\"Image shape before processing: {image.shape}\")\n",
    "    \n",
    "    # Convert RGBA/RGB to grayscale if needed\n",
    "    if image.ndim == 3:\n",
    "        if image.shape[2] == 4:  # RGBA image\n",
    "            image = image[..., :3]  # Drop alpha channel\n",
    "        image = np.mean(image, axis=2)  # Convert to grayscale\n",
    "    \n",
    "    # Invert colors (MNIST has white digits on black background)\n",
    "    image = 255 - image\n",
    "    \n",
    "    # Convert to tensor and normalize\n",
    "    image_tensor = transforms.functional.to_tensor(image).unsqueeze(0)  # Add batch dimension\n",
    "    image_tensor = transforms.functional.resize(image_tensor, (28, 28))\n",
    "    image_tensor = transforms.functional.normalize(image_tensor, (0.1307,), (0.3081,))\n",
    "    \n",
    "    return image_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8ad269f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create probability bar chart\n",
    "def plot_probabilities(probabilities):\n",
    "    fig, ax = plt.subplots()\n",
    "    bars = ax.bar(range(10), probabilities)\n",
    "    ax.set_xlabel('Digit')\n",
    "    ax.set_ylabel('Probability')\n",
    "    ax.set_title('Prediction Probabilities')\n",
    "    ax.set_xticks(range(10))\n",
    "    ax.set_ylim(0, 1)\n",
    "    \n",
    "    # Add probability text on top of bars\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{height:.2f}',\n",
    "                ha='center', va='bottom')\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c48fbb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction function for Gradio interface\n",
    "def predict_digit(input_data):\n",
    "    try:\n",
    "        # Preprocess the input image\n",
    "        input_tensor = preprocess_image(input_data).to(device)\n",
    "        \n",
    "        # Make prediction\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            output = model(input_tensor)\n",
    "            probabilities = torch.softmax(output, dim=1).cpu().numpy()[0]\n",
    "        \n",
    "        # Get predicted digit\n",
    "        predicted_digit = int(np.argmax(probabilities))\n",
    "        \n",
    "        # Create probability plot\n",
    "        prob_plot = plot_probabilities(probabilities)\n",
    "        \n",
    "        return predicted_digit, prob_plot\n",
    "    except Exception as e:\n",
    "        print(f\"Error during prediction: {str(e)}\")\n",
    "        return \"Error\", None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ea89226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Creating model...\n",
      "Training model...\n",
      "Epoch 1/10 - Train Loss: 0.2390 - Val Loss: 0.0640 - Val Accuracy: 98.13%\n",
      "Epoch 2/10 - Train Loss: 0.0947 - Val Loss: 0.0589 - Val Accuracy: 98.30%\n",
      "Epoch 3/10 - Train Loss: 0.0743 - Val Loss: 0.0453 - Val Accuracy: 98.72%\n",
      "Epoch 4/10 - Train Loss: 0.0605 - Val Loss: 0.0407 - Val Accuracy: 98.83%\n",
      "Epoch 5/10 - Train Loss: 0.0507 - Val Loss: 0.0350 - Val Accuracy: 98.99%\n",
      "Epoch 6/10 - Train Loss: 0.0466 - Val Loss: 0.0395 - Val Accuracy: 98.94%\n",
      "Epoch 7/10 - Train Loss: 0.0429 - Val Loss: 0.0347 - Val Accuracy: 99.04%\n",
      "Epoch 8/10 - Train Loss: 0.0412 - Val Loss: 0.0341 - Val Accuracy: 99.09%\n",
      "Epoch 9/10 - Train Loss: 0.0361 - Val Loss: 0.0389 - Val Accuracy: 98.99%\n",
      "Epoch 10/10 - Train Loss: 0.0364 - Val Loss: 0.0340 - Val Accuracy: 99.09%\n"
     ]
    }
   ],
   "source": [
    "# Load data and train model\n",
    "print(\"Loading data...\")\n",
    "train_loader, val_loader = load_mnist_data(batch_size=64)\n",
    "\n",
    "print(\"Creating model...\")\n",
    "model = MNISTClassifier()\n",
    "\n",
    "print(\"Training model...\")\n",
    "model = train_model(model, train_loader, val_loader, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "531ec0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Gradio interface\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"# MNIST Digit Recognition\")\n",
    "    gr.Markdown(\"Draw a digit (0-9) in the box below and see the model's prediction.\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        # Sketchpad with explicit numpy output\n",
    "        sketchpad = gr.Sketchpad(label=\"Draw Digit\", \n",
    "                                image_mode=\"L\",\n",
    "                                type=\"numpy\")\n",
    "        with gr.Column():\n",
    "            label = gr.Label(label=\"Predicted Digit\")\n",
    "            plot = gr.Plot(label=\"Prediction Probabilities\")\n",
    "    \n",
    "    sketchpad.change(\n",
    "        fn=predict_digit,\n",
    "        inputs=sketchpad,\n",
    "        outputs=[label, plot]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3855e88a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape before processing: (800, 800)\n",
      "Error during prediction: 'NoneType' object has no attribute 'shape'\n",
      "Image shape before processing: (800, 800)\n",
      "Error during prediction: 'NoneType' object has no attribute 'shape'\n",
      "Image shape before processing: (800, 800)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    demo.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
