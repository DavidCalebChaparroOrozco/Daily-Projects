# Daily-Projects
This repository contains my daily projects, challenging me to create something new every day. From small utilities to full-fledged applications, they reflect my growth as a developer. Each project has a brief description of technologies, challenges and lessons. It is a record of my progress and a constantly evolving portfolio.
* Day 01:  Polar Plots in Python with Matplotlib by Neural Nine
  * Today we learn how to work with polar coordinates and how to create polar plots in Python using Matplotlib.
* Day 02: Spotify Oldies Dataset 🎶: A Treasury of Classics [Kaggle](https://www.kaggle.com/datasets/kanchana1990/spotify-oldies-dataset/data)
  * Today I'm going to work with a dataset called Spotify Oldies Dataset: A Treasury of Classics.
* Day 03: Pomodoro Timer GUI
  * In this project, I developed a graphical user interface (GUI) for a Pomodoro Timer using Tkinter in Python. The Pomodoro Technique is a time management method that uses a timer to break down work into intervals, traditionally 25 minutes in length, separated by short breaks. This GUI application allows users to start, reset, and skip timers for Pomodoro sessions, short breaks, and long breaks, providing visual feedback on the remaining time for each interval. It serves as a practical tool for enhancing productivity and focus during work or study sessions.
* Day 04: To Do App
  * Today, I created a To Do application using Flask and SQLAlchemy. This app allows users to add, edit, and delete tasks, as well as mark them as completed or in progress. Users can also search and filter tasks by various criteria such as title, completion status, priority, and due date. Additionally, the app supports sorting tasks by ID, title, or completion status, and offers bulk actions to mark tasks as completed, in progress, or not completed. It's a simple yet practical tool for managing daily tasks efficiently.
* Day 05: ContactManager
  * This project involves creating a contact manager application using Python's Tkinter library. The ContactManager allows users to add, edit, view, and delete contacts. It provides features such as pagination, searching, importing/exporting contacts from/to CSV files, and input validation for contact details. It offers a user-friendly interface for managing contact information effectively.
* Day 06: Income Prediction Adult Income [Kaggle](https://www.kaggle.com/datasets/wenruliu/adult-income-dataset)
  * In today's project, I implemented a machine learning model to predict adult income using the Adult Income dataset. The dataset contains various demographic and employment-related features such as age, education level, occupation, and work hours per week, along with the target variable indicating whether an individual earns more than $50,000 annually. I utilized the Random Forest algorithm to train the model and extracted feature importance scores to identify the key factors influencing income prediction. The model achieved an accuracy of  0.86%, demonstrating its capability to classify individuals into different income groups. This project enhances my understanding of supervised learning techniques and their application in real-world scenarios.
* Day 07: Pokedex GUI Application
  * In this project, I developed a graphical user interface (GUI) application for a Pokedex using Python's Tkinter library. The Pokedex is a digital encyclopedia that catalogues information about different species of Pokémon, a popular franchise of fictional creatures.
* Day 08: Flet Chat Application
  * Created a chat application using Flet library in Python. This application allows users to join a chat room, send and receive messages in real-time. It features a graphical user interface (GUI) for displaying chat messages, input field for sending messages, and user authentication. The application utilizes Flet components for UI design and integrates functionalities for sending, receiving, and displaying messages efficiently. It serves as a practical tool for real-time communication and collaboration among users.
* Day 09: Video Game Sales [Kaggle](https://www.kaggle.com/datasets/gregorut/videogamesales/data)
  * Today's project delves into the world of video game sales analysis. Leveraging the Video Game Sales dataset from Kaggle, I explore trends and patterns in the gaming industry. This dataset contains information on video game sales across different platforms, regions, genres, and years, providing valuable insights into consumer preferences and market dynamics. Through data exploration, visualization, and potentially predictive modeling, I aim to uncover hidden gems and understand what makes a successful video game title. Stay tuned for the journey through pixels and polygons! 🎮✨
* Day 10: Summarize News Articles
  * Worked on a project to summarize news articles using web scraping and natural language processing libraries like newspaper3k and TextBlob.
* Day 11: Sudoku Solver
  * In this project, I've crafted a Sudoku solver leveraging the backtracking algorithm in Python. This application empowers users to input incomplete Sudoku puzzles, generating a valid solution for the board. To enhance user experience, I integrated the Tkinter graphical library to craft an interactive interface. Through this interface, users can input Sudoku numbers and witness the solution unfold step by step. This project not only offers an efficient solution for Sudoku puzzles but also serves as an educational tool to delve into backtracking algorithms and Python-based interactive user interfaces.
* Day 12: Snake Pygame
  * In today's project, I built a classic Snake game using Pygame, a popular Python library for creating 2D games. The Snake game is a timeless arcade classic where the player controls a snake that moves around the screen, eating food to grow longer while avoiding collisions with itself and the boundaries of the game area.
* Day 13: Titanic Dataset 🚢 [Kaggle](https://www.kaggle.com/c/titanic)
  * Today, we delve into the exciting world of data analysis with the famous Titanic dataset. This dataset, available on Kaggle, provides information about the passengers aboard the Titanic, including details such as age, gender, ticket class, fare paid, and more. Our task is to explore this dataset, understand its key features, and possibly develop predictive models to determine the likelihood of a passenger's survival based on various factors. Through this project, we will not only enhance our data analysis skills but also honor the memory of the Titanic passengers by extracting meaningful insights from this historic dataset.
* Day 14: Email Python
  * Today's project involves creating a Python script for sending automated emails. Leveraging libraries such as smtplib, schedule, and dotenv, we develop a script capable of sending daily inspirational emails to a specified email address. The script reads quotes from a file, selects a random quote, and sends it via SMTP protocol. Utilizing environment variables for storing email credentials ensures security and flexibility. By scheduling the script to run periodically using the schedule library, we automate the process of sending daily inspiration to recipients, fostering motivation and positivity. This project not only demonstrates practical use cases of Python for automation but also serves as a reminder of the power of uplifting messages in our daily lives.
* Day 15: Guess the Number
  * Today's project involves creating a number guessing game using Python's Tkinter library for building the graphical user interface (GUI). The game prompts the player to guess a randomly generated number between 1 and 99 within a limited number of attempts. Through input validation and dynamic feedback, the game guides the player to adjust their guesses until they either correctly identify the number or exhaust their attempts. This project not only showcases interactive GUI development with Tkinter but also reinforces concepts of random number generation, user input handling, and game logic implementation. It provides an entertaining and engaging experience for players while honing programming skills in Python. Can you beat the odds and guess the secret number? Let the guessing game begin! 🎲
* Day 16: Virtual Bookshelves
  * In this project, I'll create a virtual bookshelf management system using Python and SQLite. The application will allow users to add, remove, update, and view books in their virtual bookshelves. Each book will have attributes such as title, author, year published, and genre. The system will utilize SQLite for database management and provide a user-friendly interface for interacting with the bookshelves. This project aims to simulate real-world bookshelf management scenarios and provide users with a convenient way to organize their reading materials. Let's embark on the journey of building virtual bookshelves to enhance our reading experiences! 📚✨
* Day 17: RSS Feed Reader
  * In this project, I'll develop an RSS feed reader using Python and BeautifulSoup. The RSS feed reader will be capable of fetching and parsing RSS feeds from various sources. It will extract relevant information such as titles, descriptions, and links from the feeds, presenting them in a user-friendly format. By implementing this RSS feed reader, I aim to enhance my skills in web scraping, XML parsing, and data presentation. Stay tuned for an efficient tool to stay updated with the latest news and content from your favorite websites! 📰🚀
* Day 18: Customer Manager JSON
  * In this project, I've developed a customer management system using Python and JSON. The system allows users to store and manage information about customers, including names, email addresses, cities, etc. It implements functionalities such as searching for customers by name, updating contact information, deleting customers, and adding new customers. Leveraging JSON as the data storage format ensures portability and simplicity in data management. This project enhances my skills in file handling, data manipulation, and user interface design. It serves as a practical tool for organizing customer data efficiently and facilitating effective communication and interaction with clients. Let's embark on the journey of customer management and streamline the process of customer engagement! 📊👥
* Day 19: Expense Tracking App
  * Created an expense tracking application using Python's Tkinter library. This app allows users to record their expenses, including item name, price, and purchase date. Users can add, edit, delete, and view expense records, providing a convenient way to manage their finances. Additionally, the app calculates the total expense and remaining balance, offering insights into spending habits. It serves as a practical tool for budgeting and financial management. 📊💰
* Day 20: Hangman
  * Implemented the classic Hangman game using Python and Flask. Players can guess letters to reveal a hidden word within a limited number of attempts. The game features a user-friendly interface and supports error handling for invalid inputs. Test your vocabulary and strategic thinking in this timeless word-guessing challenge! 🎩🔤
* Day 21: Image Editor
  * In this project, I developed an image editor using Python and Tkinter. The Image Editor allows users to open image files, apply filters such as black and white, blur, sharpen, and more, flip and rotate images, draw lines over the images, change pen color, erase drawn lines, and save edited images. It provides a user-friendly interface for basic image editing tasks and serves as a practical tool for enhancing and modifying images. Let your creativity flow with the Image Editor! 🎨🖼️
* Day 22: Faker User
  * In this project, I utilized the Faker library in Python to generate synthetic user data. From names and email addresses to phone numbers and job titles, Faker User creates realistic user profiles effortlessly. Whether for testing, prototyping, or data augmentation, Faker User streamlines the process of generating diverse and customizable datasets.
* Day 23: Simple Stock Price (Steamlit)
  * Today's project revolves around creating a Simple Stock Price application using Streamlit. This application enables users to visualize stock price data, including closing prices, volume, and candlestick charts, for various companies. Leveraging the yfinance library, the app fetches historical stock data and presents it in an interactive and user-friendly manner. Users can select a company from a dropdown menu, view different metrics, and analyze performance metrics such as returns, volatility, and Sharpe ratio. With its intuitive interface and insightful visualizations, this project serves as a valuable tool for investors and enthusiasts alike to track and analyze stock market trends.
* Day 24: Quality Of Wine [Kaggle](https://www.kaggle.com/datasets/uciml/red-wine-quality-cortez-et-al-2009)
  * Exploring the quality of wine dataset from Kaggle, I aim to analyze factors influencing the quality of red wine. Leveraging data analysis and visualization techniques, I seek to uncover patterns and relationships among various chemical properties and wine quality ratings. By applying machine learning algorithms, I intend to develop predictive models to classify wine quality based on its attributes. This project provides insights into the intricate world of wine quality assessment and demonstrates the application of data science in the domain of viticulture. Cheers to discovering the essence of fine wine! 🍷📊
* Day 25: Extract Dominant Colors
  * In this project, I'll delve into the fascinating realm of image processing to extract the dominant colors from images. Utilizing Python libraries such as ColorThief and Matplotlib, I'll develop a script capable of identifying the primary colors present in an image. By analyzing color palettes and visualizing dominant hues, this endeavor aims to provide insights into the aesthetic composition of images. Join me as I explore the vibrant spectrum of colors and uncover the beauty hidden within digital imagery. 🎨🖼️
* Day 26: Tree Node
  * On day 26, I focused on the implementation of a fundamental data structure, the tree node. Through Python, I constructed a TreeNode class capable of representing nodes within a binary search tree. With the aid of methods like insertion and various traversal techniques (preorder, inorder, and postorder), I delved into the intricacies of managing and navigating through binary trees. This exploration lays the groundwork for comprehending more complex tree-based algorithms and data structures, providing a solid foundation for further study in computer science and programming. 🌳🔍
* Day 27: ML with FastAPI
  * Today we learn how to easily turn machine learning models into usable APIs using FastAPI in Python.
* Day 28: Tutorial Guide (Python Types Intro) [FastAPI](https://fastapi.tiangolo.com/python-types/)
  * On day 28, we delve into an essential aspect of Python programming - types. This tutorial guide provides an introduction to Python types, focusing particularly on their usage within the FastAPI framework. Understanding Python types is crucial for developing robust and maintainable code, and integrating this knowledge with FastAPI facilitates the creation of efficient and scalable web APIs. By exploring the intricacies of Python types within the context of FastAPI, we equip ourselves with powerful tools for building robust and type-safe applications. 🐍✨
* Day 29: Parking Space Counter
  * We implemented a parking space counter application using Python and OpenCV. This project enables users to define parking spaces on an image, count full and empty parking spots, and visualize the counts in real-time. The application leverages computer vision techniques to identify parking space boundaries and utilizes event handling to interactively mark full and empty spaces. This project serves as a practical example of applying Python and OpenCV for image processing and computer vision tasks, demonstrating their utility in real-world applications such as parking management systems. 🅿️🚗🅿️
* Day 30: [TensorFlow](https://www.tensorflow.org/tutorials/keras/classification) Guide (Beginner ~ ML Basics with Keras)
  * Explore the fundamentals of machine learning with TensorFlow and Keras in this beginner's guide. This guide provides a comprehensive overview of TensorFlow, a powerful open-source machine learning framework developed by Google. Through practical examples and step-by-step tutorials, you'll learn how to build and train neural networks using Keras, a high-level neural networks API that runs on top of TensorFlow. From basic concepts to hands-on implementation, this guide is designed to introduce you to the essentials of machine learning and empower you to start building your own ML models with TensorFlow and Keras. 🤖📚🔍
* Day 31: Spam Emails Dataset [Kaggle](https://www.kaggle.com/datasets/venky73/spam-mails-dataset/code)
  * We explored a Spam Emails Dataset available on Kaggle. This dataset contains a collection of emails labeled as spam or ham (not spam). Leveraging this dataset, we embarked on a data analysis and preprocessing journey using Python and pandas. Through this process, we gained insights into the structure of the data and performed necessary preprocessing steps to prepare it for machine learning tasks. By delving into real-world data and preparing it for analysis, we honed our data manipulation and preprocessing skills, essential for any data science or machine learning project. 📧🔍🛠️
* Day 32: Dijkstra's Algorithm Implementation
  * We implemented the Dijkstra algorithm, which is a design algorithm used to find the shortest path between nodes in a graph. The implementation is made in Python and uses a linear array to precisely search the graph and calculate the shortest distance from the starting point to all other points. Dijkstra's algorithm is widely used in a variety of applications, including network protocol routing  and  video game routing. By applying this algorithm, we increased 's design understanding  and strengthened our algorithmic problem-solving skills. 📈🔍💡
* Day 33: Technical Test "Add Two Numbers" and "FizzBuzz" [LeetCode](https://leetcode.com/problems/)
  * Add Two Numbers: We tackled the "Add Two Numbers" problem from LeetCode, which involves adding two non-empty linked lists representing non-negative integers. The digits are stored in reverse order, and each node contains a single digit. We implemented a Python solution that traverses both linked lists simultaneously, summing the corresponding digits and handling any carry. This problem enhances our understanding of linked list manipulation and problem-solving skills.
  [Problem Description](https://leetcode.com/problems/add-two-numbers/description/?source=submission-ac)
  
  * FizzBuzz: The second problem we solved was "FizzBuzz," also from LeetCode. This classic programming problem requires generating the FizzBuzz sequence up to a given number. We crafted a Python solution that iterates through the numbers from 1 to the given number, appending "Fizz" for multiples of 3, "Buzz" for multiples of 5, "FizzBuzz" for multiples of both 3 and 5, and the number itself if none of the conditions are met. This exercise reinforces our ability to write concise and efficient code to solve common programming challenges.
  [Problem Description](https://leetcode.com/problems/fizz-buzz/description/)
* Day 34: Quicksort
  * We implemented Quicksort, a divide-and-conquer algorithm used for sorting arrays or lists. Quicksort selects a pivot element, partitions the other elements into two sub-arrays based on whether they are less than or greater than the pivot, and recursively sorts the sub-arrays. Known for its efficiency, Quicksort is often used as a benchmark for comparison with other sorting algorithms, enhancing our understanding of algorithmic efficiency and problem-solving skills. 🔄📊🔍
* Day 35: Live Weather Forecast Flask App
  * In today's project, we'll develop a live weather forecast Flask app. This app will take a city name as input and provide various weather characteristics such as temperature in Celsius and Fahrenheit, humidity, wind speed, and more.
* Day 36: Random Passwords Generator
  * Today, we created a Random Passwords Generator program. This program prompts the user to specify the desired length of the password and generates a strong password consisting of a mix of lowercase and uppercase letters, digits, and special characters. Additionally, we implemented a function to save the generated passwords to a CSV file for later use. This project enhances our understanding of string manipulation, random number generation, and file handling in Python, while also providing practical utility by creating a tool for generating secure passwords. 🔒💡💻
* Day 37: Site Connectivity Checker
  * Today, we developed a Site Connectivity Checker application using Flask. This application allows users to input a URL and checks its connectivity by sending a request to the specified website. We enhanced the functionality by adding URL validation, error handling for various connection issues, and logging of activity to track the status of site connections over time. By building this project, we gained practical experience in web development with Flask, handling HTTP requests, error management, and logging, all of which are essential skills for creating robust web applications. 🌐🔍🚀
* Day 38: Heart Attack Analysis & Prediction Dataset [Kaggle](https://www.kaggle.com/datasets/rashikrahmanpritom/heart-attack-analysis-prediction-dataset/data)
  * We explored the Heart Attack Analysis & Prediction Dataset available on Kaggle. This dataset provides valuable insights into factors contributing to heart attacks and includes various health parameters such as age, sex, cholesterol levels, blood pressure, and more. By analyzing this dataset, we aim to gain a deeper understanding of the relationships between different risk factors and the likelihood of a heart attack occurrence. Leveraging statistical analysis and machine learning techniques, we strive to develop predictive models that can assist in early detection and prevention efforts for cardiovascular diseases. This project underscores the importance of data-driven approaches in healthcare and reinforces our skills in data analysis, predictive modeling, and domain knowledge application. ❤️📊🔬
* Day 39: [TensorFlow](https://www.tensorflow.org/tutorials/keras/classification) Guide Basic text Classification (Beginner ~ ML Basics with Keras)
  * Continuing from Day 30, delve deeper into machine learning with TensorFlow and Keras by exploring basic text classification. In this guide, you'll learn how to apply machine learning concepts to classify text data using TensorFlow and Keras. By following step-by-step tutorials and practical examples, you'll understand the fundamentals of text classification, including preprocessing text data, building neural network models, and evaluating model performance. Whether you're new to machine learning or looking to expand your knowledge, this guide provides valuable insights and hands-on experience to enhance your skills in natural language processing and text classification tasks. 🤖📚🔍
* Day 40: Technical Test "Minimum Height Trees" and "Zigzag Conversion" [LeetCode](https://leetcode.com/problems/)
  * Minimum Height Trees: Today, we encountered the "Minimum Height Trees" problem on LeetCode. This problem revolves around identifying the roots of minimum height trees in an undirected graph, given the number of nodes and an array of edges representing connections between nodes. We crafted a Python solution employing graph traversal and manipulation techniques to determine the roots with minimum height efficiently. This challenge enhances our ability to work with graphs, analyze graph structures, and devise optimal algorithms for graph-related problems. [Problem Description](https://leetcode.com/problems/minimum-height-trees/description/)
  * Zigzag Conversion: In addition, we tackled the "Zigzag Conversion" problem on LeetCode. This problem involves converting a given string into a zigzag pattern with a specified number of rows and then reading the string line by line. We devised a Python solution that constructs the zigzag pattern by iteratively placing characters in the appropriate rows, simulating the pattern formation and reading process. Solving this problem reinforces our understanding of string manipulation techniques and enhances our problem-solving skills in handling complex pattern-based challenges. [Problem Description](https://leetcode.com/problems/zigzag-conversion/description/)
* Day 41: Tkinter - Map View
  * Explore Tkinter's capabilities in displaying interactive maps with the Tkinter MapView project. This Tkinter-based application allows users to visualize maps, search for addresses, and adjust zoom levels seamlessly within a GUI interface. By integrating functionalities such as address lookup, zoom control, and map display, this project showcases the potential of Tkinter for creating dynamic and user-friendly applications. Dive into the world of Tkinter and enhance your skills in GUI development with the MapView project. 🗺️🖥️🔍
* Day 42: Tkinter - Digital Clock
  * Explore the world of GUI development with Tkinter by creating a digital clock application. In this project, I utilized Tkinter's functionalities to design an attractive and functional digital clock interface. By leveraging Python's time module and Tkinter's Label widget, I implemented a dynamic clock display that updates in real-time. Join me as I continue to delve into Tkinter and expand my skills in creating intuitive and visually appealing graphical user interfaces. ⏰🖥️🔧
* Day 43: PySpark (Quickstart: DataFrame)[https://spark.apache.org/docs/3.3.1/api/python/getting_started/quickstart_df.html]
  * Dive into the world of big data processing with PySpark as we explore the Quickstart guide for DataFrames. PySpark is a powerful tool for processing large-scale datasets using the Apache Spark framework. In this project, we'll delve into the basics of working with DataFrames, a distributed collection of data organized into named columns. By following the Quickstart guide, we'll learn how to create, manipulate, and analyze DataFrames efficiently. Join me on this journey as we harness the power of PySpark to tackle big data challenges with ease and scalability. 🚀💻🔍
* Day 44: Daily Routine with Desktop Notifications
  * In this project, I crafted a personalized daily routine assistant utilizing desktop notifications. Leveraging Python libraries such as `win10toast` and `schedule`, I created a system that sends timely notifications for various activities throughout the day. Whether it's studying English, working on Python projects, taking short breaks, or even enjoying a joke break, this routine keeps me organized and on track. By scheduling notifications at specific times using the schedule module, I ensure I stay productive and maintain a healthy balance between work and relaxation. Join me as I automate my daily routine and optimize my productivity with desktop notifications! 📅⏰🖥️
* Day 45: Language Detection
  * Enhancing my text processing capabilities, I delved into language detection. Leveraging the langdetect and langcodes libraries in Python, I developed a program capable of identifying the language of input text. By utilizing the powerful language detection algorithms provided by these libraries, I crafted a user-friendly interface using Tkinter. This project allows users to input text and receive instant feedback on the detected language, aiding in various applications such as multilingual text analysis, translation services, and content filtering. Join me as I explore the fascinating world of language detection and broaden the scope of text processing possibilities! 🌐🔍📝
* Day 46: Technical Test "MedianSortedArrays" and "lengthOfLongestSubstring" [LeetCode](https://leetcode.com/problems/)
  * MedianSortedArrays: Today, we encountered the "Median of Two Sorted Arrays" problem on LeetCode. This problem involves finding the median of two sorted arrays, which are of different sizes, m and n. The challenge is to achieve a time complexity of O(log(m+n)). We tackled this problem by employing the binary search approach. By partitioning the arrays and comparing elements at partition points, we efficiently determine the median. Solving this problem enhances our understanding of algorithmic complexity and binary search techniques, crucial for tackling similar problems efficiently. [Problem Description](https://leetcode.com/problems/median-of-two-sorted-arrays/)

  * lengthOfLongestSubstring: In addition, we tackled the "Longest Substring Without Repeating Characters" problem on LeetCode. This problem requires finding the length of the longest substring within a given string that does not contain any repeating characters. We approached this problem using a sliding window technique, which allows us to efficiently traverse the string while keeping track of the characters encountered. By updating the window's boundaries based on repeating characters, we determine the longest substring without repetition. Solving this problem enhances our understanding of string manipulation and sliding window algorithms, essential for solving various string-related challenges. [Problem Description](https://leetcode.com/problems/longest-substring-without-repeating-characters/description/)
* Day 47: Currency Converter
  * Today, I embarked on a journey to create a currency converter application using Python. Leveraging the tkinter library for graphical user interface (GUI) development and the forex_python library for currency conversion functionality, I crafted a simple yet effective tool for converting between different currencies. This project involved setting up dropdown menus for selecting the source and target currencies, implementing an entry widget for inputting the amount to convert, and integrating a button to trigger the conversion process. By handling exceptions and displaying conversion results dynamically, I ensured a smooth user experience. Join me as I explore the world of currency conversion and develop a handy tool for everyday use! 💱💼🔀
* Day 48: Perceptron
  * In today's project, I delved into the world of artificial neural networks by implementing a perceptron from scratch. The perceptron, a fundamental building block of neural networks, is a simple algorithm capable of learning binary classifiers. Leveraging the NumPy library for numerical operations, I crafted a perceptron class capable of training on labeled datasets and making predictions. By defining the perceptron's architecture, including input features, weights, and activation functions, I gained insight into the inner workings of neural networks. Through iterative training and weight updates based on prediction errors, the perceptron learns to separate linearly separable classes in feature space. This project serves as a foundational step towards understanding more complex neural network architectures and their applications in machine learning and artificial intelligence. Join me as I explore the basic principles of neural networks and implement a perceptron algorithm from scratch! 🧠💻🤖
* Day 49: Technical Test "Reverse Integer" and "Longest Palindromic Substring" [LeetCode](https://leetcode.com/problems/)
  * Today's technical challenge involves the "Reverse Integer" problem on LeetCode. This problem requires reversing the digits of a signed 32-bit integer. If the reversed integer overflows, the function should return 0. We'll tackle this problem by implementing a solution that handles both positive and negative integers, considering overflow conditions carefully. Solving this problem enhances our skills in handling numerical operations and edge cases effectively. [Problem Description](https://leetcode.com/problems/reverse-integer/description/)
  * "Longest Palindromic Substring": Additionally, we'll tackle the "Longest Palindromic Substring" problem on LeetCode. This problem involves finding the longest palindromic substring within a given string. We'll devise an algorithm to efficiently determine the longest palindrome, leveraging techniques such as dynamic programming or expanding around centers. By addressing this challenge, we deepen our understanding of string manipulation and algorithmic problem-solving strategies. [Problem Description](https://leetcode.com/problems/longest-palindromic-substring/description/)
* Day 50: Students Performance in Exams [Kaggle](https://www.kaggle.com/datasets/whenamancodes/students-performance-in-exams/data)
  * Today, we delve into the realm of educational data analysis by exploring a student performance dataset from Kaggle. This dataset offers valuable insights into factors that may influence student achievement in exams. By delving into this data, we can uncover patterns, trends, and relationships that can inform educational practices and improve student learning outcomes.
* Day 51: Interactive Menu for YouTube and Web Searches
  * Today's focus is on creating a music player application. Building a music player involves integrating functionalities to play, pause, skip, and control the playback of audio files. Additionally, we'll explore features such as creating playlists, displaying metadata, and providing a user-friendly interface for an immersive music listening experience. By developing a music player, we deepen our understanding of GUI frameworks, multimedia handling, and software design principles.
* Day 52: Task Manager Performance
  * Today's task revolves around analyzing the performance of a task manager application. Task managers play a crucial role in monitoring system resources, managing processes, and optimizing performance. Through this analysis, we aim to evaluate the efficiency, responsiveness, and resource utilization of the task manager under various conditions. By examining performance metrics such as CPU usage, memory consumption, and task responsiveness, we can identify areas for improvement and enhance the overall functionality of the task manager application.
* Day 53: Technical Test "Integer to Roman" and "Container With Most Water" [LeetCode](https://leetcode.com/problems/)
  * Integer to Roman:
    Roman numerals are represented by seven different symbols: I, V, X, L, C, D, and M. Implement a function to convert an integer into its corresponding Roman numeral representation.
    Given an integer, convert it to a Roman numeral. [Problem Description](https://leetcode.com/problems/integer-to-roman/)
  * Container With Most Water: You are given an integer array `height` of length `n`. There are `n` vertical lines drawn such that the two endpoints of the ith line are (i, 0) and (i, height[i]). Find two lines that together with the x-axis form a container, such that the container contains the most water.Return the maximum amount of water a container can store. [Problem Description](https://leetcode.com/problems/container-with-most-water/description/)
* Day 54: Background Remove Flask
  * Today's focus is on implementing a background removal functionality within a Flask web application. Background removal is a crucial task in image processing and computer vision, allowing users to isolate subjects from their backgrounds. By integrating this functionality into a web application using Flask, we aim to provide users with a convenient and accessible tool for background removal tasks. Throughout this process, we'll explore techniques for image manipulation, integration of third-party libraries, and web development with Flask. By building a background removal tool, we enhance our understanding of image processing algorithms, web application development, and practical applications of computer vision technology.
* Day 55: Multiple Files Renamer
  * Today's focus is on developing a multiple files renamer application. Renaming multiple files in bulk is a common task, especially when organizing files or preparing them for specific purposes. This application will provide users with the ability to select a folder containing files, specify renaming criteria, and execute the renaming process efficiently. By creating this utility, we aim to streamline file management tasks and enhance productivity for users dealing with large numbers of files. Throughout the development process, we'll explore file handling techniques, user interface design, and implementation of renaming algorithms to ensure a robust and user-friendly application.
* Day 56: Technical Test "threeSum" and "threeSumClosest" [LeetCode](https://leetcode.com/problems/)
  Today's focus is on solving technical problems related to array manipulation and algorithmic thinking. We'll tackle two problems from LeetCode:
  * threeSum: Given an integer array nums, return all the triplets `[nums[i], nums[j], nums[k]]` such that `i != j, i != k`, and `j != k, and nums[i] + nums[j] + nums[k] == 0`. The solution set must not contain duplicate triplets. [Problem Description](https://leetcode.com/problems/3sum/description/)
  * threeSumClosest: Given an integer array nums of length n and an integer target, find three integers in nums such that the sum is closest to target. Return the sum of the three integers. You may assume that each input would have exactly one solution. [Problem Description](https://leetcode.com/problems/3sum-closest/description/)
* Day 57: KeyLogger 
  * Today's focus is on developing a KeyLogger application. A KeyLogger is a program that records the keystrokes made by a user on their computer. It's commonly used for various purposes such as monitoring employee activity, parental control, or debugging software. Our KeyLogger application will capture keystrokes and store them in a log file, providing users with the ability to monitor keyboard activity. Through this project, we'll delve into event handling, file I/O operations, and potentially explore additional features such as email notifications for logged keystrokes, enhancing the utility and versatility of the KeyLogger.
* Day 58: Matrix Effect
  * Today's focus is on creating a Matrix Effect, inspired by the iconic "Matrix" movie. This project involves generating a cascading effect of characters resembling the falling code seen in the film. Through this project, we'll explore concepts such as terminal manipulation, randomization, and animation. By implementing this Matrix Effect, we aim to recreate the visually stunning display seen in the movie, offering a fun and engaging coding exercise.
* Day 59: Dice-Rolling [realpython.com](https://realpython.com/python-dice-roll/#step-1-code-the-tui-of-your-python-dice-rolling-app)
  * Today's focus is on implementing a Dice-Rolling application. This project involves creating a Python program to simulate rolling dice. We'll explore concepts such as random number generation, user input validation, and ASCII art for visual representation of dice faces. Additionally, we'll delve into creating a text-based user interface (TUI) for the application. By developing this Dice-Rolling application, we aim to provide users with a fun and interactive way to simulate rolling dice, suitable for various gaming and recreational purposes.
* Day 60: Technical Test "letterCombinations" and "4Sum" [LeetCode](https://leetcode.com/problems/)
  * **Letter Combinations of a Phone Number**: Given a string containing digits from 2-9 inclusive, return all possible letter combinations that the number could represent. Return the answer in any order. [Problem Description](https://leetcode.com/problems/letter-combinations-of-a-phone-number/description/)
  * **4Sum**: Given an array `nums` of n integers, return an array of all the unique quadruplets `[nums[a], nums[b], nums[c], nums[d]]` such that:
     - `0 <= a, b, c, d < n`
     - `a, b, c, and d` are distinct.
     - `nums[a] + nums[b] + nums[c] + nums[d] == target`
  You may return the answer in any order. [Problem Description](https://leetcode.com/problems/4sum/)
* Day 61: Anemia Types Classification [Kaggle](https://www.kaggle.com/datasets/ehababoelnaga/anemia-types-classification/data)
  * Today, we focus on anemia types classification using a dataset from Kaggle. This dataset contains CBC (Complete Blood Count) data labeled with the diagnosis of anemia type, collected from several CBCs and diagnosed manually. By analyzing this dataset, we aim to understand the relationships between CBC parameters and different types of anemia. This analysis can provide valuable insights for medical diagnosis and treatment strategies.
* Day 62: Cinema Management System using OOP
  * Today, we delve into a cinema project focusing on Object-Oriented Programming (OOP). The project involves designing classes to simulate various aspects of a cinema system, including movies, rooms, reservations, and the cinema itself. Through this project, we aim to implement key OOP principles such as encapsulation, inheritance, and polymorphism. By structuring the code in an object-oriented manner, we can create a modular and scalable system that effectively models the functionalities of a real-world cinema. This project provides an excellent opportunity to practice OOP concepts while developing a practical application.
* Day 63: Technical Test "removeNthFromEnd" and "isMatch" [LeetCode](https://leetcode.com/problems/).
  * Today's technical test on LeetCode involves two problems:
  * removeNthFromEnd: Given the head of a linked list, remove the nth node from the end of the list and return its head. This problem challenges your ability to manipulate linked lists efficiently. [Problem Description](https://leetcode.com/problems/remove-nth-node-from-end-of-list/description/)
  * isMatch: Implement regular expression matching with support for '.' and '*', where '.' matches any single character and '*' matches zero or more of the preceding element. The matching should cover the entire input string (not partial). [Problem Description](https://leetcode.com/problems/regular-expression-matching/description/).
  
  These problems test your proficiency in data structures and algorithms, particularly in linked list manipulation and dynamic programming. Working on them will enhance your problem-solving skills and algorithmic thinking.
* Day 64: Contour Plots in Matplotlib - Visualize 3D Functions in 2D [NeuralNine](https://www.youtube.com/watch?v=DYn9HdTmt0E)
  * In today's session, we explore how to create contour plots in Matplotlib, a powerful visualization tool in Python. Contour plots allow us to represent 3D functions in 2D, providing a clear view of the function's behavior over a plane. We will generate 2D grids using `numpy.meshgrid` and define various 3D functions to visualize. The session includes creating both surface plots and filled contour plots using Matplotlib's `plot_surface` and `contourf` functions, respectively. This exercise will help you understand how to effectively visualize complex functions, enhancing your data presentation skills and making your plots more informative and visually appealing.
* Day 65: Technical Test "isValidParentheses" and "MergeTwoSortedLists" [LeetCode](https://leetcode.com/problems/).
  * isValidParentheses: Given a string `s` containing just the characters '(', ')', '{', '}', '[' and ']', determine if the input string is valid. An input string is valid if:
      * Open brackets must be closed by the same type of brackets.
      * Open brackets must be closed in the correct order.
      * Every close bracket has a corresponding open bracket of the same type. 
      [Problem Description](https://leetcode.com/problems/valid-parentheses/description/)
  * MergeTwoSortedLists: Given the heads of two sorted linked lists `list1` and `list2`, merge the two lists into one sorted list. The list should be made by splicing together the nodes of the first two lists. Return the head of the merged linked list. [Problem Description](https://leetcode.com/problems/merge-two-sorted-lists/description/)
* Day 66: Web Scraping Job Listings with Python
  * In today's session, we delve into the world of web scraping using Python. Our goal is to extract job listings from the Python.org jobs page and save the data into a CSV file. We will use the `requests` library to fetch the HTML content of the webpage and `BeautifulSoup` for parsing the HTML and extracting the job details. The details we will extract include the job title, company name, location, posting date, and job type. After extracting the data, we will write it into a CSV file using Python's `csv` module. This exercise will enhance your skills in web scraping, data extraction, and handling CSV files, providing a practical approach to gather and organize data from web sources.
* Day 67: [TensorFlow](https://www.tensorflow.org/tutorials/keras/regression) Regression (Beginner ~ ML Basics with Keras)
  * Today, we embark on a journey into the basics of regression analysis using TensorFlow and Keras. This tutorial covers the essential steps to build, train, and evaluate regression models. We will start by loading and cleaning the Auto MPG dataset, which includes features like 'Horsepower', 'Weight', and 'Acceleration'. After preprocessing the data, we'll split it into training and testing sets, and normalize it to improve model performance. You'll learn how to construct simple linear regression models, first with a single input and then with multiple inputs. Furthermore, we'll explore more complex models using deep neural networks (DNNs). This hands-on guide will help you understand the fundamentals of regression analysis, model training, evaluation, and making predictions, providing a strong foundation in machine learning with TensorFlow and Keras. 🚗📈🤖
* Day 68: Recursion "SierpinskiTriangle" and "FractalTree".
  * On day 68, we explore the concept of recursion through the creation of two classic fractals: the Sierpinski Triangle and the Fractal Tree. Both examples utilize Python's turtle graphics library to visualize the recursive processes.
    * Sierpinski Triangle: This fractal is formed by recursively subdividing an equilateral triangle into smaller triangles. Each subdivision step reduces the size of the triangles and changes their color based on the recursion depth. This exercise helps in understanding how recursion can break down complex problems into simpler, repeatable tasks.
    * Fractal Tree: This fractal simulates the natural growth patterns of a tree. Starting with a trunk, the tree branches into smaller sub-branches, each at a specific angle and length decrement. By adjusting the recursion depth, angle, and length decrement, different tree shapes and complexities can be generated. This project emphasizes the power of recursion in modeling natural phenomena and visualizing algorithmic patterns.
* Day 69: Ticket management GUI
  * On day 69, we delve into building a web-based Ticket Management System using Flask. This project includes two primary interfaces: one for clients to generate tickets for order claims, and another for providers to manage and track the tickets. The client-side allows users to enter their name, generate a ticket with a unique number, and record the time of generation. The provider-side interface displays the next ticket in the queue along with the current ticket being attended to and which counter is handling it. This system demonstrates the basics of web development with Flask, including form handling, data storage, and dynamic content rendering. By completing this project, you will gain practical experience in creating web applications, managing state, and ensuring smooth interactions between different user roles. 🧾🖥️✨
* Day 70: Scientific GUI Calculator
  * On day 70, we constructed a Graphical User Interface (GUI) for a scientific calculator using the tkinter library in Python. This calculator provides a wide range of mathematical functions, including basic arithmetic operations, trigonometric functions, logarithmic functions, and more. Users can input numerical values, perform calculations, and view results conveniently through the intuitive interface. The calculator's design incorporates various buttons for different mathematical operations, making it easy to use and navigate. By creating this project, you will enhance your skills in GUI development, event handling, and integrating complex mathematical operations into user-friendly applications. 🧮💻🔍
* Day 71: Technical Test "generateParenthesis" and "mergeKLists" [LeetCode](https://leetcode.com/problems/).
  * generateParenthesis: Given `n` pairs of parentheses, write a function to generate all combinations of well-formed parentheses.
  [Problem Description](https://leetcode.com/problems/generate-parentheses/description/)
  * mergeKLists: You are given an array of `k` linked-lists, each linked-list is sorted in ascending order. Merge all the linked-lists into one sorted linked-list and return it.[Problem Description](https://leetcode.com/problems/merge-k-sorted-lists/description/)
* Day 72: Knight's Tour Problem Solver
  * On day 72, we explore the classic Knight's Tour problem using Python. This project involves developing an algorithm to find a sequence of moves that allows a knight to visit every square on an N x N chessboard exactly once. The solution employs backtracking to systematically search for a valid tour, ensuring that all board positions are covered without repetition. The implementation includes functions to validate moves, print the board, and recursively attempt to solve the tour from a given starting position. By tackling this problem, you will gain a deeper understanding of recursion, backtracking, and algorithmic problem-solving. This project is an excellent exercise in enhancing your skills in algorithm development and Python programming. ♞📐💡
* Day 73: Tic-Tac-Toe Multiplayer [NeuralNine](https://youtu.be/s6HOPw_5XuY?si=ZlnrpRTxmJiYtGv8)
  * On day 73, we developed a multiplayer Tic-Tac-Toe game using Python. This project allows two players to connect over a network and play Tic-Tac-Toe in real-time. One player hosts the game, while the other player connects to it. The implementation includes setting up a server-client architecture using the socket library and managing game state and turns through a combination of functions for move validation, board updates, and win condition checks. The game uses threading to handle simultaneous communication between players. By completing this project, you will enhance your understanding of network programming, client-server communication, and basic game development in Python. 🎮🕹️💻
* Day 74: Technical Test "twoSum" and "myAtoi" [LeetCode](https://leetcode.com/problems/).
  * twoSum: Given an array of integers nums and an integer target, return indices of the two numbers such that they add up to target. You may assume that each input would have exactly one solution, and you may not use the same element twice. You can return the answer in any order.
  [Problem Description](https://leetcode.com/problems/two-sum/description/)
  * myAtoi: Implement the `myAtoi(string s)` function, which converts a string to a 32-bit signed integer. The function follows a specific algorithm to ignore leading whitespace, determine the sign, read digits, and handle integer overflow by clamping the result within the 32-bit signed integer range.
  [Problem Description](https://leetcode.com/problems/string-to-integer-atoi/description/)
* Day 75: Spotify Songs Album [Kaggle](https://www.kaggle.com/datasets/zeesolver/spotfy/data)
  * Today, we embark on a journey into the realm of music data analysis with a dataset sourced from Kaggle, focusing on Spotify songs albums. This dataset provides a comprehensive collection of information about various songs, including attributes such as danceability, energy, and acousticness. By delving into this dataset, we aim to uncover intriguing insights into the characteristics of popular songs, trends in music streaming, and the impact of different attributes on song popularity. Through exploratory data analysis and visualization techniques, we will unravel patterns, correlations, and unique features within the dataset, shedding light on the dynamic landscape of the music industry. Join us as we dissect this rich dataset to discover the rhythms and melodies that shape our musical experiences.
* Day 76: Bank Queue Management System
  * Today, we delve into the development of a robust bank queue management system designed for "Su ahorrito". This system aims to streamline the process of managing customer service operations, focusing on assigning and managing customer turns efficiently. Our system encompasses several key functionalities:
    - User Management: Create and manage user profiles, including user ID, name, and client type (General, Preferential1, Preferential2).
    - Turn Assignment: Automatically assign turns to users, categorizing each turn with a specific transaction type (Deposit, Withdrawal, Bill Payment).
    - Customer Service: Facilitate the process of attending to customers, ensuring that completed transactions are recorded and stored systematically.
    - Transaction Analysis: Calculate and display the percentage distribution of different transaction types, providing insights into customer needs and service trends.
    - Turn Management: Enable the removal of specific turns and display the number of turns assigned to each user.
    - Transaction History: Maintain and showcase a history of all completed transactions, ensuring transparency and record-keeping.
Through this project, we aim to enhance the efficiency of customer service in a banking environment by leveraging Python to build an intuitive and effective queue management system. Join us as we implement and explore this essential application, ensuring a smoother experience for both bank staff and customers.
* Day 77: Inventory Management GUI
Today, we embarked on the development of a Graphical User Interface (GUI) for an Inventory Management System. Leveraging the Flask web framework in Python, we crafted an intuitive interface that enables users to efficiently manage their inventory of products. The system offers a range of features to enhance inventory control and streamline operations, including:
  - **Product Management:** Users can easily add, edit, and delete products from the inventory, facilitating seamless product catalog management.
  - **Real-time Inventory Monitoring:** The application provides a comprehensive view of the current inventory status, allowing users to track product quantities and make informed decisions.
  - **Report Generation:** With built-in reporting capabilities, users can generate detailed reports on inventory status, product performance, and more, empowering data-driven decision-making.
  - **Low Stock Alerts:** The system automatically alerts users to products with low stock levels, helping prevent stockouts and optimize inventory replenishment.
  - **Data Export:** Users can export inventory data to CSV or Excel formats for further analysis or integration with external systems.

  By developing this Inventory Management GUI, we aimed to provide businesses with a powerful tool to effectively manage their inventory, improve efficiency, and optimize resource utilization. Join us as we continue to explore the intersection of technology and business operations, empowering organizations to thrive in today's dynamic marketplace. 📦💻📊
* Day 78: Technical Test "swapPairs" and "reverseKGroup" [LeetCode](https://leetcode.com/problems/).
  * swapPairs: Given a linked list, swap every two adjacent nodes and return its head. You must solve the problem without modifying the values in the list's nodes (i.e., only nodes themselves may be changed) [Problem Description](https://leetcode.com/problems/swap-nodes-in-pairs/description/)
  * reverseKGroup: Given the head of a linked list, reverse the nodes of the list k at a time, and return the modified list. k is a positive integer and is less than or equal to the length of the linked list. If the number of nodes is not a multiple of k, then the left-out nodes at the end should remain as they are. You may not alter the values in the list's nodes, only nodes themselves may be changed. [Problem Description](https://leetcode.com/problems/reverse-nodes-in-k-group/description/)
* Day 79: Minesweeper GUI Pygame
  * Today, we're diving into the development of a Minesweeper game with a Graphical User Interface (GUI) using Pygame. This classic game challenges players to uncover hidden mines on a grid-based board without detonating any of them. Our implementation leverages Pygame's intuitive interface to provide an engaging and immersive gaming experience. Players can reveal tiles, flag potential mines, and navigate through various difficulty levels or customize their game settings. Join us as we explore the world of game development with Python and Pygame, bringing the timeless excitement of Minesweeper to life in a modern and visually appealing format. 🕹️💣🎮
* Day 80: Student Practice Management System
  * Today, we developed a Python-based system to manage student internships. This system features:
    - **Practice Registration**: Capture student details, company name, and practice duration.
    - **Internship Tracking**: Monitor ongoing practices with detailed views.
    - **Average Duration Calculation**: Display the average length of internships.
    - **Company-Specific Intern Count**: Determine the number of interns per company.
    - **Company Update for Practices**: Modify the company associated with a student's practice.
    - **User-Friendly Menu Interface**: Easily navigate and interact with the system.

  This system aims to streamline the management of student internships, benefiting both students and administrators. 🎓🏢📊
* Day 81: Random Roulette
  * Today, we're building a Random Roulette web application using Flask. This app allows users to add and modify options for the roulette, and then spin to select a random option. With Flask's lightweight and flexible framework, we'll create an interactive and dynamic web interface where users can easily manage their options. The application features a simple design with an intuitive navigation system, ensuring a seamless user experience. Join us as we delve into web development with Flask, creating a fun and functional tool for making random selections. 🎡🔄✨
* Day 82: Test Projects "celsius_to_fahrenheit"
  * Today, we're focusing on writing unit tests for a simple function that converts temperatures from Celsius to Fahrenheit. Testing is a crucial part of software development, ensuring that our code works as expected and helps prevent bugs from creeping into our projects. We'll use Python's unittest module to create and run our tests. This exercise will help you understand the basics of writing tests and how to use them to verify the correctness of your code.
* Day 83: Technical Test "removeDuplicates" and "removeElement" [LeetCode](https://leetcode.com/problems/).
  * removeDuplicates: Given an integer array nums sorted in non-decreasing order, remove the duplicates in-place such that each unique element appears only once. The relative order of the elements should be kept the same. Then return the number of unique elements in nums. [Problem Description](https://leetcode.com/problems/remove-duplicates-from-sorted-array/description/)
  * removeElement: Given an integer array nums and an integer val, remove all occurrences of val in nums in-place. The order of the elements may be changed. Then return the number of elements in nums which are not equal to val. [Problem Description](https://leetcode.com/problems/remove-element/description/)
* Day 84: Complaint Management System
  * Today, we developed a Python-based system to manage complaints for the General Prosecutor's Office. This system features:
    - **Complaint Creation**: Record details such as complainant, accused, date, type, and unique code.
    - **Complaint Deletion**: Remove complaints using a unique code.
    - **Sublist Creation**: Generate a sublist of complaints involving a specific person.
    - **Type-Based Percentage Calculation**: Calculate the percentage of each type of complaint.
    - **Complaint Display**: Show all registered complaints.
    - **Date Modification**: Update the date of a specific complaint.
    - **User-Friendly Menu Interface**: Easily navigate and interact with the system.

  This system is designed to streamline the management of complaints, making it easier for the General Prosecutor's Office to handle and organize them effectively. 📅📝🔍
* Day 85: Convert Word Files To PDF [NeuralNine](https://www.youtube.com/watch?v=i57uYpW5Ng8)
  * Today, we worked on a project to convert Word files (.docx) to PDF format. This project was inspired by a video tutorial from NeuralNine. While the tutorial provided the basic functionality for converting a single DOCX file to PDF, we expanded the project by adding several new features:
    - **Graphical User Interface (GUI)**: Using `tkinter`, we created an intuitive interface that allows users to easily select files and specify output options.
    - **Single File Conversion**: Users can convert a single DOCX file to PDF by selecting the file and choosing a destination.
    - **Multiple File Conversion**: Users can select multiple DOCX files and convert them all to PDF at once, saving the converted files in a specified directory.
    - **Error Handling**: The application includes robust error handling to inform users of any issues during the conversion process.
    - **User Notifications**: After a successful conversion, the application provides a notification to the user.
    
  These enhancements make the tool more user-friendly and versatile, offering a complete solution for converting Word documents to PDF efficiently.

* Day 86: Goldner-Harary Graph in 3D
  * Today, we explored the fascinating world of graph theory by creating and visualizing the Goldner-Harary graph in 3D. This project helped us understand the properties of planar graphs and verify Euler's formula. Here are the key features and steps we implemented:
    - **Graph Construction**: We created the Goldner-Harary graph, which consists of 11 vertices and 27 edges.
    - **3D Visualization**: Using `matplotlib` and `networkx`, we plotted the graph in a 3D space, providing a comprehensive visual representation of its structure.
    - **Planarity Check**: We verified the graph's planarity, confirming that it can be drawn on a plane without any edges crossing.
    - **Euler's Formula Verification**: We checked Euler's formula (v - e + f = 2) for the graph, ensuring it holds true for planar graphs.
    - **Graph Information**: We displayed essential information about the graph, including the number of vertices, edges, and faces.
    
  This project not only enhanced our understanding of graph theory but also provided practical experience with 3D data visualization techniques. The Goldner-Harary graph, with its complex structure, served as an excellent example for studying planar graphs and their properties. 🌐📊🔍
* Day 87: Building Management System
  * Today, we developed a Python-based Building Management System. This system offers functionalities such as generating invoices, making payments, and tracking property ownership. Key features include:
    - **Invoice Generation**: Automatically generate monthly invoices for property owners.
    - **Payment Processing**: Record and manage payments made by proprietors.
    - **Account Statements**: Generate account statements for proprietors, detailing payments and dues.
    - **Delinquency Monitoring**: Identify delinquent apartments based on overdue balances.
    
  This system streamlines property management tasks, enhancing efficiency and organization. 🏢💼💰
* Day 88: Technical Test "strStr" and "divide" [LeetCode](https://leetcode.com/problems/).
  * strStr: Given two strings needle and haystack, return the index of the first occurrence of needle in haystack, or -1 if needle is not part of haystack. This classic problem tests your ability to efficiently search substrings within a larger string. [Problem Description](https://leetcode.com/problems/find-the-index-of-the-first-occurrence-in-a-string/description/)
  * divide: Given two integers, dividend and divisor, divide them without using multiplication, division, and mod operator. Ensure the result is truncated toward zero. This problem challenges you to implement efficient division using basic arithmetic operations. [Problem Description](https://leetcode.com/problems/divide-two-integers/description/)
* Day 89: Dragon Ball Radar Animation with DBSCAN Clustering
  * Today, we crafted an animated Dragon Ball radar using Python, leveraging DBSCAN clustering to detect clusters of Dragon Balls. Here's a breakdown of what we accomplished:
    - **Radar Animation**: We animated a radar line sweeping through 360 degrees, simulating the iconic Dragon Ball radar from the anime series.
    - **DBSCAN Clustering**: Utilizing the DBSCAN algorithm, we clustered randomly generated Dragon Ball positions, mimicking their distribution across the radar's range.
    - **Cluster Visualization**: Each cluster of Dragon Balls was represented by a yellow point on the radar, with the number of Dragon Balls in each cluster displayed alongside.
    - **Interactive Animation**: The animation included blinking points and text to add dynamism and visual appeal to the radar display.

  This project blends entertainment with data science, offering a playful yet educational exploration of clustering algorithms and animated visualizations. 🐉🔍✨
* Day 90: Pong Game Development in Python
  * Today, we developed a classic Pong game using Python and the Pygame library. Here's a summary of our progress:
    - **Game Mechanics**: We implemented the basic mechanics of Pong, including ball movement, paddle control, and collision detection.
    - **Scoring System**: A scoring system was added, with the game ending when a player reaches 5 points. The score is displayed on the screen, and a winning message is shown at the end.
    - **Paddle Customization**: The paddles were given distinct colors (red for the left paddle and blue for the right paddle) to enhance the visual appeal.
    - **Smooth Animation**: The game runs smoothly at 60 frames per second, providing a responsive and enjoyable gaming experience.

  This project demonstrates the fundamentals of game development in Python, showcasing the power and flexibility of Pygame for creating interactive applications. 🎮🚀✨
* Day 91: Flask-based Online Survey Application
  Today, we created a Flask-based Online Survey Application. This project allows users to create surveys and participate in them. Key functionalities include:

    - **Survey Creation**: Users can create new surveys with customizable options.
    - **Survey Participation**: Other users can vote in existing surveys.
    - **Results Display**: The application displays results for each survey, showing the distribution of votes.
    
  This project aims to provide a straightforward platform for conducting surveys online, enhancing user engagement and feedback collection. 📊🖥️✅
* Day 92: Tower of Hanoi and N Queens Problem Solutions
  * Today, we implemented solutions to the classic Tower of Hanoi and N Queens problems in Python. Here's a summary of our progress:
    - **Tower of Hanoi**: We developed a recursive function to solve the Tower of Hanoi problem, which involves moving disks from one peg to another according to specific rules. The function efficiently moves disks from the source peg to the target peg using an auxiliary peg.
    - **N Queens Problem**: We implemented a backtracking algorithm to solve the N Queens problem, which involves placing N queens on an NxN chessboard such that no queen attacks another. The algorithm ensures that each queen is placed safely by checking for conflicts with other queens in the same row, column, or diagonal.

  These projects demonstrate the power of Python for solving complex problems and the importance of recursion and backtracking in solving these types of problems. 🎯👑

* Day 93: Word Search Puzzle GUI
  * Today, we created a graphical user interface (GUI) for a word search puzzle using Python's Tkinter library. Here's an overview of what we accomplished:
    - **Word Entry**: We added an input field for users to enter words (comma-separated) which will be hidden in the word search grid.
    - **Grid Generation**: We implemented a function to generate a grid filled with random letters, ensuring that the words are placed in random directions (horizontal, vertical, diagonal).
    - **Word Selection**: We enabled cell selection in the grid. Selected cells highlight in yellow until a word is completely formed. If the word is valid, the cells change to green, indicating that the word has been found. If not, the cells revert to their original state.
    - **Word List Display**: The words are displayed on the right side of the interface. Found words are struck through.
    - **Timer**: We added a configurable timer (5 to 10 minutes) that counts down. If the user doesn't find all the words within the time limit, a message prompts them to try again.
    - **Solve Button**: A centrally placed "Solve" button highlights all the words in the grid, assisting the user in finding the words.
    - **Completion and Reset**: Upon finding all the words or the timer running out, the user is prompted to play again, allowing the game to reset.

  This project demonstrates the integration of Python with Tkinter to create interactive applications, enhancing user experience and interface design. 🧩🕹️

* Day 94: Technical Test "findSubstring" and "nextPermutation" [LeetCode](https://leetcode.com/problems/).
  * findSubstring: Given a string `s` and an array of strings `words`, find all starting indices of substring(s) in `s` that is a concatenation of each word in `words` exactly once and without any intervening characters. [Problem Description](https://leetcode.com/problems/substring-with-concatenation-of-all-words/description/)
  * nextPermutation: Implement the next permutation, which rearranges numbers into the lexicographically next greater permutation of numbers. If such an arrangement is not possible, it must rearrange it as the lowest possible order (i.e., sorted in ascending order). The replacement must be in place and use only constant extra memory. [Problem Description](https://leetcode.com/problems/next-permutation/description/)
* Day 95: PhishGuard - Anti-Phishing Email and Website Filter
  * Today, we developed a phishing protection filter called **PhishGuard** using Python. Here's an overview of what we accomplished:
    - **Keyword Detection**: Implemented a function to identify phishing keywords in email content.
    - **URL Analysis**: Extracted and analyzed URLs from emails, checking them against a list of known phishing domains.
    - **Email Filtering**: Created a filter to process a list of emails, blocking those identified as phishing attempts.
    - **Hotmail Example**: Tested the filter with example Hotmail emails to demonstrate its effectiveness.
      
  This project highlights how Python can be used to enhance email security by detecting and blocking potential phishing attacks. 🛡️📧
* Day 96: World Clock GUI
  * Today, we developed a **World Clock GUI** using Python and Tkinter. Here's an overview of what we accomplished:
    - **Time Zone Updates**: Implemented a function to update and display the current time for multiple time zones including Colombia, New York, China, Germany, and Norway.
    - **GUI Design**: Created a user-friendly graphical interface with labeled clocks for each time zone, enhancing the visual appeal and usability.
    - **Icon and Flags**: Added an application icon and country flags to represent each time zone, providing a clear and engaging visual representation.
    - **Dynamic Updates**: Ensured the clock times are updated dynamically every second, keeping the displayed times accurate.

  This project showcases how Python can be used to create a functional and visually appealing world clock application. 🕒🌍
* Day 97: Pipelines for inference [🤗 Transformers](https://huggingface.co/docs/transformers/pipeline_tutorial)
  * Today, I explored the powerful pipeline feature from the Hugging Face Transformers library to perform automatic speech recognition (ASR) and text generation tasks. Here's a summary of what I accomplished:
    - **Automatic Speech Recognition**: Utilized the `pipeline()` function for ASR to transcribe audio files into text. Implemented and tested the OpenAI Whisper model for improved accuracy.
    - **Batch Processing**: Leveraged batch processing to handle multiple audio files efficiently, enhancing the pipeline's performance on a GPU.
    - **Task-Specific Parameters**: Experimented with parameters such as `return_timestamps` for subtitling and `chunk_length_s` for processing long audio files, demonstrating the flexibility of the pipeline.
    - **Device Management**: Configured the pipeline to run on the appropriate device (CPU or GPU) based on availability, optimizing computational resources.
    - **Dataset Integration**: Integrated the pipeline with datasets to perform inference on large datasets, showing the capability of the pipeline to handle extensive data inputs seamlessly.

  This project highlights the versatility and ease of using Hugging Face's pipeline feature for various NLP and ASR tasks, showcasing the practical applications of machine learning models in real-world scenarios.
* Day 98: Vehicle Management System
  * Today, I developed a Vehicle Management System to help the Universidad de Envigado manage the vehicles that enter and exit the campus. The system identifies each vehicle by its license plate and entry date. Here's a summary of what I accomplished:
    - **Vehicle Entry**: Implemented functionality to add a vehicle to the active vehicles list and log its entry time.
    - **Vehicle Exit**: Created a method to remove a vehicle from the active list and log its exit in the history.
    - **Date-Specific Entry Count**: Added a feature to determine the number of vehicles that entered the campus on a specific date.
    - **Entry Count by Vehicle**: Developed a function to list the number of times a specific vehicle has entered the campus.
    - **User-Friendly Menu**: Designed an interactive menu for users to manage vehicle entries and exits, check vehicle counts, and handle inputs gracefully, including validation for empty inputs.

  This project showcases the application of object-oriented programming principles to solve real-world problems, providing an efficient solution for managing campus vehicle traffic. The user-friendly interface ensures ease of use, while robust input validation enhances reliability.
* Day 99: 🌬️ Asthma Disease Dataset 🌬️ [Kaggle](https://www.kaggle.com/datasets/rabieelkharoua/asthma-disease-dataset/data)
  * Today, I worked with the Asthma Disease Dataset from Kaggle, aiming to analyze and model the factors contributing to asthma diagnosis. Here's a summary of what I accomplished:
    - **Data Exploration and Cleaning**: Conducted an initial exploration of the dataset to understand its structure and identify missing values. Cleaned the data by handling missing values and irrelevant columns.
    - **Feature Analysis**: Performed an exploratory data analysis (EDA) to visualize distributions of numerical features, correlations, and demographic insights. Created plots to understand the relationships between various factors and asthma diagnosis.
    - **Descriptive Statistics**: Calculated and interpreted key statistics for age distribution, gender, ethnicity, and education level among diagnosed and non-diagnosed patients.
    - **Pie Charts and Histograms**: Generated pie charts for categorical variables like ethnicity, gender, and education level. Plotted histograms for age distribution of diagnosed patients to identify trends.
    - **Correlation Heatmap**: Created a heatmap to visualize correlations between numerical features, helping to identify significant relationships.
    - **Model Training and Evaluation**: Developed and evaluated several machine learning models, including Logistic Regression, Random Forest, Gradient Boosting, Support Vector Machine, XGBoost, and K-Nearest Neighbors. Assessed model performance using accuracy and ROC AUC scores.
    - **Scaling and Splitting Data**: Preprocessed the data by scaling features and splitting it into training and testing sets to ensure robust model evaluation.

  This project highlights the importance of data preprocessing, exploratory analysis, and model evaluation in the context of medical data. The insights and models developed can help in understanding the factors influencing asthma diagnosis and potentially aid in early detection and prevention strategies.
* Day 100: 🎮 2048 Game with Flask 🎮

  * Today, I created a web-based 2048 game using Flask. The project involved building the game logic, setting up a server, and creating a responsive user interface. Here's a summary of what I accomplished:
    - **Flask Application Setup**: Initialized a Flask application to handle game logic and API endpoints. Defined routes for starting a new game, making moves, and autoplay functionality.
    - **Game Logic Implementation**: Developed functions to initialize the game board, add new tiles, and perform moves in all directions (left, right, up, down). Ensured that the game logic correctly merges tiles and adds new ones after each move.
    - **Autoplay Feature**: Implemented an autoplay feature that simulates moves automatically until the game ends. This feature helps demonstrate the game mechanics and provides a way to observe strategies for achieving higher scores.
    - **Game Over Check**: Added functionality to detect when the game is over, offering the option to restart the game and encouraging continuous play.
    - **User Interface Design**: Created a responsive UI using HTML and CSS, ensuring the game board is centered and visually appealing. Applied a dark background for better visibility and user experience.
    - **Styling with CSS**: Separated CSS into an external file, focusing on clean design and readability. Styled the board and cells to clearly display game states and centered numbers within their cells.
    - **JavaScript Integration**: Moved JavaScript code to an external file for better organization. Handled user input for moves, board rendering, and autoplay functionality.
    - **Restart Option**: Added a restart button to allow users to start a new game when the current game ends.
    - **Enhanced User Experience**: Improved the overall user experience by ensuring smooth interactions, clear game states, and responsive design elements.

  This project demonstrates the integration of front-end and back-end technologies to create an interactive web application. It highlights the importance of clean code organization, user-centric design, and robust game logic implementation. The 2048 game serves as a fun and engaging way to explore web development with Flask.

* Day 101: Technical Test "longestValidParentheses" and "search" [LeetCode](https://leetcode.com/problems/).
  * longestValidParentheses: Given a string containing just the characters '(' and ')', find the length of the longest valid (well-formed) parentheses substring. [Problem Description](https://leetcode.com/problems/longest-valid-parentheses/description/)
  * search: Given an array of integers `nums` sorted in ascending order, which is possibly rotated at an unknown pivot, and an integer `target`, find the index of `target` in `nums` or return -1 if it is not in `nums`. The algorithm must run in O(log n) time complexity. [Problem Description](https://leetcode.com/problems/search-in-rotated-sorted-array/description/)

* Day 102: 🍦 Object-Oriented Programming in Python with Ice Cream Example 🍦

  * Today, I explored the fundamentals of Object-Oriented Programming (OOP) in Python using a fun and relatable example: an ice cream shop. This project highlights the six basic principles of OOP—inheritance, cohesion, abstraction, polymorphism, coupling, and encapsulation. Here's a summary of what I accomplished:

    - **Abstraction and Encapsulation**: Created an abstract base class `IceCream` to represent the common attributes and behaviors of all ice creams. Encapsulated the flavor and price attributes to protect them from direct modification.
    - **Inheritance**: Developed two subclasses, `ScoopIceCream` and `Sundae`, inheriting from the `IceCream` class. These subclasses extend the base class by adding specific attributes like the number of scoops and toppings.
    - **Polymorphism**: Implemented a function `print_ice_cream_details` that takes any `IceCream` object and prints its details. This demonstrates how different ice cream objects can be handled through a single interface.
    - **Cohesion**: Ensured each class has a single, well-defined responsibility. For example, `ScoopIceCream` handles the specifics of scoop-based ice cream, while `Sundae` manages sundae-specific attributes.
    - **Coupling**: Maintained loose coupling between classes to ensure that changes in one class minimally affect others. This was achieved through well-defined interfaces and clear separation of responsibilities.
    - **Encapsulation**: Used private attributes to encapsulate the internal state of the objects, providing getter methods to access the values.
* Day 103: [TensorFlow](https://www.tensorflow.org/tutorials/keras/text_classification_with_hub) Text classification with TF Hub

  * Today, I explored text classification using TensorFlow Hub and TensorFlow Datasets. This project focused on building a neural network model to classify movie reviews as positive or negative. Here's a summary of what I accomplished:

    - **Data Loading and Preparation**: Utilized TensorFlow Datasets to download and prepare the IMDB dataset, splitting it into training, validation, and test sets.
    - **Exploration**: Examined the dataset to understand its structure and content. Each example in the dataset consists of a movie review (text) and a corresponding label (0 for negative, 1 for positive).
    - **Text Embedding**: Leveraged a pre-trained text embedding from TensorFlow Hub to convert sentences into embedding vectors. This approach simplifies text preprocessing, benefits from transfer learning, and provides a fixed-size output.
    - **Model Building**: Constructed a neural network model using Keras Sequential API. The model includes:
      - A TensorFlow Hub layer for text embedding.
      - A Dense layer with 16 hidden units and ReLU activation.
      - A Dense output layer with a single unit for binary classification.
    - **Loss Function and Optimizer**: Configured the model with the `binary_crossentropy` loss function and the Adam optimizer. This setup is suitable for binary classification tasks.
    - **Model Training**: Trained the model for 10 epochs using mini-batches of 512 samples, monitoring the loss and accuracy on the validation set.
    - **Model Evaluation**: Evaluated the model on the test set to measure its performance, reporting both loss and accuracy.

  This project demonstrates the application of TensorFlow and TensorFlow Hub for natural language processing tasks. It highlights the importance of using pre-trained models for efficient text embedding and the benefits of a well-structured neural network for text classification.
* Day 104: Battleship Game with Flask
  * Today, I developed a Battleship game using Flask, a micro web framework for Python. This project involved creating a web-based version of the classic Battleship game, where users can guess the locations of ships on a grid. Here's a summary of what I accomplished:

    - **Setting Up Flask Application**: Initialized a Flask project, set up routes, and managed sessions to maintain game state between requests.
    - **Game Logic Implementation**: Implemented the core game logic in Python, including functions for creating ships, processing user guesses, and checking for game over conditions.
    - **Session Management**: Utilized Flask sessions to store the hidden and guess boards, ensuring the game state is preserved between user interactions.
    - **User Interface**: Developed HTML templates using Jinja2 to render the game board and provide a user-friendly interface. Included labels for rows and columns to guide the user.
    - **Game Mechanics**: Added functionality to handle user guesses, update the game board, and provide feedback on hits and misses. Also implemented logic to reveal ship locations if the user runs out of turns.

  This project showcases how to build a simple yet interactive web application with Flask. It emphasizes the importance of session management in web applications and demonstrates how to create a dynamic user interface with Jinja2 templates. Additionally, it illustrates the implementation of classic game mechanics in a web-based environment.

* Day 105: Technical Test "searchRange" and "searchInsert" [LeetCode](https://leetcode.com/problems/).

  - **searchRange**: Given an array of integers `nums` sorted in non-decreasing order, find the starting and ending position of a given target value. If the target is not found in the array, return [-1, -1]. The algorithm must run in O(log n) time complexity.
  [Problem Description](https://leetcode.com/problems/find-first-and-last-position-of-element-in-sorted-array/description/)
    
  - **searchInsert**: Given a sorted array of distinct integers and a target value, return the index if the target is found. If not, return the index where it would be if it were inserted in order. The algorithm must run in O(log n) time complexity. [Problem Description](https://leetcode.com/problems/search-insert-position/description/)
* Day 106: Create a Multipage App with Streamlit [Streamlit Tutorial](https://docs.streamlit.io/get-started/tutorials/create-a-multipage-app)
  * Today, I focused on building a multipage web application using Streamlit, a popular open-source app framework for Machine Learning and Data Science projects. This project involved creating a web application that can navigate between different pages, each displaying unique content or functionality. Here's a summary of what I accomplished:

    - **Setting Up Streamlit Environment**: Installed Streamlit and set up the development environment.
    - **Creating Pages**: Developed multiple pages for the application, each serving a distinct purpose. For example, a home page, a data visualization page, and a user input page.
    - **Navigation Implementation**: Implemented a navigation system to switch between different pages. Used Streamlit’s built-in components to create a user-friendly interface for navigation.
    - **Dynamic Content**: Ensured each page displays dynamic content based on user interactions. For instance, visualizations that update based on user input or data selections.
    - **User Interface Design**: Designed the layout and style of the application to make it intuitive and visually appealing. Leveraged Streamlit’s layout options and widgets to enhance the user experience.

  This project showcases the versatility of Streamlit in creating interactive and multipage web applications. It emphasizes the ease of setting up a multi-page structure and the ability to integrate dynamic content seamlessly. This was an excellent exercise in web development and user interface design, demonstrating how to build comprehensive applications using Streamlit.
* Day 107: Twenty One Card Game GUI
  * Today, I developed a Twenty-One card game (similar to Blackjack) in Python. This project involved creating the core game logic, displaying cards, handling user interactions, and implementing the rules of the game. Here's a summary of what I accomplished:

    - **Card Display Function**: Created a function to display cards in a visually appealing format using ASCII art. This function helps players see their cards and the dealer's cards clearly.
    - **Random Card Generation**: Implemented a function to generate random cards, ensuring a mix of suits and values for each game.
    - **Card Value Calculation**: Developed a function to calculate the value of each card, considering the special case for Aces, which can be worth either 1 or 11 points.
    - **Game Logic**: Implemented the main game loop, handling the player's turn and the dealer's turn, including decision-making processes and win/lose conditions.
    - **User Interaction**: Added functionality for user input to decide whether to continue playing or stop, and to determine if the player wants to try again after a game ends.

  This project demonstrates the implementation of a classic card game using Python, focusing on interactive gameplay and dynamic card management. It emphasizes the importance of user-friendly design and accurate game mechanics.
* Day 108: Character-Level Language Model with RNN
  * Today, I developed a simple character-level language model using Recurrent Neural Networks (RNN) with TensorFlow and Keras. This project involved creating a model to predict the next character in a sequence of text. Here's a summary of what I accomplished:

    - **Text Preparation**: Prepared the input text by creating mappings from characters to indices and vice versa. Split the text into sequences for training.
    - **Dataset Creation**: Generated training data by creating overlapping sequences of characters and the corresponding next character to predict.
    - **Model Building**: Constructed an RNN model using Keras. The model includes:
      - An Embedding layer to learn character embeddings.
      - A SimpleRNN layer to capture sequential dependencies.
      - A Dense output layer with softmax activation to predict the next character.
    - **Model Compilation**: Compiled the model using categorical cross-entropy loss and the Adam optimizer.
    - **Model Training**: Trained the model on the prepared dataset, using a batch size of 2 and running for 100 epochs.
    - **Prediction Function**: Implemented a function to predict the next character given a sequence of characters. This function uses the trained model to generate predictions.

  This project showcases the process of building a character-level language model using RNNs. It emphasizes the importance of text preprocessing, sequence generation, and model training for sequential data tasks. The model is capable of predicting the next character in a sequence, demonstrating the potential of RNNs in natural language processing.
* Day 109: PolarsVSPandas (Polars Is The Faster Pandas) [NeuralNine](https://www.youtube.com/watch?v=zthI91ASV58)
  * Today, I explored the performance differences between Pandas and Polars for data manipulation tasks. This project was inspired by NeuralNine's video on Polars being faster than Pandas. Here's a summary of what I accomplished:

    - **Data Preparation**: Created a dataset with 120,000 rows of random data using NumPy.
    - **DataFrame Creation**: Generated DataFrames using both Pandas and Polars to compare their performance.
    - **Reading Data**: Measured the time taken to read the data into Pandas and Polars DataFrames.
    - **Aggregation**: Performed aggregation operations to calculate the mean of column 'B' and the sum of column 'C' grouped by column 'A'.
    - **Filtering**: Filtered the data to include only rows where column 'A' is greater than 50.
    - **Joining**: Conducted join operations to merge two DataFrames on column 'A'.
    - **Conditional Column Addition**: Added a new column to a DataFrame based on a condition using both Pandas and Polars.

  This project demonstrates the significant performance improvements that Polars offers over Pandas for certain data manipulation tasks. It highlights the importance of choosing the right tools for data processing to achieve efficient and scalable solutions. Special thanks to NeuralNine for the step-by-step guide provided in his video.

* Day 110: Technical Test "isValidSudoku" and "solveSudoku" [LeetCode](https://leetcode.com/problems/).

  - **isValidSudoku**: Determine if a 9 x 9 Sudoku board is valid. Only the filled cells need to be validated according to the following rules:
    - Each row must contain the digits 1-9 without repetition.
    - Each column must contain the digits 1-9 without repetition.
    - Each of the nine 3 x 3 sub-boxes of the grid must contain the digits 1-9 without repetition.
    Note:
    - A Sudoku board (partially filled) could be valid but is not necessarily solvable.
    - Only the filled cells need to be validated according to the mentioned rules.
    [Problem Description](https://leetcode.com/problems/valid-sudoku/description/)
    
  - **solveSudoku**: Write a program to solve a Sudoku puzzle by filling the empty cells. A sudoku solution must satisfy all of the following rules:
    - Each of the digits 1-9 must occur exactly once in each row.
    - Each of the digits 1-9 must occur exactly once in each column.
    - Each of the digits 1-9 must occur exactly once in each of the nine 3x3 sub-boxes of the grid.
    The '.' character indicates empty cells.
    [Problem Description](https://leetcode.com/problems/sudoku-solver/description/)
* Day 111: Library Management System

  - Today, I developed a Flask-based system for managing books, members, loans, and returns in a library setting. Data storage is handled using JSON files.
    - **Features**:
      - **Books Management**: Add, view, and list books.
      - **Members Management**: Add and list members.
      - **Loans Management**: Loan and return books with member associations.
    - **Technologies**: Flask, JSON, HTML/CSS.
    - **Project Structure**:
      - **app.py**: Flask application handling routes and data operations.
      - **templates/**: HTML templates for rendering pages.
      - **static/**: CSS styles for frontend.
    - **Future Enhancements**: Implement editing and deletion functionalities for books and members, search functionality, and user authentication.
* Day 112: Maze Generator and Solver
  - **Maze Generator**: Implemented a recursive maze generator using the turtle graphics library in Python. The maze is generated by moving the turtle to adjacent cells based on the least visited neighbors.
  - **Maze Solver**: Developed a recursive solver to find the path from the start to the end of the maze. The path is drawn using a different color to indicate the solution.

  This project showcases the use of recursive algorithms for generating and solving mazes, highlighting the power of Python's turtle graphics library for visualizing the process.
* Day 113: Basketball Scoreboard in Flask

  - **Basketball Scoreboard**: Created a web application using Flask to simulate a basketball scoreboard. The scoreboard allows users to input the names of the home and away teams, track scores (1-point, 2-point, and 3-point baskets), fouls, and display the current quarter or overtime. The game progresses through regular quarters, halftime, and overtime periods as needed, with a final winner determined based on scores.

  This project demonstrates the use of Flask for web development and real-time updating of game states, showcasing interactive elements like score tracking, foul recording, and game progression logic.
* Day 114: Internet Speed Test Application

  - **Internet Speed Test Application**: Developed a desktop application using Tkinter to measure internet speed. The application tests the download and upload speed as well as the ping of the user's internet connection. Results are displayed in the application window in real-time.

    - **Speed Test**: Utilized the Speedtest library to measure download and upload speeds in Mbps, and ping in milliseconds. The results are displayed in a user-friendly format.
    - **User Interface**: Designed a simple and intuitive GUI using Tkinter, with buttons to start the speed test, display information about the application, and exit the program.
    - **Information Dialog**: Added an information dialog box to provide users with details about the application's functionality.

  This project demonstrates the use of Tkinter for building desktop applications and integrating third-party libraries to perform real-time internet speed tests.
* Day 115: Steganography Application using Flask

  - **Steganography Application**: Developed a web application using Flask to hide and reveal secret messages within images using the Stegano library. This project involved creating a user-friendly interface for uploading images and entering messages to hide or reveal.

    - **Hide Message**: Implemented functionality to allow users to upload an image and input a message, which is then hidden within the image using the LSB (Least Significant Bit) method provided by the Stegano library. The resulting image is saved and displayed to the user.
    - **Reveal Message**: Added functionality to upload an image and extract any hidden message from it. The extracted message, if any, is displayed to the user along with the image.
    - **User Interface**: Designed a clean and intuitive web interface with routes for hiding and revealing messages, ensuring ease of use and smooth user experience.

    This project demonstrates the use of Flask for building web applications, integrating third-party libraries for steganography, and handling file uploads and processing.
* Day 116: Technical Test "countAndSay" and "combinationSum" [LeetCode](https://leetcode.com/problems/).

  - **countAndSay**: Generate the nth term in the count-and-say sequence. The count-and-say sequence is a sequence of digit strings defined by the recursive formula:
    - countAndSay(1) = "1"
    - countAndSay(n) is the run-length encoding of countAndSay(n - 1).
    
    For example, to compress the string "3322251" using run-length encoding, replace "33" with "23", replace "222" with "32", replace "5" with "15" and replace "1" with "11". Thus the compressed string becomes "23321511".
    [Problem Description](https://leetcode.com/problems/count-and-say/description/)

  - **combinationSum**: Return a list of all unique combinations of candidates where the chosen numbers sum to a given target. Each number in candidates may be used an unlimited number of times in the combination. Two combinations are unique if the frequency of at least one of the chosen numbers is different.

    Given an array of distinct integers `candidates` and a target integer `target`, this problem finds all unique combinations of candidates that sum to the target. The test cases are generated such that the number of unique combinations that sum up to the target is less than 150 combinations for the given input.
    [Problem Description](https://leetcode.com/problems/combination-sum/description/)
* Day 117: Recursion "BinaryTreeExpressionEvaluator"
  * This project defines a binary tree where each node can be a numeric value or an operator. It evaluates the expression represented by the binary tree using recursion. The supported operations are addition, subtraction, multiplication, division, and exponentiation.
  
  - **TreeNode Class**: A class that represents a node in the binary tree.
    - `value`: The value of the node, which can be an integer (leaf node) or an operator (internal node).
    - `left`: The left child node.
    - `right`: The right child node.
  
  - **evaluate_tree Function**: A function that evaluates the binary tree to compute the result of the expression it represents.
    - It takes the root node of the binary tree as an argument.
    - It returns the result of the expression as an integer or float.
    - It raises a `ValueError` if there is an attempt to divide by zero.
  
  - **Example Usage**: The project includes an example usage of creating a binary tree for the expression `((3 + 2) * (4 - 1)) ^ 2` and evaluating it to get the result.

  This project showcases the power of recursion in evaluating complex expressions represented by binary trees, highlighting the versatility of binary trees in computational problems.
* Day 118: Shirt Store
  * Implemented a Python application for managing a shirt store using object-oriented programming concepts. The application allows users to add shirts to the store's inventory, manage customer interactions including adding to cart and purchasing, and view store and customer details.
* Day 119: Household Basket
  - **Household Basket Application**: Developed a desktop application using Tkinter to manage household items in a basket, including fruits, vegetables, meat, dairy, and other categories. The application connects to an SQLite database to store and manage the items.

    - **Add Item**: Implemented functionality to add items to the household basket. Users can select a category, enter the name and quantity of the item, and add it to the database. Validation ensures proper input for name and quantity fields.
    - **View Items**: Added a treeview to display all items in the household basket. Users can see the item ID, category, name, and quantity.
    - **Delete Item**: Included functionality to delete selected items from the basket. Users can select an item from the treeview and remove it from the database with a single click.
    - **Database Management**: Utilized SQLite to create a persistent storage solution for the household basket items. Functions were developed to create the table, insert items, retrieve items, and delete items from the database.
    - **User Interface**: Designed a user-friendly and responsive interface with Tkinter, ensuring a smooth user experience. The interface includes input fields, buttons, and a treeview to manage and display items effectively.
* Day 120: Copa America 2024 Groups [Dataset](https://en.wikipedia.org/wiki/2024_Copa_Am%C3%A9rica)
  - **Copa America 2024 Groups**: Developed a Python script to scrape and process data from the Wikipedia page for the 2024 Copa América, extracting the group stage tables and organizing them into a dictionary for easy access and manipulation.
    - **Data Scraping**: Used the `pandas` library to read all tables from the Wikipedia page, focusing on the relevant indices to extract the tables for Groups A to D.
    - **Data Processing**: Renamed the second column of each table to "Team" and removed the "Qualification" column for cleaner data representation.
    - **Data Organization**: Stored the processed tables in a dictionary, with group letters as keys for easy retrieval and display.
    - **Data Persistence**: Saved the dictionary to a file using the `pickle` library for persistent storage and later use.
* Day 121: Technical Test "combinationSum2" and "firstMissingPositive" [LeetCode](https://leetcode.com/problems/).
  - **combinationSum2**: Find all unique combinations in candidates where the candidate numbers sum to target. Each number in candidates may only be used once in the combination, and the solution set must not contain duplicate combinations. This problem involves using a backtracking approach to explore all possible combinations, ensuring that no duplicates are included in the result set. [Problem Description](https://leetcode.com/problems/combination-sum-ii/description/)

  - **firstMissingPositive**: Return the smallest positive integer that is not present in an unsorted integer array `nums`. The algorithm must run in O(n) time and use O(1) auxiliary space. The solution involves rearranging the array so that each positive integer `n` is placed at index `n-1`. Then, the first index that does not contain the correct integer indicates the missing positive integer. [Problem Description](https://leetcode.com/problems/first-missing-positive/description/)
* Day 122: Recursion "Knapsack"

  * This project tackles the Knapsack problem using both recursive and dynamic programming approaches. The Knapsack problem is a classic algorithmic problem that involves selecting items with given weights and values to maximize the total value without exceeding the weight capacity.

  - **knapsack_recursive Function**: A recursive function to solve the Knapsack problem.
    - `weights`: A list of weights of the items.
    - `values`: A list of values of the items.
    - `W`: The maximum weight capacity of the knapsack.
    - `n`: The number of items.
    - This function returns the maximum value that can be obtained by including or excluding the nth item.
    - Base cases include no items left or a knapsack capacity of 0. The function chooses the maximum value between including and not including the nth item.

  - **knapsack_dynamic Function**: A dynamic programming function to solve the Knapsack problem.
    - `weights`: A list of weights of the items.
    - `values`: A list of values of the items.
    - `W`: The maximum weight capacity of the knapsack.
    - This function returns the maximum value that can be obtained using a bottom-up approach to build a table `dp` where `dp[i][w]` represents the maximum value that can be obtained with the first `i` items and a knapsack capacity of `w`.
    - The function iterates over the items and capacities, filling the table based on whether the item is included or not.

  - **Example Usage**: The project includes an example with weights `[1, 2, 3, 4]`, values `[10, 20, 30, 40]`, and a knapsack capacity `W = 5`. It demonstrates the maximum value calculation using both recursive and dynamic programming approaches.
* Day 123: [TLC Trip Record Data](https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page)
  - **NYC Taxi Data Analysis**: Developed a data analysis project using PySpark and Pandas to process and visualize the NYC Yellow Taxi Trip data. This project involved extensive data cleaning, transformation, and visualization to uncover patterns and insights from the dataset.

    - **Data Cleaning and Transformation**: Utilized PySpark for efficient handling of large datasets. Performed data cleaning steps such as filtering out invalid data, handling missing values, and creating new columns for analysis.
      - **Trip Duration Calculation**: Calculated trip duration from pickup and dropoff timestamps and added it as a new column.
      - **Sampling**: Extracted a sample of the data to facilitate visualization and analysis in Pandas.

    - **Data Visualization**: Converted the cleaned data to a Pandas DataFrame for visualization using Seaborn and Matplotlib.
      - **Distribution of Trip Durations**: Plotted a histogram to show the distribution of trip durations.
      - **Trips per Hour**: Visualized the number of trips per hour to identify peak times for taxi rides.
      - **Trip Distance vs Fare Amount**: Created scatter plots to explore the relationship between trip distance and fare amount.
      - **Heatmaps of Pickup and Dropoff Locations**: Generated heatmaps to show the frequency of pickups and dropoffs by location ID.
      - **Passenger Count Distribution**: Displayed the distribution of the number of passengers per trip.
      - **Payment Type Distribution**: Visualized the distribution of different payment types used in the trips.
      - **Total Amount vs Tip Amount**: Plotted the relationship between the total fare amount and the tip amount.

  This project demonstrates the use of PySpark for big data processing and Pandas/Seaborn for detailed data visualization, providing insights into the NYC taxi operations and passenger behaviors.
* Day 124: 🏫 Object-Oriented Programming in Python with University Enrollment System 🏫

  * Today, I worked on a university enrollment system project to reinforce the principles of Object-Oriented Programming (OOP) in Python. This project incorporates key OOP concepts such as inheritance, encapsulation, and abstraction. Here's a summary of what I accomplished:

    - **Abstraction and Encapsulation**: Created an abstract base class `Person` to represent common attributes and behaviors for both students and teachers. Encapsulated the name and ID number attributes to protect them from direct modification. Implemented abstract methods to enforce a consistent interface for subclasses.
    - **Inheritance**: Developed two subclasses, `Student` and `Teacher`, inheriting from the `Person` class. These subclasses extend the base class by adding specific attributes and methods like enrolling in courses and assigning courses.
    - **Course Management**: Created a `Course` class to represent a university course, including attributes for course name, credits, teacher, and maximum number of students. Added methods to handle student enrollment, calculate total students, and determine the cost per student.
    - **User Interaction**: Implemented a menu-driven interface to allow users to enroll students in courses, display student details, and show course information. This interactive component showcases how OOP can be used to structure complex, real-world applications.
    - **Data Storage**: Used dictionaries to manage and store student instances, demonstrating the practical use of data structures in conjunction with OOP to handle multiple objects efficiently.

  This project provided a comprehensive exercise in applying OOP principles to a realistic scenario, reinforcing the importance of well-structured, maintainable, and scalable code.
* Day 125: Technical Test "trap" and "multiply" [LeetCode](https://leetcode.com/problems/).
  - **trap**: Given n non-negative integers representing an elevation map where the width of each bar is 1, compute how much water it can trap after raining. This problem involves using a two-pointer approach to traverse the elevation map and calculate the trapped water by comparing the heights of bars. It requires understanding how to efficiently track the maximum heights from both ends of the array to determine the water level at each position. [Problem Description](https://leetcode.com/problems/trapping-rain-water/description/)

  - **multiply**: Given two non-negative integers `num1` and `num2` represented as strings, return the product of `num1` and `num2`, also represented as a string. The solution must not use any built-in BigInteger library or convert the inputs to integers directly. This problem requires implementing a manual multiplication algorithm similar to the one learned in school, handling digit-by-digit multiplication, and managing carry-over between digits. [Problem Description](https://leetcode.com/problems/multiply-strings/description/)
* Day 126: Basketball Ground Using Turtle
  * Created a visual representation of a basketball court using the Turtle graphics library in Python. This project involves drawing a complete basketball court with various elements like the court boundaries, center circle, and basket areas.

  - **Drawing the Court**: Utilized Turtle graphics to draw the court boundaries, including the outer lines and the rectangular playing area.
  - **Center Circle and Baskets**: Implemented functions to draw the center circle and the areas around the baskets, including the semi-circles and rectangles that represent the key areas on the court.
  - **Colors and Aesthetics**: Used different colors and fill patterns to differentiate various parts of the court, enhancing the visual appeal and clarity of the representation.

  This project showcases the capabilities of the Turtle graphics library for creating detailed and visually appealing graphics. It also emphasizes the importance of geometric calculations and the use of loops and functions to create complex shapes and patterns.

  The code for this project was adapted from an example on GeekforGeeks: [Create a Basketball Ground Using Turtle Library in Python](https://www.geeksforgeeks.org/create-a-basketball-ground-using-turtle-library-in-python/).
* Day 127: Employee Hours
  - **Employee Hours Management System**: Developed a web application using Flask and SQLite to manage and track employee working hours. This project includes functionalities for user authentication, logging working hours, editing logged hours, and visualizing the weekly work schedule.

    - **User Authentication**: Implemented login and registration features to ensure secure access to the application.
      - **Login**: Users can log in with their username and password. If credentials are invalid, an error message is displayed.
      - **Registration**: New users can register by providing a username and password. The registration page is linked from the login page.

    - **Logging Working Hours**: Provided functionality to log working hours with task details.
      - **Form Validation**: Ensured that logged hours are within weekdays (Monday to Friday) and between 06:00 and 23:00. If the user tries to log hours outside these constraints, an error message is displayed.

    - **Editing Logged Hours**: Allowed users to edit previously logged hours.
      - **Task and Start Time Modification**: Users can update the task description and the start time of logged hours, with the same validation constraints as logging new hours.

    - **Data Visualization**: Displayed the logged hours in a tabular format showing the weekly schedule.
      - **Weekly Schedule Table**: Organized logged hours by day and time, highlighting the tasks performed.
      - **Total Hours Calculation**: Summed up the total hours worked in a week and displayed it. If total hours exceed 42, the overtime hours are also shown.

    - **Database Management**: Used SQLite to store user credentials and logged hours.
      - **Database Initialization**: Created tables for users and logged hours if they do not exist.

    - **Additional Features**:
      - **Clear Hours**: Added a button to clear all logged hours for the next week, ensuring a fresh start.
      - **Responsive Design**: Implemented a professional CSS for a better user experience and user interface.

    This project demonstrates the use of Flask for web development, SQLite for database management, and JavaScript for client-side validation. It provides a comprehensive solution for managing and tracking employee working hours, ensuring data integrity and user-friendliness.
* Day 128: Recursion "Letter Combinations"

  * This project focuses on solving the "Letter Combinations of a Phone Number" problem using recursion. Given a string containing digits from 2-9 inclusive, the goal is to return all possible letter combinations that the number could represent. The mapping of digits to letters is based on the traditional telephone keypad.

  - **letter_combinations Function**: A recursive function to find all possible letter combinations for a given phone number.
    - `digits`: A string containing the digits from 2-9.
    - This function returns a list of all possible letter combinations.
    - The function uses a helper function `backtrack` to perform backtracking and explore all possible combinations.
    - The `phone_map` dictionary maps each digit to its corresponding letters.
    - The `backtrack` function iterates over all letters that map to the next available digit, appending the current letter to the combination and proceeding with the next digit until all digits are processed.
* Day 129: Pneumonia Detection Using Deep Learning

  - **Pneumonia Detection System**: Developed a deep learning model to detect pneumonia from chest X-ray images. This project includes data wrangling, model training, and evaluation using TensorFlow.

    - **Data Collection and Preparation**: 
      - **Dataset**: Utilized a dataset from Kaggle containing chest X-ray images categorized as "NORMAL" or "PNEUMONIA".
      - **Pathlib for File Handling**: Separated the dataset into training, validation, and test sets using Pathlib.
      - **Data Wrangling**: Generated labels for the images based on their directory names.

    - **Model Development**: 
      - **Data Preprocessing**: Implemented functions to load, transform, and create TensorFlow datasets from the image paths and labels.
      - **Model Architecture**: Used ResNet50V2 as the backbone for the CNN model, followed by GlobalAveragePooling2D and Dense layers with a sigmoid activation function.
      - **Regularization Techniques**: Added dropout and L2 regularization to improve model generalization and prevent overfitting.

    - **Model Training**: 
      - **Compilation**: Compiled the model with the Adam optimizer and binary cross-entropy loss, tracking accuracy, precision, and recall metrics.
      - **Callbacks**: Implemented ModelCheckpoint and EarlyStopping to save the best model and stop training early if no improvement was observed.
      - **Training Process**: Trained the model on the training dataset, validating it with the validation dataset over multiple epochs.

    - **Evaluation and Interpretation**: 
      - **Model Evaluation**: Evaluated the model on the test dataset to calculate accuracy, precision, and recall.
      - **Visualizations**: Plotted the training and validation metrics over epochs to interpret the model's performance.

    - **Complete Model and Deployment**: 
      - **Saving the Model**: Saved the best model weights and the complete trained model for future use.
      - **Loading and Testing**: Loaded the saved model and tested it on new images to ensure it works as expected.

    This project demonstrates the use of deep learning for medical image classification, involving data preprocessing, model building, training, and evaluation with TensorFlow. It provides a comprehensive solution for detecting pneumonia from chest X-rays, showcasing the potential of AI in healthcare.
* Day 130: Technical Test "WildcardisMatch" and "jump" [LeetCode](https://leetcode.com/problems/)
  - **WildcardisMatch**: Given an input string `s` and a pattern `p`, implement wildcard pattern matching with support for `?` and `*`. The `?` matches any single character, while the `*` matches any sequence of characters (including the empty sequence). The solution should cover the entire input string, not just a partial match. This problem involves using dynamic programming to efficiently manage the different matching scenarios and ensure the pattern matches the entire string. [Problem Description](https://leetcode.com/problems/wildcard-matching/description/)
  - **jump**: Given a 0-indexed array of integers `nums` of length `n`, where each element `nums[i]` represents the maximum length of a forward jump from index `i`, return the minimum number of jumps to reach `nums[n - 1]`. The solution should use a greedy algorithm to track the farthest point that can be reached and count the jumps needed to reach the last index. The test cases guarantee that you can reach the last index. [Problem Description](https://leetcode.com/problems/jump-game-ii/description/)
* Day 131: 🐕 Dogs vs Cats 🐈 [Kaggle](https://www.kaggle.com/datasets/salader/dogs-vs-cats)

  * Today, I worked with the Dogs vs Cats dataset from Kaggle, focusing on developing a Convolutional Neural Network (CNN) to classify images of dogs and cats. Here's a summary of what I accomplished:
    - **Data Preparation**: Downloaded and extracted the dataset, and created training and validation datasets using TensorFlow’s `image_dataset_from_directory` function. The images were normalized for better model performance.
    - **Model Architecture**: Built a CNN using Keras, consisting of multiple Conv2D layers with Batch Normalization and MaxPooling. The model included three Conv2D layers with increasing filter sizes (32, 64, 128) to extract features from the images.
    - **Fully Connected Layers**: Added fully connected Dense layers to the model, with Dropout for regularization, to perform the final classification.
    - **Model Compilation**: Compiled the model with Adam optimizer and binary cross-entropy loss function, suitable for binary classification tasks.
    - **Training**: Trained the model on the prepared dataset for 9 epochs, validating its performance on the validation dataset. Visualized the training and validation accuracy and loss over epochs using Matplotlib.
    - **Testing**: Tested the model with sample images of dogs and cats to verify its predictions.

  This project highlights the importance of proper data preprocessing, designing a robust neural network architecture, and evaluating the model's performance to achieve accurate image classification. The insights and models developed can be further refined and used for various image classification tasks.
* Day 132: 🎬 Object-Oriented Programming in Python with Movie Subscription System 🎬

  * Today, I worked on a movie subscription system project to reinforce the principles of Object-Oriented Programming (OOP) in Python. This project incorporates key OOP concepts such as inheritance, encapsulation, and abstraction. Here's a summary of what I accomplished:

    - **Abstraction and Encapsulation**: Created an abstract base class `Person` to represent common attributes and behaviors for both viewers and directors. Encapsulated the name and ID number attributes to protect them from direct modification. Implemented abstract methods to enforce a consistent interface for subclasses.
    - **Inheritance**: Developed two subclasses, `Viewer` and `Director`, inheriting from the `Person` class. These subclasses extend the base class by adding specific attributes and methods like subscribing to genres and adding movies to the director's filmography.
    - **Movie Management**: Created a `Movie` class to represent a movie, including attributes for the movie title, genre, director, rating, and duration. Added methods to handle movie details and categorize movies by genre.
    - **User Interaction**: Implemented a menu-driven interface to allow users to subscribe viewers to genres, display viewer details, and show movie information. This interactive component showcases how OOP can be used to structure complex, real-world applications.
    - **Data Storage**: Used dictionaries to manage and store viewer instances, demonstrating the practical use of data structures in conjunction with OOP to handle multiple objects efficiently.

  This project provided a comprehensive exercise in applying OOP principles to a realistic scenario, reinforcing the importance of well-structured, maintainable, and scalable code.
* Day 133: 🤖 Implementing a Simple Neural Network in Python with Backpropagation 🤖

  * Today, I worked on a project to build a simple neural network from scratch in Python, focusing on the fundamental concepts of neural networks and backpropagation. Here's a summary of what I accomplished:

    - **Activation Function**: Implemented the sigmoid function and its derivative, which are essential for the forward and backward passes in the neural network.
    - **Loss Function**: Used the mean squared error (MSE) as the loss function to measure the performance of the neural network.
    - **Network Initialization**: Created a `NeuralNetwork` class with two hidden layers. Randomly initialized the weights for connections between the input layer, hidden layers, and output layer.
    - **Forward Propagation**: Developed a method to pass input data through the network, compute the activations of the hidden layers and the final output.
    - **Backward Propagation**: Implemented the backpropagation algorithm to update the weights based on the error between predicted and actual outputs. This involved calculating deltas for each layer and adjusting the weights using the learning rate.
    - **Training the Network**: Trained the neural network using a small dataset, splitting it into training and validation sets. Monitored the training and validation loss to ensure the network was learning correctly.
    - **Prediction**: Added a function to test the trained network with new input data, demonstrating its ability to make predictions.

  This project provided a hands-on exercise in understanding and implementing the core components of a neural network, from initialization to training and prediction. It reinforced key concepts in machine learning, such as forward and backward propagation, weight updates, and performance evaluation.
* Day 134: ♟️ Building a Chess Game in Python with Object-Oriented Programming ♟️

  * Today, I worked on a project to create a chess game in Python, focusing on the principles of Object-Oriented Programming (OOP). This project involved designing classes for different chess pieces and implementing their movements on the board. Here's a summary of what I accomplished:

    - **ChessPiece Base Class**: Developed an abstract `ChessPiece` class to represent a generic chess piece. This class includes a `color` attribute and an abstract method `get_legal_moves` which must be implemented by subclasses.
    
    - **King Class**: Created a `King` class that inherits from `ChessPiece` and implements the `get_legal_moves` method to return all possible legal moves for the king, considering its unique movement rules.

    - **Queen Class**: Developed a `Queen` class that combines straight and diagonal moves, mimicking the behavior of both a rook and a bishop. This class uses helper methods `get_straight_moves` and `get_diagonal_moves` to calculate all legal moves.

    - **Rook Class**: Created a `Rook` class that inherits from `ChessPiece` and reuses the `get_straight_moves` method from the `Queen` class to determine its legal moves.

    - **Bishop Class**: Implemented a `Bishop` class that inherits from `ChessPiece` and reuses the `get_diagonal_moves` method from the `Queen` class to calculate its legal moves.

    - **Knight Class**: Designed a `Knight` class with a unique movement pattern, implementing its own `get_legal_moves` method to return all possible L-shaped moves.

    - **Pawn Class**: Developed a `Pawn` class that includes specific movement rules such as moving forward one or two squares from the starting position and capturing diagonally.

    - **ChessBoard Class**: Created a `ChessBoard` class to initialize the board with all pieces in their starting positions. This class includes methods to display the board, move pieces, check for valid moves, and evaluate the position.

    - **Move Validation**: Implemented logic in the `move_piece` method to ensure moves are legal according to each piece's movement rules. This method also switches the current turn between white and black players.

    - **Evaluation and Legal Moves Generation**: Added methods to evaluate the board's position and generate all legal moves for a given color, providing a foundation for future enhancements like check and checkmate detection.

  This project provided a comprehensive exercise in applying OOP principles to a classic game, reinforcing the importance of creating maintainable and scalable code. It also offered a practical way to implement and test various chess piece movements and game mechanics.
* Day 135: ☕ Analyzing Worldwide Coffee Consumption Trends with Python ☕

  Today, I focused on a data analysis project that examines coffee consumption patterns across various countries using a dataset that spans from 2000 to 2023. This project provided valuable insights into how coffee is enjoyed around the world. Here's a summary of what I accomplished:

  - **Loading the Data**: Imported the dataset containing information on coffee consumption, prices, types of coffee consumed, and population for different countries.

  - **Data Exploration**: Explored the dataset to understand its structure, including the number of records, data types, and basic statistics.
    - **Fields and Data Types**:
      - `Country`: The name of the country where the data was collected.
      - `Year`: The year of the record, spanning from 2000 to 2023.
      - `Coffee Consumption (kg per capita per year)`: The amount of coffee consumed per person annually.
      - `Average Coffee Price (USD per kg)`: The average price of coffee per kilogram in US dollars.
      - `Type of Coffee Consumed`: The most popular types of coffee enjoyed in each country.
      - `Population (millions)`: The estimated population of each country.

  - **Data Cleaning**: Renamed columns to remove spaces and make them more code-friendly.

  - **Handling Missing Data**: Checked for and handled any missing data to ensure the dataset was complete and accurate for analysis.

  - **Exploratory Data Analysis (EDA)**: Conducted various analyses to gain insights into the data:
    - **Distributions**: Plotted histograms for numerical features to understand their distributions.
    - **Trends Over Time**: Analyzed the number of records per year for different types of coffee.
    - **Correlation Analysis**: Created a heatmap to visualize the correlations between numerical features.
    - **Pie Charts**: Visualized the distribution of different types of coffee consumed.
    - **Stacked Bar Chart**: Showed the trends of coffee types consumed over the years.
    - **Box Plot**: Compared coffee prices across different countries.
    - **Top Countries Analysis**: Identified and analyzed the top 10 countries by average coffee consumption.
    - **Heatmap**: Displayed the distribution of different types of coffee consumed across countries.

  This project provided a comprehensive exercise in data analysis, helping to reinforce key concepts in data cleaning, exploration, visualization, and interpretation.
* Day 136: Technical Test "permute" and "permuteUnique" [LeetCode](https://leetcode.com/problems/)
  - **permute**: Given an array `nums` of distinct integers, return all possible permutations. The solution involves using backtracking to generate permutations by swapping elements and recursively building each permutation until the entire array is permuted. [Problem Description: Permutations](https://leetcode.com/problems/permutations/description/)
  - **permuteUnique**: Given a collection of numbers that might contain duplicates, return all possible unique permutations. The solution sorts the input array and uses backtracking with a set to skip over duplicate elements during the permutation process. [Problem Description: Permutations II](https://leetcode.com/problems/permutations-ii/description/)
* Day 137: Test Projects "NotesManager"
  * Today, we're focusing on writing unit tests for a simple Note Manager application. Testing is a crucial part of software development, ensuring that our code works as expected and helps prevent bugs from creeping into our projects. We'll use Python's unittest module to create and run our tests. This exercise will help you understand the basics of writing tests and how to use them to verify the correctness of your code.
* Day 138: 🐾 Developing a Pet Store Management System in Python with Unit Testing 🐾

  * Today, I worked on a project to create a Pet Store Management System in Python, emphasizing the principles of Object-Oriented Programming (OOP) and unit testing. This project involved designing classes for customers, staff, and pets, and implementing a menu-driven interface for interactions. Here's a summary of what I accomplished:

    - **Person Base Class**: Developed an abstract `Person` class to represent a generic person in the system, including attributes for name and ID number. This class also includes an abstract method `get_description` which must be implemented by subclasses.

    - **Customer Class**: Created a `Customer` class that inherits from `Person` and includes methods to adopt pets and retrieve a list of adopted pets. The class also implements the `get_description` method to return customer details.

    - **Staff Class**: Developed a `Staff` class that inherits from `Person` and includes methods to assign pets to staff and retrieve a list of assigned pets. This class also implements the `get_description` method to return staff details.

    - **Pet Class**: Designed a `Pet` class with attributes for name, breed, age, and price. This class includes a method `get_description` to return pet details.

    - **Menu Interface**: Implemented a menu-driven interface that allows users to adopt a pet, display customer details, and display pet details. The interface interacts with the `Customer`, `Staff`, and `Pet` classes to manage the store's operations.

    - **Unit Testing**: Wrote comprehensive unit tests using Python's `unittest` module to verify the functionality of the application. The tests cover:
      - Adding pets to customers and ensuring they are correctly added to the list.
      - Assigning pets to staff and verifying the assignment.
      - Retrieving and verifying descriptions of customers, staff, and pets.

  This project provided an in-depth exercise in applying OOP principles and writing effective unit tests to maintain code quality. It reinforced the importance of encapsulation, inheritance, and abstraction in creating maintainable and scalable code.
* Day 139: Top 20 Play Store App Reviews [Kaggle](https://www.kaggle.com/datasets/odins0n/top-20-play-store-app-reviews-daily-update/data)

  * Today, I worked with the Top 20 Play Store App Reviews dataset from Kaggle, focusing on analyzing review sentiments using the DistilBERT model. Here's a summary of what I accomplished:
    - **Data Loading**: Loaded the dataset using Pandas to get a comprehensive view of the reviews and their scores.
    - **Review Analysis**: 
      - Visualized the distribution of review scores to understand the general sentiment of the reviews.
      - Sampled 200 reviews from the dataset for detailed analysis.
    - **Sentiment Analysis with DistilBERT**:
      - Utilized the DistilBERT model for sentiment analysis. The model was fine-tuned on the SST-2 dataset for sentiment classification.
      - Created a sentiment analysis pipeline using the model and tokenizer.
      - Performed sentiment analysis on the reviews and added the results to the dataset.
    - **Visualization**:
      - Plotted the distribution of sentiments (Positive vs. Negative) to get an overview of the sentiment spread.
    - **Model Evaluation**:
      - Evaluated the model's performance using a confusion matrix and classification report.
      - Compared the sentiment analysis results with the actual review scores to assess the model's accuracy.
    - **Key Insights**:
      - The model achieved an overall accuracy of 85% in predicting sentiments.
      - Highlighted the balance between precision and recall, showing effective performance in classifying both positive and negative reviews.

  This project demonstrates the practical application of pre-trained transformer models in sentiment analysis, emphasizing the importance of data preprocessing, model evaluation, and visualization in deriving meaningful insights from textual data.
* Day 140: 🎮 Memory Game 🎮
  * Today, I created a memory game using Pygame, focusing on building a fun and interactive application that challenges players to find matching pairs of colored cards. Here's a summary of what I accomplished:
    - **Game Setup**: Initialized Pygame and set up the display with a grid of cards.
    - **Card Generation**: 
      - Defined a set of colors and created pairs for the memory game.
      - Shuffled the colors and assigned them to the cards in a grid layout.
    - **Game Logic**: 
      - Implemented the logic for flipping cards and checking for matches.
      - Handled user input to select and flip cards, and checked for matched pairs.
      - Included a mechanism to hide unmatched cards after a short delay.
    - **Graphics and Display**:
      - Drew the cards on the screen, showing either the card back or the front color based on their state.
      - Added text to display a winning message when all pairs are found.
    - **Game Loop**: 
      - Managed the main game loop to handle events, update the game state, and redraw the screen.
      - Ensured the game runs smoothly and responds to user actions.

  This project highlights the use of Pygame for game development, emphasizing the importance of game logic, user interaction, and visual display to create an engaging user experience. The memory game is a great way to practice Pygame and develop skills in interactive application design.
* Day 141: 🧮 EMI Calculator with Tkinter and Matplotlib 📊
  * Today, I developed an EMI (Equated Monthly Installment) Calculator using Tkinter for the GUI and Matplotlib for visualizing the EMI breakdown. This project involved creating a user-friendly interface and implementing the logic for EMI calculation and graphical representation. Here's a summary of what I accomplished:

    - **GUI Setup**:
      - Created the main window using Tkinter and set the title and background color.
      - Registered validation commands to ensure the user inputs are valid.

    - **Input Fields**:
      - Added input fields for total loan amount, loan period (years and months), and interest rate.
      - Used Tkinter's Entry widget for text inputs and Spinbox for selecting years and months.

    - **Calculation Logic**:
      - Implemented the EMI calculation formula to compute the monthly payment.
      - Calculated the total payment, interest amount, and the breakdown of payments over time.

    - **Result Display**:
      - Formatted and displayed the calculation results in a message box.
      - Showed the monthly payment, total EMI period, total amount, interest amount, and total payment.

    - **Graphical Visualization**:
      - Utilized Matplotlib to plot the EMI breakdown over time.
      - Displayed the balance, interest, and principal components month-wise in a line graph.
      - Added titles, labels, legends, and grid to the plot for better readability.

    - **Clear Functionality**:
      - Implemented a clear function to reset all input fields and prepare the form for new input.

    This project demonstrates the integration of Tkinter for building interactive GUI applications and Matplotlib for data visualization. The EMI Calculator is a practical tool for understanding loan repayment schedules and visualizing the impact of different loan parameters.
* Day 142: Technical Test "rotate" and "groupAnagrams" [LeetCode](https://leetcode.com/problems/)
  - **rotate**: This function rotates an `n x n` 2D matrix by 90 degrees clockwise. The solution involves first transposing the matrix (swapping rows and columns) and then reversing each row. [Problem Description: Rotate Image](https://leetcode.com/problems/rotate-image/description/)
  - **groupAnagrams**: This function groups anagrams together from a list of strings. The solution uses a dictionary where the key is the sorted version of the word and the value is the list of words that, when sorted, match the key. [Problem Description: Group Anagrams](https://leetcode.com/problems/group-anagrams/description/)
* Day 143: 🎵 Object-Oriented Programming in Python with Music Subscription System 🎵
  * Today, I worked on a music subscription system project to reinforce the principles of Object-Oriented Programming (OOP) in Python. This project incorporates key OOP concepts such as inheritance, encapsulation, and abstraction. Here's a summary of what I accomplished:
    - **Abstraction and Encapsulation**: Created an abstract base class `Person` to represent common attributes and behaviors for both listeners and artists. Encapsulated the name and ID number attributes to protect them from direct modification. Implemented abstract methods to enforce a consistent interface for subclasses.
    - **Inheritance**: Developed two subclasses, `Listener` and `Artist`, inheriting from the `Person` class. These subclasses extend the base class by adding specific attributes and methods like subscribing to genres and adding songs to the artist's discography.
    - **Song Management**: Created a `Song` class to represent a song, including attributes for the song title, genre, artist, rating, and duration. Added methods to handle song details and categorize songs by genre.
    - **User Interaction**: Implemented a menu-driven interface to allow users to register listeners and artists, subscribe listeners to genres, register songs, display listener details, display song information, and show artist details. This interactive component showcases how OOP can be used to structure complex, real-world applications.
    - **Data Storage**: Used dictionaries to manage and store listener, artist, and song instances, demonstrating the practical use of data structures in conjunction with OOP to handle multiple objects efficiently.

  This project provided a comprehensive exercise in applying OOP principles to a realistic scenario, reinforcing the importance of well-structured, maintainable, and scalable code.
* Day 144: 🌀 Mandelbrot Set Visualization 🌀
  * Today, I delved into the fascinating world of fractals by visualizing the Mandelbrot set using Python. This project involved implementing the mathematical principles behind the Mandelbrot set and generating a beautiful visual representation. Here's a summary of what I accomplished:

    - **Mathematical Foundations**: Implemented the Mandelbrot sequence using a function that iterates a complex number to determine if it belongs to the Mandelbrot set. The function returns the iteration count, which is used to determine the color of each point in the visualization.
    - **Grid Creation**: Generated a grid of complex numbers representing the real and imaginary parts of the Mandelbrot set. Used `numpy` to create linear spaces for the real and imaginary components, and iterated over this grid to compute the Mandelbrot values.
    - **Visualization**: Utilized `matplotlib` to plot the computed Mandelbrot set. Applied a color map to visually represent the iteration count, creating a vivid and intricate fractal image. Added labels and a color bar for better readability.
    - **Code Organization**: Structured the code into functions to improve readability and maintainability. This modular approach ensures that each part of the computation and visualization process is clearly defined and easy to understand.
    - **Inspiration**: Based this project on a tutorial by NeuralNine. You can watch the video here: [NeuralNine YouTube Tutorial](https://www.youtube.com/watch?v=xjjmkg9J7Gg).

  This project provided a deep dive into both mathematical computation and data visualization, reinforcing the importance of combining theoretical concepts with practical implementation.
* Day 145: 🌳 Recursive Tree Animation 🌳
  * Today, I explored the world of recursive graphics by creating an animated visualization of a fractal tree using Python. This project combined recursion with animation to produce a dynamic and captivating visual representation. Here's a summary of what I accomplished:

    - **Recursive Tree Drawing**: Implemented a recursive function to draw a tree. The function calculates the end points of each branch using trigonometric functions and recursively draws smaller branches at specified angles. This method creates the characteristic fractal structure of a tree.
    - **Animation Setup**: Used `matplotlib` and `numpy` to set up the initial figure and axis for the animation. Defined the limits and aspect ratio to ensure the tree is displayed correctly.
    - **Frame Updates**: Created an animation function that updates the tree's depth with each frame, gradually increasing the depth of recursion to animate the growth of the tree. This function clears the previous frame, sets the axis limits, and draws the tree with the current depth.
    - **Creating the Animation**: Utilized `matplotlib.animation.FuncAnimation` to create the animation. Defined the initial and maximum depth, and set the interval between frames to control the animation speed.
    - **Displaying the Animation**: Configured `matplotlib` to display the animation, showcasing the growth of the fractal tree in real-time.

  This project provided an exciting opportunity to delve into recursive algorithms and animation techniques, demonstrating the power of combining mathematical concepts with visual art.
* Day 146: 🏦 ATM Machine Simulation 🏦
  * Today, I ventured into the realm of GUI programming by creating an ATM machine simulation using Python and Tkinter. This project involved developing a user-friendly interface that mimics the functionalities of a real ATM, providing an interactive experience for users. Here's a summary of what I accomplished:

    - **GUI Design**: Designed the main application window with Tkinter, setting up the initial balance and PIN. Configured the window to be non-resizable and applied a consistent color scheme for a professional look.
    - **PIN Validation**: Implemented a PIN entry system to authenticate users. The application verifies the entered PIN and provides appropriate feedback using message boxes.
    - **ATM Menu**: Created a menu with options to check balance, deposit money, withdraw money, and exit. Each menu option is linked to its corresponding function, ensuring smooth navigation.
    - **Balance Check**: Developed a function to display the current balance in a message box.
    - **Deposit Money**: Added functionality to allow users to deposit money into their account. Implemented input validation to ensure the deposited amount is a positive number.
    - **Withdraw Money**: Enabled users to withdraw money, with validation to check for sufficient balance and ensure the withdrawn amount is positive.
    - **Code Organization**: Structured the code into functions and classes to enhance readability and maintainability. This modular approach ensures that each part of the application is clearly defined and easy to understand.

  This project provided valuable insights into GUI development and user interaction, demonstrating the importance of creating intuitive and functional interfaces.
* Day 147: Technical Test "myPow" and "NQueens" [LeetCode](https://leetcode.com/problems/)
  - **myPow**: Implemented a function that calculates \( x^n \) (x raised to the power n) efficiently. This problem involves optimizing the power calculation by leveraging recursion and handling edge cases such as negative powers. [Problem Description: myPow](https://leetcode.com/problems/powx-n/description/)
  - **NQueens**: Solved the N-Queens problem, which involves placing n queens on an n x n chessboard so that no two queens attack each other. The solution uses backtracking to explore all possible placements and returns all distinct configurations. [Problem Description: NQueens](https://leetcode.com/problems/n-queens/description/)
* Day 148: 🎮 Video Game Subscription System in Python 🎮

  * Today, I expanded my understanding of Object-Oriented Programming (OOP) by developing a Video Game Subscription System using Python. This project leverages fundamental OOP principles such as inheritance, encapsulation, and abstraction. Here’s a summary of the key elements:

    - **Abstraction and Encapsulation**: Defined an abstract base class `Person` representing common features for both `Player` and `Developer`. Encapsulated attributes like name and ID number to ensure data integrity. The abstract method `get_description` enforces a consistent interface for subclasses.
    - **Inheritance**: Created two subclasses, `Player` and `Developer`, that inherit from `Person`. These subclasses add specific attributes and methods, such as subscribing to game genres for `Player` and adding games to a portfolio for `Developer`.
    - **Game Management**: Introduced a `Game` class to represent individual games, including details such as title, genre, developer, rating, and release year. Methods within this class manage game-related information and allow interaction with player and developer objects.
    - **User Interaction**: Built a menu-driven interface allowing users to register players and developers, add new games, subscribe players to game genres, and display details for players, games, and developers. This interactive component illustrates the practical application of OOP in creating user-friendly software systems.
    - **Data Organization**: Employed dictionaries to efficiently manage and store instances of players, developers, and games. This approach highlights the integration of OOP and data structures to handle complex, real-world data scenarios.

  This project provided an engaging and insightful exercise in implementing OOP principles to simulate a real-world application, reinforcing the importance of design patterns and code maintainability.
* Day 149: 🧩 Wordle Game with Flask and CSS 🖥️

  * Today, I worked on developing a Wordle-inspired game using Flask for the backend and custom CSS for styling. This project integrates web development skills with game logic to create an interactive user experience. Here’s a summary of the key components:

    - **Flask Application**: Implemented a Flask application to handle game logic, including word selection, guess validation, and feedback management. Used session variables to track game state, including the target word, attempts, and game status.
    - **Word Management**: Loaded a list of possible words from a text file and used it to randomly select a word for each game session. Validated player guesses against this word and provided feedback on correctness, presence, or absence of letters.
    - **User Interface**: Designed a user-friendly interface using HTML and CSS, featuring forms for guess input, feedback display, and game status updates. The interface also includes a responsive design to ensure compatibility across different devices.
    - **Feedback System**: Incorporated a feedback mechanism to visually represent the correctness of each guessed letter, including color-coded indicators for correct, present, and absent letters.
    - **Game Flow Control**: Managed game flow with options to restart the game or handle game-over scenarios, providing an engaging experience with clear instructions and error handling.

  This project allowed me to apply web development and design skills in a practical context, creating an enjoyable and visually appealing game experience.

* Day 150: 🧠 Brain Tumor Dataset 🧠 Analysis [Kaggle](https://www.kaggle.com/datasets/odins0n/brain-tumor-dataset)

  * Today, I worked with the Brain Tumor dataset from Kaggle, focusing on exploring various aspects of the data and performing detailed analyses. Here's a summary of what I accomplished:
    - **Data Loading**: Loaded the dataset using Pandas, and explored the initial structure of the data.
    - **Data Cleaning**:
      - Renamed columns for consistency and easier access.
      - Checked for and handled missing data, ensuring the dataset was ready for analysis.
    - **Exploratory Data Analysis (EDA)**:
      - **Categorical Features**: 
        - Created count plots for features like Tumor Type, Location, and Gender to visualize their distributions.
        - Analyzed the correlation between Tumor Location and Grade using a heatmap.
      - **Numerical Features**:
        - Generated correlation heatmaps to understand relationships between numeric features like Age and Tumor Size.
        - Visualized the distribution of Tumor Grade by Age and Gender, and Tumor Size by Type and Grade.
      - **Outlier Detection**:
        - Used boxplots to detect outliers in Age and Tumor Size, identifying specific data points for further investigation.
    - **Principal Component Analysis (PCA)**:
      - Applied PCA to reduce dimensionality, focusing on numeric features like Age and Size.
      - Visualized the resulting principal components to explore potential clustering by Tumor Type.
    - **Feature Engineering**:
      - Grouped Age into categories to simplify analysis.
      - Created a binary feature indicating whether a tumor was in a critical location.
    - **Automated Report**:
      - Developed functions to generate a statistical summary, distribution graphs, and correlation analysis for both numerical and categorical variables.
      - Automated the generation of visual and textual insights from the dataset.

  * This work provided valuable insights into the distribution and relationships within the dataset, which could be crucial for understanding and predicting outcomes related to brain tumors. The automated report functions developed can also be reused for similar datasets in future projects.
* Day 151: 🏗️ Tower of Babel - Recursive Algorithm 🏗️

  * Today, I implemented and explored the Tower of Babel problem, a variation of the classic Tower of Hanoi, using a recursive algorithm. This project focused on moving blocks from one position to another following specific rules. Here's a summary of what I accomplished:
    - **Recursive Function Design**:
      - Developed a recursive function `build_tower` that moves blocks between positions to simulate the construction of a tower.
      - The base case handles the movement of a single block, while the recursive case manages the movement of multiple blocks.
    - **Block Movement Logic**:
      - Implemented the `move_block` function to transfer blocks between positions, ensuring that each move is printed to the console for clarity.
    - **Initial and Final Tower States**:
      - Initialized the tower with a specific number of blocks in one position.
      - The recursive process successfully moved all blocks to the target position, maintaining the rules of the problem.
    - **Visualization and Debugging**:
      - Provided clear output of the tower's state before and after the recursive process, aiding in debugging and understanding the algorithm's flow.
      - Used print statements to trace each block movement, making it easier to follow the recursive calls.

  * This exercise was a great opportunity to reinforce my understanding of recursion, particularly in solving problems that involve multiple recursive calls and complex state management. The Tower of Babel problem also highlights the importance of clear base cases and recursive steps in algorithm design.
* Day 152: Technical Test "totalNQueens" and "maxSubArray" [LeetCode](https://leetcode.com/problems/)
  - **totalNQueens**: Implemented a solution to the N-Queens II problem, which involves counting the number of distinct solutions for placing n queens on an n x n chessboard so that no two queens attack each other. The solution uses backtracking to explore all valid placements and utilizes arrays to track columns and diagonals that are under attack. The efficient marking and unmarking of attacked positions allow the algorithm to explore all configurations systematically. [Problem Description: totalNQueens](https://leetcode.com/problems/n-queens-ii/description/)

  - **maxSubArray**: Solved the Maximum Subarray problem, where the goal is to find the contiguous subarray within a one-dimensional numeric array that has the largest sum. The solution employs a dynamic programming approach, where the maximum sum is updated as the algorithm iterates through the array, considering each element either as a standalone subarray or as an extension of the previous subarray. This approach ensures an optimal solution with a time complexity of O(n). [Problem Description: maxSubArray](https://leetcode.com/problems/maximum-subarray/description/)
* Day 153: 🎮 Rock Paper Scissor Game with Tkinter 🎮

  * Today, I developed a Rock Paper Scissor game using Python's Tkinter library. The game allows the player to select between Rock, Paper, or Scissors, while the computer randomly selects its move. Here’s a summary of the key components of this project:
    - **Graphical User Interface (GUI) Design**:
      - Created an intuitive and user-friendly interface with buttons for the player's choices, as well as labels for displaying the results.
      - Utilized Tkinter widgets such as `Label`, `Button`, and `Frame` to organize the layout and display game elements.
    - **Game Logic Implementation**:
      - Implemented the game logic for Rock, Paper, Scissors, where the player’s choice is compared with the computer’s random selection.
      - Handled different outcomes such as "Player Wins", "Computer Wins", or "Match Draw" based on the rules of the game.
    - **Reset and State Management**:
      - Added a reset button to allow players to restart the game without closing the application.
      - Disabled buttons after each round to prevent multiple choices in a single game, ensuring a fair gameplay experience.
    - **Random Computer Selection**:
      - Used Python's `random` library to simulate the computer's choice, making the game unpredictable and engaging.

  * This project was a great way to practice my skills in building GUI applications with Tkinter, as well as implementing simple game mechanics in Python. It reinforced concepts such as event handling, state management, and the importance of a well-structured user interface.
* Day 154: 🏥 Medical Appointment System in Python 🩺

  * Today, I developed a Medical Appointment System using Python, implementing Object-Oriented Programming (OOP) principles such as inheritance, encapsulation, and abstraction. This project focuses on managing patients, doctors, and appointments in an organized and scalable manner. Here's a summary of the key features:

    - **Abstraction and Encapsulation**: Defined an abstract base class `Person` to represent common attributes for both `Patient` and `Doctor`, ensuring a consistent interface through the abstract method `get_description`. Encapsulated sensitive data like name and ID number to protect the integrity of the information.
    - **Inheritance**: Created two subclasses, `Patient` and `Doctor`, that extend the functionality of the `Person` class. The `Patient` class manages patient-specific data like age and appointments, while the `Doctor` class tracks the doctor's specialty and assigned patients.
    - **Appointment Scheduling**: Introduced an `Appointment` class to manage the scheduling of appointments between patients and doctors, storing details like date, time, and reason for the visit. This class ties together both patient and doctor information, ensuring smooth coordination.
    - **Menu-Driven Interaction**: Built a user-friendly interface that allows the registration of new patients and doctors, scheduling of appointments, and viewing detailed information about patients and doctors. This menu system showcases the integration of OOP with real-world applications.
    - **Data Management**: Used dictionaries to organize and store instances of patients and doctors efficiently. This approach facilitates quick access and updates to patient and doctor records, demonstrating the importance of effective data structures in software systems.

  This project was a great opportunity to practice implementing OOP concepts in a practical scenario, creating a robust system for managing medical appointments. It deepened my understanding of how OOP principles can streamline the organization of complex data and processes.
* Day 155: 🎬 Movie Ratings Analysis with PySpark and Seaborn 🎥 [Dataset](https://grouplens.org/datasets/rating-disposition-2023/)

  * Today, I worked on a data analysis project focused on movie ratings using PySpark for distributed data processing and Seaborn for visualizations. The project involved cleaning, processing, and analyzing a dataset of movie ratings to uncover trends and insights. Here's a breakdown of the key features:

    - **Data Processing with PySpark**: Utilized PySpark to handle a large dataset of movie ratings, allowing efficient computation on big data. I loaded the data into a DataFrame, filtered, and aggregated it using PySpark’s powerful functions like `groupBy`, `agg`, and `filter` to analyze ratings per movie and user.
    - **Average Rating Calculation**: Calculated the average rating for each movie and determined the number of ratings each movie received. This information was crucial for identifying popular movies and trends in user preferences.
    - **User Activity Analysis**: Analyzed user behavior by calculating the average rating given by each user and identifying the most active users, showcasing how PySpark can be used to extract valuable insights from large datasets.
    - **Visualization with Seaborn**: Converted the PySpark DataFrame to a pandas DataFrame and used Seaborn to create a bar chart representing the distribution of ratings across movies. This visual representation helped highlight the most common rating values and their occurrences.
    - **Interactive Data Exploration**: Implemented a menu-driven interface allowing exploration of the data, including displaying top-rated movies, most active users, and the distribution of ratings. This approach ties together both data processing and visualization in a cohesive project.

  This project was a great opportunity to dive deeper into big data processing with PySpark, as well as exploring data visualization techniques with Seaborn. It enhanced my ability to work with large datasets and transform them into meaningful insights, while reinforcing the importance of visualizations in data analysis.
* Day 156: 🗒️ To-Do List Application with Flet 📝

  * Today, I created a To-Do List application using Flet, a modern framework for building interactive web applications in Python. This project was a fantastic exercise in using Flet to manage user input, display dynamic content, and handle interactive events. Here's a summary of the key features:

    - **User Interface Design**: Designed a clean and user-friendly interface with a centered layout. The application features a title, input field, and button for adding tasks, along with a dynamically updated list of tasks.
    - **Task Management**: Implemented functionality to add new tasks to the list and display them with checkboxes. Tasks are displayed in a list view, allowing users to see and manage their to-dos easily.
    - **Interactive Elements**: Incorporated interactive elements such as a `TextField` for task input and a `FilledButton` to add tasks. Added checkboxes next to each task to allow users to mark tasks as completed.
    - **Dynamic Updates**: Created functions to update the task list and display selected tasks based on user interactions. The list updates in real-time to reflect new tasks and changes in task selection.
    - **Data Handling**: Used a list to manage and store tasks, and updated the displayed list dynamically. The application tracks which tasks are selected and updates the display accordingly.

  This project was an excellent opportunity to explore Flet's capabilities in building interactive web applications and to apply concepts of UI design and event handling in a practical context.
* Day 157: Technical Test "spiralOrder" and "canJump" [LeetCode](https://leetcode.com/problems/)

  - **spiralOrder**: Solved the Spiral Matrix problem, where the task is to traverse a 2D matrix in spiral order and return the elements in the order they are visited. The algorithm follows a structured approach by traversing the matrix in four directions (right, down, left, up) while adjusting the boundaries (top, bottom, left, right) as the spiral tightens. This method ensures that each element is visited exactly once. The solution has a time complexity of O(m * n), where m and n are the dimensions of the matrix. [Problem Description: Spiral Order](https://leetcode.com/problems/spiral-matrix/description/)

  - **canJump**: Implemented a solution for the Jump Game problem, which asks whether it is possible to reach the last index of an array given that each element represents the maximum jump length from that position. The algorithm utilizes a greedy approach to track the farthest reachable index as it iterates through the array. If at any point the current index is beyond the farthest reachable index, the function returns `False`. Otherwise, it returns `True` if the last index is reachable. This solution operates in linear time with a time complexity of O(n). [Problem Description: Can Jump](https://leetcode.com/problems/jump-game/description/)
* Day 158: 🖌️ Floodfill Image Color Changer with Tkinter 🖌️

  * Today, I created a graphical application in Python using Tkinter that allows users to apply a floodfill operation to an image. The application provides a simple interface for loading an image, selecting a color, and applying the floodfill to change the color of a specific region. Here’s a summary of the key components of this project:
    - **Image Loading and Display**:
      - Implemented a file dialog to allow users to select an image from their system. The selected image is then displayed on a Tkinter canvas.
      - Utilized the PIL (Python Imaging Library) to handle image loading and conversion to the RGB format, ensuring compatibility with various image types.
    - **Floodfill Operation**:
      - Added a floodfill feature where the user can choose a color using a color chooser dialog, and apply it to a specific pixel on the image.
      - The floodfill algorithm fills all connected pixels with the chosen color, making it easy to change the appearance of large areas within the image.
    - **Saving the Modified Image**:
      - Integrated a save dialog that allows users to save the modified image in their desired format (PNG, JPEG, etc.).
      - Ensured that the application handles any errors during the save process, providing user feedback through message boxes.
    - **User Interface**:
      - Designed a clean and intuitive user interface with buttons for loading, applying floodfill, and saving the image. The interface is styled with colors and fonts to enhance the user experience.
    - **Error Handling**:
      - Included comprehensive error handling to manage issues like unsupported image formats, out-of-bound pixel selections, and file save errors, ensuring a robust application.

  * This project was an excellent exercise in working with images and enhancing my skills in Tkinter and PIL. It allowed me to delve deeper into image processing techniques and GUI development in Python.
* Day 159: 🏠 Real Estate Data Visualization with Folium 🗺️

  * Today, I worked on a project that visualizes real estate data using Folium, a powerful Python library for creating interactive maps. The project was inspired by a [NeuralNine](https://www.youtube.com/watch?v=5UQyxgiQAzk) video, which provided a great foundation for this type of data visualization. Here’s a summary of the key components of this project:
  
    - **Data Handling**:
      - Utilized the California Housing dataset provided by Scikit-Learn to analyze various features such as median house value, average number of rooms, and population.
      - Converted the dataset into a Pandas DataFrame for easy manipulation and analysis.

    - **Map Initialization**:
      - Created an interactive map centered on the average latitude and longitude of the data points.
      - Used Folium to set up the base map with a zoom level appropriate for visualizing the entire California region.

    - **Marker Creation**:
      - Iterated through each row of the dataset to add circle markers on the map, with each marker representing a location in the dataset.
      - Adjusted the size of the markers based on the normalized average number of rooms, providing a visual indication of housing density.
      - Applied a color gradient to the markers based on the median house value, allowing for quick visual identification of high-value areas.

    - **Popup Information**:
      - Added detailed popups to each marker, displaying information such as median house value, average rooms, population, and median income.
      - Ensured the popups are clear and informative, making the map not only visually appealing but also data-rich.

    - **Additional Features**:
      - Integrated a minimap plugin for better navigation and spatial context, enhancing the user’s ability to explore different regions.
      - Saved the final interactive map as an HTML file, making it easy to share and view on any web browser.

  * This project was a great exercise in combining data science with geographic visualization. It allowed me to deepen my understanding of how to represent complex datasets in a user-friendly manner using Python and Folium. Special thanks to NeuralNine for the inspiration!
* Day 160: Top 1000 Global Tech Companies Dataset (2024) [Kaggle](https://www.kaggle.com/datasets/muhammadehsan000/top-1000-global-tech-companies-dataset-2024/code)

  * Today, I explored the Top 1000 Global Tech Companies dataset from Kaggle, focusing on data analysis and visualization. Below is a summary of the key activities and findings:
  
    - **Data Loading**: 
      - Loaded the dataset using Pandas and inspected the initial data structure.
  
    - **Data Cleaning**:
      - Renamed the "Market Cap" column to "Market_Cap" for easier access and consistency.
      - Checked for and identified any missing data within the dataset.
  
    - **Exploratory Data Analysis (EDA)**:
      - **Categorical Features**:
        - Created count plots for the "Country," "Sector," and "Industry" features to visualize their distributions.
        - Analyzed the distribution of industries across different countries using a heatmap.
        - Focused on the top 10 industries to further analyze their distribution by country.
      - **Numerical Features**:
        - Visualized the distribution of company rankings within the dataset.
        - Examined the top 10 companies by market capitalization, converting the values to billions for clarity.
      - **Country Distribution**:
        - Analyzed the distribution of companies by country, identifying the top 10 countries by the number of companies.
  
    - **Automated Reporting**:
      - Developed functions to automate the generation of statistical summaries, distribution graphs, and correlation analyses for both numerical and categorical variables.
      - These functions facilitate rapid insights and visualizations for future projects involving similar datasets.

  * This analysis provided a comprehensive understanding of the distribution of tech companies globally, with insights into key industries and market leaders. The automated report generation process developed can be applied to future datasets for efficient and consistent analysis.
* Day 161: 🏨 Hotel Reservation System in Python 🏢

  Today, I developed a Hotel Reservation System using Python, focusing on Object-Oriented Programming (OOP) principles such as inheritance, encapsulation, and abstraction. This project is designed to manage guests, rooms, and reservations in a streamlined and efficient manner. Here's a summary of the key features:

  - **Encapsulation**: The `Person` class encapsulates the attributes `name` and `ID number`, making them private to protect data integrity. Getter methods are provided to access these attributes safely.
    
  - **Inheritance**: The `Guest` class inherits from the abstract base class `Person`, which defines common attributes for all persons in the system. This ensures code reusability and consistency.

  - **Abstraction**: The `Person` class includes an abstract method `get_description`, which is implemented by the `Guest` class to provide a detailed description of the guest. This enforces a consistent interface across different types of persons in the system.

  - **Room Management**: The `Room` class manages the details of each room, such as the number of beds, baths, food service, and entertainment availability. It also tracks the guests assigned to each room.

  - **Reservation System**: The `Reservation` class ties together the guest and room information, storing details such as check-in and check-out dates. Guests can have multiple reservations, and rooms can accommodate multiple guests.

  - **User Interaction**: A menu-driven interface allows users to register new guests and rooms, make reservations, and view detailed information about guests and rooms. This interface demonstrates the practical application of OOP principles in a real-world scenario.

  - **Data Organization**: Dictionaries are used to store and manage instances of guests and rooms, providing efficient access and updates to the data.

  This project was an excellent opportunity to apply OOP concepts in creating a functional and user-friendly hotel reservation system. It reinforced my understanding of how abstraction, inheritance, and encapsulation can be used to build organized and scalable software solutions.
* Day 162: 🌀 Gray Code Generator - Recursive Algorithm 🌀

  * Today, I explored and implemented a Gray Code Generator using a recursive algorithm in Python. Gray codes are binary sequences where two successive values differ in only one bit, making them useful in error correction, digital communications, and other fields. Here's a summary of what I accomplished:
    - **Recursive Generation of Gray Codes**:
      - Developed the function `generateGrayarr(n)` to generate all possible n-bit Gray codes.
      - Utilized recursion to progressively build the Gray code sequences, starting with the base patterns "0" and "1".
    - **Base Case Handling**:
      - Established a base case that handles scenarios where `n` is 0 or negative, ensuring no Gray codes are generated when `n` is invalid.
    - **Efficient Code Generation**:
      - Implemented a loop to iteratively generate 2^n Gray codes by appending previously generated codes in reverse order.
      - Prefixed "0" to the first half and "1" to the second half of the Gray codes during each iteration, effectively doubling the number of codes.
    - **Binary Manipulation**:
      - Utilized bitwise operations (`<<` and `1 << n`) to manage and generate the appropriate number of codes efficiently.
    - **Output Display**:
      - Printed all generated n-bit Gray codes, providing a clear representation of the output for a 5-bit Gray code sequence.

  * This project provided a solid exercise in recursion, bitwise operations, and efficient algorithm design. The Gray Code Generator is a powerful tool in various computational applications, and implementing it was a great way to deepen my understanding of recursive sequences and binary operations.

* Day 163: Technical Test "merge_intervals" and "insert_intervals" [LeetCode](https://leetcode.com/problems/)

  - **merge_intervals**: Developed a solution for the Merge Intervals problem, where the goal is to merge all overlapping intervals in a given list of intervals. The algorithm starts by sorting the intervals based on their starting times. It then iterates through the sorted list, merging intervals that overlap by adjusting the end time of the current interval. If no overlap is found, the current interval is added to the list of merged intervals. This approach ensures that all overlapping intervals are merged efficiently. The solution has a time complexity of O(n log n) due to the initial sorting step, where n is the number of intervals. [Problem Description: Merge Intervals](https://leetcode.com/problems/merge-intervals/description/)

  - **insert_intervals**: Solved the Insert Interval problem, where the task is to insert a new interval into an existing list of non-overlapping intervals and merge if necessary. The solution involves three main steps: adding all intervals that come before the new interval, merging the new interval with any overlapping intervals, and then adding the remaining intervals that come after. This method ensures that the intervals remain sorted and non-overlapping after insertion. The algorithm has a time complexity of O(n), where n is the number of intervals in the list. [Problem Description: Insert Interval](https://leetcode.com/problems/insert-interval/description/)
* Day 164: 🧮 BMI Calculator with Tkinter and Matplotlib 📊

  * Today, I developed a Body Mass Index (BMI) calculator using Python, Tkinter, and Matplotlib. The application not only calculates BMI based on user input but also provides health recommendations and visualizes BMI and weight trends. Here’s a breakdown of the key features of this project:
    - **BMI Calculation**:
      - Implemented a function to calculate BMI from the user's weight and height, converting height from centimeters to meters for accurate results.
      - Displayed the BMI result in the interface along with a personalized health recommendation based on the calculated BMI.
    - **Dynamic Interface**:
      - Enhanced the user experience by changing the background color of the interface based on the BMI category (e.g., underweight, normal weight, overweight, obese).
      - Added the ability to reset input fields and clear the results, making the application user-friendly and intuitive.
    - **Calculation History**:
      - Implemented a history feature that keeps track of the last five BMI calculations, displaying them in a list within the application.
      - Provided options to save and load the calculation history to/from a JSON file, ensuring data persistence and allowing users to track their BMI over time.
    - **Graphical Visualization**:
      - Used Matplotlib to create and display graphs that show the evolution of BMI and weight over time, giving users a clear visual representation of their progress.
      - Incorporated interactive elements in the Tkinter interface to seamlessly integrate the graphs with the rest of the application.
    - **Error Handling**:
      - Included robust error handling to manage invalid inputs, such as non-numeric values, ensuring the application operates smoothly and provides helpful feedback to users.

  * This project was a great way to practice integrating graphical elements with data processing in Python. It allowed me to enhance my skills in both Tkinter and Matplotlib, creating a functional and visually appealing health tool.
* Day 165: 🗂️ File Manager Pro with Python 🖥️

  - Today, I developed a File Manager system in Python that enables users to efficiently manage their files and folders. This application allows for creating, finding, listing, and deleting files or folders while also calculating the total size of all files in a directory. Below are the key features and components of this project:

    - **File and Folder Creation**:
      - Implemented functionality to create new files with specified names, extensions, and sizes. The system also supports the creation of folders within the base directory.
      - Ensured that the necessary directories are created automatically if they don't exist before a file is generated.

    - **Search Functionality**:
      - Developed a search feature to locate the path of a specific file or folder within the base directory. The system recursively searches through all subdirectories to find the desired item.

    - **Listing Contents**:
      - Created a method to list all files and folders within a given directory, providing an easy overview of the contents.

    - **Size Calculation**:
      - Added the ability to calculate the total size of all files within the base directory, summing up the sizes of individual files to give an accurate total.

    - **File Deletion by Extension**:
      - Included a feature to delete all files with a specified extension across the entire directory structure, helping in bulk file management.

    - **Interactive Command-Line Interface**:
      - Built a user-friendly menu that allows users to interact with the system through various options, such as creating files, listing contents, and deleting files.

    This project provided an excellent opportunity to delve into file management operations using Python’s `os` library. It helped me strengthen my understanding of directory traversal, file handling, and creating user-friendly command-line interfaces.
* Day 166: 🥤 Soda Combinations Generator - Recursive Algorithm 🥤

  * Today, I developed a Python program to generate all possible combinations of a list of sodas using recursion. This project focused on understanding and implementing recursive algorithms to explore all subsets of a given set. Here’s what I achieved:
  
    - **Recursive Generation of Combinations**:
      - Created the function `soda_combinations(sodas, current_combo=[], index=0)` to recursively generate and print all possible combinations of sodas.
      - Implemented two recursive cases: one to include the current soda in the combination and another to exclude it, ensuring all subsets are covered.
    
    - **Base Case Handling**:
      - The base case handles scenarios where all sodas have been considered (`index == len(sodas)`). When this condition is met, the current combination is printed, representing one possible subset.
    
    - **Exploring All Possibilities**:
      - The algorithm explores every combination, from no sodas to the full list, by either including or excluding each soda in the list. This approach ensures that all possible combinations are generated and displayed.
    
    - **Output Display**:
      - Each combination is printed as it is generated, providing a clear and immediate representation of all subsets of the soda list.

  * This project was a great exercise in recursive thinking and subset generation. The ability to systematically explore all possible combinations is a fundamental technique in combinatorial problems, and this implementation deepened my understanding of recursive algorithms in Python.
* Day 167: Technical Test "lengthOfLastWord" and "generateMatrix" [LeetCode](https://leetcode.com/problems/)

  - **lengthOfLastWord**: Implemented a solution for the "Length of Last Word" problem, where the goal is to find the length of the last word in a given string. The algorithm trims any trailing spaces from the string and then finds the index of the last space to determine the length of the last word. The solution efficiently handles different cases, including strings with multiple spaces and empty strings. This method has a time complexity of O(n), where n is the length of the string. [Problem Description: length Of Last Word](https://leetcode.com/problems/length-of-last-word/description/)

  - **generateMatrix**: Solved the "Spiral Matrix II" problem, which involves generating an n x n matrix filled with elements from 1 to n² in a spiral order. The solution uses a systematic approach to fill the matrix by defining boundaries (left, right, top, bottom) and progressively moving inward while filling the matrix. This ensures that the matrix is filled correctly in spiral order. The algorithm has a time complexity of O(n²), where n is the dimension of the matrix. [Problem Description: generate Matrix](https://leetcode.com/problems/spiral-matrix-ii/description/)
* Day 168: Compound Interest Calculator in Python by [NeuralNine](https://www.youtube.com/watch?v=OqCqFfLfFsk)

  * Today, I worked on a project that implements a Compound Interest Calculator using Python and Flask, inspired by a [NeuralNine](https://www.youtube.com/watch?v=OqCqFfLfFsk) tutorial. Here's a breakdown of the key components and features of the project:

    - **User Interface**:
      - Built a simple and user-friendly web interface using HTML and Flask, allowing users to input initial deposit, interest rate, contribution amount, compounding type, and time period in years.
      - Integrated form handling in Flask to process the user input and display the calculated results.

    - **Compound Interest Calculation**:
      - Implemented the compound interest formula to calculate the final amount, considering both the initial deposit and regular contributions over time.
      - Allowed users to choose between monthly and annual compounding, affecting the frequency of interest application.

    - **Visualization**:
      - Used Matplotlib to generate a line graph comparing the growth of the investment with and without interest over the specified time period.
      - Embedded the graph directly in the web page, providing a visual representation of the investment’s growth.

    - **Results Display**:
      - Displayed the final amount with interest and the difference compared to the total contributions without interest.
      - Provided a clear comparison of how much the investment grows due to compound interest.

    - **Technical Implementation**:
      - Utilized Python for back-end calculations and Matplotlib for data visualization.
      - Designed the front-end using HTML, with integration into the Flask framework for dynamic content rendering.

  * This project was a fantastic opportunity to apply mathematical concepts to a real-world financial application, and to further my skills in web development using Flask. The ability to visualize the results added an extra layer of insight into the power of compound interest, making the project both educational and practical.
* Day 169: 🌱 Plant Management System for "La Planta Feliz" Nursery 🌿

  Today, I developed a Plant Management System using Python to help "La Planta Feliz" nursery efficiently manage their inventory of plants. This project focused on leveraging Object-Oriented Programming (OOP) principles to create a flexible and user-friendly system. Here’s a breakdown of the key features:

  - **Plant Creation**: The `Plant` class was designed to represent each plant in the nursery, encapsulating details such as the plant’s code, name, size, species, and price. This structured approach makes it easy to manage and manipulate plant data.

  - **Handling Tall Plants**: I implemented a method in the `Nursery` class to generate a sublist of plants taller than 2 meters. This feature allows the nursery to quickly identify and manage plants that may require special care or different pricing due to their size.

  - **Removing Plants by Name**: The system includes functionality to remove all plants with a specified name. This is particularly useful for managing inventory when certain plants are discontinued or need to be cleared from stock.

  - **Species Counting**: Another key feature is the ability to count the number of plants of a specific species. This helps in understanding the diversity of the nursery’s inventory and making informed decisions about species-specific care or sales strategies.

  - **User Interaction**: The system is designed with a simple interface that allows users to add new plants, filter plants by size, remove plants by name, and count plants by species. This demonstrates the practical application of OOP principles in managing real-world data.

  - **Data Management**: All plant data is managed using lists and list comprehensions, ensuring efficient storage and retrieval of information. This approach facilitates scalability as the nursery's inventory grows.

  This project was an insightful experience in applying OOP concepts to create a functional and efficient system for managing plant inventory. It reinforced my understanding of how encapsulation and data handling can be effectively used in software development to meet specific business needs.
* Day 170: 🍕🍽️ Pizza Restaurant Sales [Kaggle](https://www.kaggle.com/datasets/shilongzhuang/pizza-sales/data)

  * Today, I delved into the Pizza Restaurant Sales dataset from Kaggle, focusing on data analysis and visualization. Below is a summary of the key activities and findings:

    - **Data Loading**:
      - Loaded the dataset using Pandas and examined the initial data structure to understand its composition.
  
    - **Data Cleaning**:
      - Checked for missing values and verified the integrity of the data.
      - Converted `order_time` to a string type and extracted hour, minute, and second for further analysis.
  
    - **Exploratory Data Analysis (EDA)**:
      - **Categorical Features**:
        - Created count plots for the `pizza_size`, `pizza_category`, and `pizza_name` features to visualize their distributions.
        - Analyzed the distribution of pizza sizes and categories using pie charts.
        - Examined the frequency of orders by hour and day of the week, along with monthly trends.
      - **Numerical Features**:
        - Analyzed total price distributions by pizza name and size using box plots and sunburst charts.
        - Visualized the median prices by pizza size and category using a treemap.
      - **Time Series Analysis**:
        - Investigated order frequencies across different hours of the day and days of the week.
        - Created visualizations to show how order distributions vary by date and hour.
  
    - **Advanced Visualizations**:
      - Generated interactive plots using Plotly, including bar charts for order distributions and sunburst plots for price distributions.
      - Used seaborn and Matplotlib for detailed count plots and box plots, enhancing visual insights.
  
  * This analysis provided a detailed view of the pizza sales data, including insights into order trends, pizza categories, and pricing. The generated visualizations offer a comprehensive understanding of the sales dynamics, aiding in decision-making and strategy formulation for the restaurant.
* Day 171: 🔍 Partitioning a List into Two Equal Subsets - Recursive Algorithm 🔍

  * Today, I developed a Python program to determine if a given list of integers can be partitioned into two subsets with equal sum using recursion. This project focused on implementing recursive techniques to explore the possibility of such a partition. Below is a summary of the key tasks and insights:

    - **Understanding the Problem**:
      - The goal was to check if a list can be split into two subsets with an equal sum, a common problem in dynamic programming and recursion.

    - **Recursive Approach**:
      - Implemented the `can_partition_recursive(nums, target_sum, index, subset)` function, which uses recursion to explore whether a subset with a target sum can be found within the list.
      - The function considers two main scenarios: excluding the current number from the subset and including it, then recursively checks the remaining elements.

    - **Base Case Handling**:
      - The base cases include situations where the target sum becomes zero (indicating a successful partition) or when all elements are considered, and the target sum remains unmet.

    - **Exploring Subsets**:
      - By exploring all possible combinations of the list’s elements, the algorithm identifies whether a valid subset exists that equals half the total sum, thus confirming if the list can be partitioned into two equal subsets.

    - **Output and Visualization**:
      - If a valid partition is found, the program outputs the subsets, providing a clear visual representation of the solution.

  * This project reinforced key concepts in recursive problem-solving and subset exploration, offering a deeper understanding of how to approach partitioning problems with Python. The recursive approach not only highlights the power of recursion in combinatorial problems but also emphasizes the importance of base case management and backtracking in algorithm design.
* Day 172: 🏀 Basketball Player Statistics Generator with Python 📊

  * Today, I developed a Python program that allows users to input basic basketball statistics for a player (points, rebounds, assists) and calculates key metrics such as averages per game, shooting percentages, and more. This project provided an excellent opportunity to work with object-oriented programming and data visualization. Below is a summary of the key tasks and insights:

    - **Understanding the Problem**:
      - The goal was to create a system where users can input game statistics for basketball players and easily calculate and visualize key metrics, such as points per game, rebounds per game, assists per game, and shooting percentages.

    - **Class-Based Approach**:
      - Implemented the `BasketballPlayer` class, which tracks a player's game statistics, calculates averages, and computes shooting percentages. The class structure allowed for a clean and modular design, making it easy to manage and update player stats.

    - **Data Input and Handling**:
      - The program features a menu-driven interface that allows users to create players, select existing players, and input game statistics. This interactive approach ensures that the program is user-friendly and can handle multiple players seamlessly.

    - **Statistics Calculation**:
      - The `calculate_averages` method computes the player's averages per game for points, rebounds, and assists, while the `calculate_shooting_percentage` method determines the shooting accuracy based on the shots made and attempted. These calculations are crucial for analyzing player performance.

    - **Data Visualization**:
      - The `plot_stats` method uses Matplotlib to generate bar charts that visually represent the player's statistics. This feature enhances the program by providing a graphical interpretation of the data, making it easier to identify trends and performance levels.

  * This project reinforced my understanding of object-oriented programming, particularly in the context of sports statistics. The integration of data visualization added an extra layer of insight, demonstrating the value of combining algorithmic calculations with graphical outputs. I'm excited to explore further enhancements, such as incorporating advanced metrics and player comparisons.
* Day 173: 🎵 Discord Music Bot with Python and discord.py 🎶

  * Today, I developed a Discord music bot using Python, `discord.py`, and `yt-dlp`. This bot allows users to play and manage music in a voice channel, providing functionalities such as queuing songs, playing the next track, and skipping the current song. Here’s a summary of the key tasks and insights:

    - **Understanding the Problem**:
      - The goal was to create a Discord bot that can play audio from YouTube in a voice channel. The bot should handle commands for adding songs to a queue, playing them, and managing playback.

    - **Bot Setup and Intents**:
      - Configured the bot with necessary intents to read message content and handle voice state updates. This setup ensures the bot can interact with users and manage voice connections effectively.

    - **Music Playback**:
      - Implemented the `play` command to search for a song on YouTube, retrieve its URL, and add it to a queue. The bot connects to the user's voice channel if it is not already connected.

    - **Queue Management**:
      - Developed a queue system to manage song playback. The `play_next` method handles playing the next song in the queue and automatically continues playback when a song ends.

    - **Error Handling**:
      - Incorporated error handling to manage issues that may arise during the search and playback process, providing users with clear feedback if something goes wrong.

    - **Skipping Songs**:
      - Added a `skip` command to stop the currently playing song and move to the next one, enhancing the bot's usability.

  * This project provided valuable experience in integrating Discord's API with audio streaming, handling asynchronous tasks, and implementing user commands. The bot's functionality showcases the practical application of Python in creating interactive and useful tools for Discord communities.
* Day 174: Technical Test "getPermutation" and "rotateRight" [LeetCode](https://leetcode.com/problems/)

  - **getPermutation**: Implemented a solution for the "Permutation Sequence" problem, where the task is to return the k-th permutation sequence of numbers from 1 to n. The approach involves calculating the factorial of n to determine the number of permutations for each block of numbers. The solution uses this factorial to pick the correct digit for each position in the permutation and progressively builds the k-th sequence by updating k for the next position. The algorithm efficiently finds the desired permutation by reducing the search space with each step. The time complexity is O(n²) due to the factorial computations and list manipulations.  
    [Problem Description: getPermutation](https://leetcode.com/problems/permutation-sequence/description/)

  - **rotateRight**: Solved the "Rotate List" problem, where the objective is to rotate a linked list to the right by k places. The algorithm first calculates the length of the list and makes it circular by connecting the last node to the head. Afterward, it determines the new tail and head by traversing the list based on the modulo of k with the list length. The final step involves breaking the circular connection to form the rotated list. This method has a time complexity of O(n), where n is the length of the list.  
    [Problem Description: rotateRight](https://leetcode.com/problems/rotate-list/description/)
* Day 175: Build Your Own News Hub in Python - RSS Feed Aggregator by [NeuralNine](https://www.youtube.com/watch?v=5mEmE7pBI1A)

  * Today, I worked on a project to create an RSS Feed Aggregator using Python and Flask, inspired by a [NeuralNine](https://www.youtube.com/watch?v=5mEmE7pBI1A) tutorial. This project fetches and displays news articles from multiple sources in a user-friendly interface. Here's a breakdown of the key components and features:

    - **User Interface**:
      - Developed a simple web interface with HTML templates and Flask, allowing users to browse the latest news articles from different sources.
      - Implemented a search functionality that enables users to look for specific keywords across the fetched news articles.

    - **RSS Feed Parsing**:
      - Used the `feedparser` library to fetch and parse RSS feeds from various news sources such as Yahoo Finance, Hacker News, Wall Street Journal, and CNBC.
      - Dynamically displayed the fetched articles in a paginated format, allowing for better user experience when browsing through large sets of articles.

    - **Search Functionality**:
      - Added a search form to the header of the website, enabling users to input a keyword and retrieve relevant articles containing that term.
      - Filtered the RSS feed entries to match the search query, displaying the results in a dedicated search results page.

    - **Pagination**:
      - Implemented a pagination system that divides articles into pages, showing 10 articles per page. Users can navigate between pages using the “Next” and “Previous” buttons.

    - **Technical Implementation**:
      - The back-end logic was implemented in Python using the Flask framework, while HTML was used for the front-end.
      - The project makes use of RSS feeds and dynamically updates the content based on the fetched data.
      - Designed reusable HTML templates with `base.html` providing a consistent layout, and specific pages like `index.html` and `search_results.html` handling different types of content.

  * This project was an excellent exercise in integrating multiple technologies, including Flask for web development, RSS feeds for content aggregation, and HTML for building dynamic and responsive web pages. It provided a great opportunity to work on creating a functional news hub with real-time data.
* Day 176: 🔺 Maximum Sum Path in a Triangle - Recursive Algorithm 🔺

  * Today, I worked on a Python program that finds the maximum sum path from the top to the bottom of a triangle using recursion. The project focused on applying recursive techniques to explore different paths and choose the one with the maximum sum. Below is an overview of the key components and insights:

    - **Understanding the Problem**:
      - The goal was to navigate a triangle from the top to the bottom, selecting adjacent numbers in each row, and calculating the maximum possible sum along the way.

    - **Recursive Approach**:
      - Implemented the `max_sum_path(triangle, row, col, n)` function to recursively calculate the maximum sum path by exploring two possible moves: directly below or diagonally to the right.
      - At each step, the function returns the maximum sum path by comparing the two possible paths (left and right).

    - **Base Case Handling**:
      - The base case occurs when the recursion reaches the last row of the triangle, where the function simply returns the value of the current element.
      - This ensures the recursion terminates when all rows are processed.

    - **Initiating the Recursion**:
      - The `find_max_sum(triangle)` function initiates the recursive process from the top of the triangle, passing the necessary parameters to the recursive function to explore all paths.

    - **Output and Visualization**:
      - The program prints the maximum sum path from the top to the base of the triangle, providing a clear indication of the optimal path for maximizing the sum.

  * This project was a great way to apply recursive problem-solving to a real-world mathematical challenge. It also reinforced the importance of recursion in exploring all possible combinations and selecting the optimal solution, offering valuable insights into dynamic programming techniques as well.
* Day 177: 📂 File System Management in Python 🖥️

  Today, I worked on a File System Management project using Python, which focused on applying Object-Oriented Programming (OOP) principles like inheritance, encapsulation, and abstraction to manage files and folders. Here are the key highlights of the project:

  - **Encapsulation**: The `FileSystemItem` class encapsulates the attributes `name` and `path`, making them private to ensure data protection. Getter methods provide controlled access to these attributes.

  - **Inheritance**: The `File` and `Folder` classes inherit from the abstract base class `FileSystemItem`. This ensures that both files and folders have common attributes and behaviors, promoting code reusability.

  - **Abstraction**: The `FileSystemItem` class includes an abstract method `get_description`, which is implemented differently by `File` and `Folder` classes to return specific details about each item. This maintains a consistent interface while allowing customized behavior for different types of items.

  - **File and Folder Operations**: Users can register new files and folders, check their details, and perform operations on files (such as reading or writing). A menu-driven interface makes interaction with the system user-friendly and practical.

  - **File System Interaction**: The project interacts with the actual file system, checking if the paths provided for files and folders exist and retrieving file sizes. This adds a layer of real-world utility by directly integrating with the operating system.

  - **File Operations**: The `FileOperation` class logs operations performed on files (such as read, write, or execute), along with the date of the operation, providing a history of interactions with each file.

  This project provided a practical implementation of OOP concepts and demonstrated how they can be used to build scalable and structured systems. It was a great opportunity to reinforce my understanding of how inheritance, encapsulation, and abstraction contribute to clean, maintainable code in real-world applications.

* Day 178: 🛒📊 Customer Purchasing Behaviors [Kaggle](https://www.kaggle.com/datasets/hanaksoy/customer-purchasing-behaviors/data)

  * Today, I worked with the Customer Purchasing Behaviors dataset from Kaggle, focusing on data analysis and visualization. Below is a summary of the key activities and insights obtained:

    - **Data Loading**:
      - Imported the dataset using Pandas and conducted an initial examination to understand the data structure and key features.

    - **Data Cleaning**:
      - Checked for missing values and ensured the data's integrity.
      - Performed data type conversions, particularly for dates and categorical variables, to facilitate analysis.
    
    - **Exploratory Data Analysis (EDA)**:
      - **Categorical Features**:
        - Created count plots for various features like product categories, customer segments, and purchase channels.
        - Analyzed the distribution of customer segments and product categories using pie charts.
        - Investigated the frequency of purchases across different days, months, and customer segments to identify trends.
      - **Numerical Features**:
        - Analyzed the distribution of total spending by customer and product category using box plots and bar charts.
        - Visualized the average and median purchase amounts across different customer segments and product types.
      - **Time Series Analysis**:
        - Explored how purchasing behaviors varied by time of day, day of the week, and month.
        - Created visualizations showing the distribution of purchases over time, including monthly and daily trends.

    - **Advanced Visualizations**:
      - Utilized Plotly to create interactive visualizations such as heatmaps for purchase frequency across different days and customer segments.
      - Generated detailed bar charts and sunburst plots to explore customer purchase patterns by product category and segment.
      - Used seaborn and Matplotlib to produce enhanced count plots, box plots, and time series graphs for deeper insights.

  * This analysis provided valuable insights into customer purchasing behaviors, including trends across product categories, spending patterns, and customer segments. The visualizations helped uncover key patterns that can guide marketing and sales strategies for businesses looking to optimize their offerings based on customer data.
* Day 179: Movie Recommendation App with Streamlit  
  * Today, I focused on building a **Movie Recommendation App** using Streamlit, a powerful open-source framework designed for creating web applications. The app allows users to select a movie genre and receive recommendations based on a dataset of movies. Here's a breakdown of what I accomplished:

    - **Setting Up the Environment**: Installed Streamlit and other necessary libraries like Pandas for data manipulation.
    - **Dataset**: Used a dataset from [Kaggle](https://www.kaggle.com/datasets/akshaypawar7/millions-of-movies) that contains information about millions of movies, including genres, ratings, release dates, and more.
    - **Loading Data Efficiently**: Implemented data caching using `st.cache_data` to improve performance when loading the movie dataset.
    - **User Interface**: Built an intuitive UI where users can:
      - Preview the movie dataset, showing details like title, genres, release date, rating, and vote count.
      - Select a movie genre from a dropdown menu and receive a list of recommended movies from that genre.
    - **Movie Filtering and Display**: Filtered the movies by genre and displayed each recommendation with details such as the title, release year, rating, vote count, and a brief overview. Additionally, the app displays the movie poster fetched from an external source.
    - **Sidebar with Additional Information**: Created a sidebar that provides information about the app and some statistics about the dataset, including the total number of movies and the top 5 highest-rated films.
  
  This project highlights the ease of using Streamlit to build interactive applications with dynamic content based on user input. The recommendation feature provides a practical use case for filtering and displaying data, making it a helpful tool for exploring movie options by genre. 

  This was an excellent exercise in building a recommendation system, working with movie datasets, and creating a user-friendly interface.
* Day 180: Technical Test "uniquePaths" and "uniquePathsWithObstacles" [LeetCode](https://leetcode.com/problems/)
  
  - **uniquePaths**: Implemented a solution for the "Unique Paths" problem, where the task is to determine the number of unique paths a robot can take to reach the bottom-right corner of an m x n grid, starting from the top-left corner. The robot can only move either right or down at any point. The approach uses dynamic programming to compute the number of ways to reach each cell in the grid by adding the number of ways to reach the top and left cells. The solution has a time complexity of O(m * n) as we fill up the grid iteratively.
    [Problem Description: uniquePaths](https://leetcode.com/problems/unique-paths/description/)

  - **uniquePathsWithObstacles**: Solved the "Unique Paths II" problem, which is an extension of the "Unique Paths" problem but introduces obstacles in the grid, marked as 1. The robot must avoid these obstacles when moving to the bottom-right corner. The algorithm uses a modified dynamic programming approach to track valid paths, ensuring that any cell marked with an obstacle is not considered in the path calculation. The time complexity remains O(m * n), as the grid is processed similarly to the first problem but with obstacle checks.
    [Problem Description: uniquePathsWithObstacles](https://leetcode.com/problems/unique-paths-ii/description/)

* Day 181: 🏀 Basketball Team Generator and Visualizer with Python 📊

  * Today, I developed a Python program that generates a team of random basketball players and visualizes their statistics using various charts. This project allowed me to explore data generation, visualization, and file handling in Python. Here’s a summary of the key tasks and insights:

    - **Understanding the Problem**:
      - The objective was to create a system that generates random basketball player statistics and provides visualizations for analysis. The program includes functionalities to generate player data, display it in graphical formats, and optionally save the generated data to a file.

    - **Player Generation**:
      - Implemented the `generate_player` function to create random player profiles, including attributes such as name, height, position, and performance metrics like points per game, rebounds, assists, and field goal percentage. This function uses the `random` library to ensure that each player’s statistics are unique and realistic.

    - **Data Visualization**:
      - The `plot_player_stats` function creates a polar bar chart using Matplotlib to visualize rebounds, assists, and field goal percentage. This chart helps in comparing these metrics in a circular format, making it easier to see the distribution of stats.
      - The `plot_points` function generates a separate bar chart to display the points scored per game by each player. This visualization highlights the player's scoring ability in a straightforward bar format.

    - **Team Creation and Saving**:
      - The `create_team` function generates a list of random players based on user input for the number of players. This feature allows for flexible team sizes.
      - The `save_team` function saves the generated team data to a text file, making it easy to store and review the player information later. The data is written in a human-readable format, providing a comprehensive view of each player’s attributes.

    - **Interactive User Experience**:
      - The main program includes user prompts to determine the number of players to generate and whether to save the team data. This interactive approach ensures that the program can be used effectively based on user preferences.

  * This project provided valuable experience in combining data generation with visualization techniques. By integrating polar and bar charts, the program offers a comprehensive view of player statistics. The file-saving feature also enhances the program’s usability by allowing users to store and manage player data efficiently. Moving forward, I plan to explore additional enhancements, such as advanced statistical analyses and more sophisticated visualizations.
* Day 182: 🍽️ Restaurant Management System in Python 🍴

  Today, I worked on a Restaurant Management System using Python, with a focus on Object-Oriented Programming (OOP) principles such as inheritance, encapsulation, and abstraction. The project allows customers to place orders, manage food and drinks, calculate tips, and keep track of the server responsible for each order. Below are the key highlights:

  - **Encapsulation**: The `Person` class encapsulates attributes like `name` and `id_number`, ensuring that personal information is protected by making them private. Controlled access is provided through getter methods.

  - **Inheritance**: The system uses inheritance for customer and server classes, both derived from the `Person` abstract class. This allows reusability of common attributes (like `name` and `id_number`) while providing specialized functionality for each subclass.

  - **Abstraction**: The `Person` class contains an abstract method `get_description`, which is implemented by both `Customer` and `Server` classes. This ensures that each type of person in the system has a tailored description, maintaining a consistent interface.

  - **Order Management**: Customers can place orders that include food, drinks, and optional tips. The `Order` class captures details like order number, total price, and the server assigned to the order. This makes the system easy to extend with new features in the future.

  - **Billing and Tips**: The system calculates the total bill based on the items ordered, with an option to add a tip. The final payment amount is clearly displayed, offering both customer satisfaction and ease of tracking for the restaurant.

  - **Menu Options**: A menu-driven interface allows for interaction with the system, where users can place orders, check order details, and calculate the final bill. This makes the program user-friendly and practical for a real restaurant scenario.

  This project was an excellent exercise in applying OOP principles to create a well-structured and maintainable system. I had the opportunity to refine my understanding of how abstraction, encapsulation, and inheritance work together to create clean and reusable code, all while building a practical restaurant management tool.


* Day 183: 🌊 Crossing the River Problem - Recursive Solution 🌊

  * Today, I developed a Python program that solves the classic **Crossing the River Problem** using a recursive approach. This problem involves moving a farmer, a wolf, a goat, and a cabbage across a river with specific constraints, ensuring no dangerous combinations are left unsupervised. Here's an overview of the key components and insights from this project:

    - **Understanding the Problem**:
      - The goal is to transport the farmer, the wolf, the goat, and the cabbage from the left bank of the river to the right bank using a boat. However, there are restrictions:
        - The wolf cannot be left alone with the goat.
        - The goat cannot be left alone with the cabbage.
        - Only two items (the farmer and one other) can cross the river at a time.

    - **Recursive Approach**:
      - Implemented the `solve(state, path=[])` function to recursively explore possible moves while ensuring the state remains valid after each crossing.
      - The program explores all possible combinations of moves, considering the constraints and checking if the goal state (all items on the right bank) is achieved.

    - **State Validation**:
      - A helper function `is_valid_state(state)` ensures that no illegal combinations occur on either bank when the farmer is absent. This prevents situations where the goat is eaten by the wolf or the cabbage is eaten by the goat.

    - **Recursive Movement**:
      - The `move_item(state, item)` function moves the farmer and an optional item between the banks. The recursion avoids revisiting the same state to ensure efficiency.

    - **Goal Achievement**:
      - The base case occurs when all objects are successfully transported to the right bank, and the recursion terminates with the correct solution path.

    - **Output and Visualization**:
      - The program prints each step of the solution, showing the left and right bank configurations after each crossing, leading to the final state where all items have crossed safely.
* Day 184: Technical Test "minPathSum" and "isNumber" [LeetCode](https://leetcode.com/problems/) 

  - **minPathSum**: Implemented a solution for the "Minimum Path Sum" problem, where the task is to find the path from the top-left corner to the bottom-right corner of a grid that minimizes the sum of all numbers along the path. The robot can only move either right or down at any point in time. The approach uses dynamic programming to iteratively update the grid by calculating the minimum sum required to reach each cell. The time complexity is O(m * n), where m and n represent the dimensions of the grid.
    [Problem Description: minPathSum](https://leetcode.com/problems/minimum-path-sum/description/)

  - **isNumber**: Solved the "Valid Number" problem, which validates if a given string can be interpreted as a valid number according to specific rules, including handling integers, decimal numbers, and exponents. The solution uses regular expressions to match the structure of valid numbers, ensuring correct handling of edge cases such as signs, decimal points, and scientific notation. The solution processes the string in O(1) time, as regular expressions offer an efficient way to match the pattern.
    [Problem Description: isNumber](https://leetcode.com/problems/valid-number/description/)
* Day 185: Estimating Pi with Monte Carlo Method
  Today, I focused on building a Python program to estimate the value of **Pi** using the **Monte Carlo** method. This method involves generating random points in a unit square and calculating how many fall within a unit circle to estimate the value of Pi. Here's a breakdown of what I accomplished:

  - **Importing Libraries**: Utilized essential Python libraries like `matplotlib` for plotting and `numpy` for generating random points and mathematical calculations.
    
  - **Monte Carlo Method Implementation**:
    - Created a function `pi_montecarlo(n, n_exp)` where:
      - `n` represents the number of random points generated per experiment.
      - `n_exp` represents the number of experiments to perform.
    - For each experiment, the program generates random `(x, y)` points between 0 and 1.
    - It calculates the distance of each point from the origin and checks whether the point lies inside the unit circle.
    - Repeated the experiment `n_exp` times and averaged the results to get a more accurate estimate of Pi.

  - **Visualizing the Results**:
    - Plotted the estimated values of Pi over multiple experiments to observe how the accuracy improves as the number of experiments increases.
    - The final plot includes:
      - Estimated values of Pi for each experiment.
      - Clear labels for the x-axis (Experiment Number) and y-axis (Estimated Pi).
      - A title to make the plot more informative: "Estimated Pi Values over Experiments."
    
  - **Program Execution**:
    - Ran the function with 10,000 points per experiment and 200 experiments.
    - Displayed the average estimated value of Pi and plotted the results for visualization.

  This project provides an excellent example of applying statistical techniques to estimate a mathematical constant. The Monte Carlo method demonstrates how random sampling can be used to approximate complex values with increasing accuracy as more data points are used.
* Day 186: BMI Calculator in Python - Flask Application
  * Today, I worked on building a simple BMI (Body Mass Index) calculator using Python and Flask. This project allows users to input their weight and height, calculate their BMI, and receive a health category based on the result. Below is a breakdown of the key components and features:

    - **User Interface**:
      - Developed a clean and minimalistic web interface using HTML and CSS. The form takes the user’s weight (in kilograms) and height (in meters) as inputs and calculates the BMI upon form submission.
      - Implemented responsive design with a focus on user-friendliness, ensuring the form and results are clearly visible on both desktop and mobile devices.

    - **BMI Calculation**:
      - Used a simple formula to calculate BMI: `BMI = weight / (height^2)` where weight is in kilograms and height is in meters.
      - Displayed the calculated BMI along with a corresponding health category:
        - **Underweight**: BMI less than 18.5
        - **Normal weight**: BMI between 18.5 and 24.9
        - **Overweight**: BMI between 25 and 29.9
        - **Obesity**: BMI of 30 or higher

    - **Result Display**:
      - After submitting the form, the user is shown their calculated BMI and the associated health category (e.g., "Normal weight").
      - Implemented condition-based formatting for better visual feedback. For example, different BMI categories are highlighted with different colors for clarity.

    - **Technical Implementation**:
      - The back-end logic is written in Python using the Flask framework, which processes the input data, calculates the BMI, and renders the result back to the user.
      - A `POST` method was used to handle form submission and calculation. The results are dynamically displayed using Jinja2 templates.
      - The front-end includes a `style.css` file in the `/static/css` directory to ensure the application has a clean, modern look.

    * This project was a great opportunity to further enhance my Flask skills while building a practical health-related application. It provided insights into form handling, dynamic content generation, and simple calculations based on user input.
* Day 187: 🎲 Lottery Simulator in Python 🎯 

  Today, I worked on a Lottery Simulator using Python and Tkinter, creating a graphical interface for users to choose their lottery numbers and check if they match randomly generated lottery results. Below are the key highlights of the project:

  - **User Input**: The program allows users to input six unique numbers between 1 and 49. These numbers are validated to ensure they meet the required conditions, such as being within the range and not repeating.

  - **Random Number Generation**: The program generates six random lottery numbers using Python's `random.sample` function, ensuring that each number is unique. These numbers are then compared with the user's input.

  - **Matching Logic**: The user’s input is compared with the randomly generated lottery numbers, and the number of matches is displayed in a message box. If all six numbers match, a congratulatory message appears, declaring the user as the winner.

  - **Graphical User Interface (GUI)**: The program uses Tkinter to create a simple and clean interface. The layout is organized with entry boxes for user input and a button that triggers the lottery check. The interface includes:
    - **Entry Fields**: Six entry fields for users to input their numbers.
    - **Lottery Check Button**: A button that checks the user's numbers against the generated lottery numbers and displays the result.
    - **Message Box**: A message box to display the outcome, whether it's a win or how many numbers matched.

  - **Error Handling**: The system handles input errors gracefully, ensuring that users input valid numbers and receive informative messages if they don't.
* Day 188: Technical Test "addBinary" and "plusOne" [LeetCode](https://leetcode.com/problems/) 
  - **addBinary**: Implemented a solution for the "Add Binary" problem, which involves adding two binary strings and returning their sum as a binary string. The approach processes the binary strings from right to left, simulating manual addition by summing digits and tracking carry. The solution handles cases where the strings have different lengths and ensures that any remaining carry is accounted for in the final result. The time complexity is O(max(n, m)), where n and m are the lengths of the input strings.
    [Problem Description: addBinary](https://leetcode.com/problems/add-binary/description/)

  - **plusOne**: Solved the "Plus One" problem, where the task is to increment an integer represented by an array of its digits. The algorithm starts from the least significant digit and adds one, adjusting for carries as necessary. If the entire number consists of nines, a new digit is added at the beginning of the array. The time complexity is O(n), where n is the number of digits in the input array.
    [Problem Description: plusOne](https://leetcode.com/problems/plus-one/description/)
* Day 189: 🔍 Longest Common Subsequence (LCS) 

  Today, I worked on the Longest Common Subsequence (LCS) problem using Python, focusing on recursion to solve the problem. This algorithm finds the longest subsequence common between two given strings. Below are the key highlights:

  - **Recursion**: The solution is implemented using a recursive approach. The base case checks if either of the strings is empty, in which case the LCS is zero. Otherwise, the function compares the last characters of both strings.

  - **Character Matching**: If the last characters of the two strings match, the function proceeds by removing the last character from both strings and recursively calling itself. The result is incremented by 1, indicating that the matched character contributes to the LCS.

  - **Character Mismatch**: When the last characters differ, the algorithm explores two options: removing the last character from one of the strings and calling the function recursively on the remaining parts of the strings. The maximum result from these two recursive calls is taken as the LCS length.

  - **Efficiency**: This recursive approach, while intuitive, is not the most efficient for large strings due to its exponential time complexity. However, it serves as a clear demonstration of how recursion can be applied to complex problems like LCS.

  - **Base Cases**: The base cases are crucial to the recursive approach. When either string is reduced to an empty substring, the recursion stops, ensuring that the solution does not continue indefinitely.

  - **Example Case**: For the strings `"AGGTAB"` and `"GXTXAYB"`, the algorithm correctly identifies that the LCS is `"GTAB"` with a length of 4.

  - **Future Enhancements**: This recursive solution can be further optimized using dynamic programming techniques to avoid redundant calculations, making it feasible for larger inputs.

  This project was an excellent opportunity to deepen my understanding of recursion in Python. I explored how breaking down a problem into subproblems can simplify the overall structure, even when the solution is not the most optimal. I look forward to extending this solution with dynamic programming to handle more complex cases efficiently.
* Day 190: 🧠 MNIST Neural Network with Hyperparameter Tuning in Python 🤖
  Today, I worked on building a neural network model using Python and TensorFlow to classify handwritten digits from the MNIST dataset. This project is based on the amazing work and tutorial by **NeuralNine**, which I followed on [YouTube](https://www.youtube.com/watch?v=lKusotIjzwk). I respect and admire the quality of content NeuralNine provides, and this tutorial was a fantastic learning experience. Below are the key highlights:

  - **Model Architecture**: The neural network consists of an input layer, a flattening layer to convert the 2D images into a 1D vector, hidden layers with ReLU activation functions, and a final output layer using softmax activation for multiclass classification. This architecture allows the network to learn complex features of the handwritten digits.

  - **Normalization**: The input data was normalized to ensure that the values fall between 0 and 1, which helps the model converge faster and improves accuracy during training.

  - **Adam Optimizer**: The model is trained using the Adam optimizer, with a learning rate of 0.005. Adam is well-suited for large datasets and adjusts the learning rate dynamically, leading to faster convergence.

  - **GridSearchCV**: I implemented hyperparameter tuning using GridSearchCV from scikit-learn, which allowed me to search for the best combination of hyperparameters such as the number of hidden layers, the number of neurons per layer, and batch normalization/dropout options. This optimization process helps in finding the model with the highest accuracy on the test set.

  - **Dropout and Batch Normalization**: The project includes options to add dropout layers and batch normalization to prevent overfitting and ensure that the model generalizes well to unseen data.

  - **Model Evaluation**: The model was evaluated using the test dataset after training. Accuracy and loss were calculated to assess the model’s performance, ensuring that it classifies the digits with high precision.

  - **Hyperparameter Tuning Results**: After running GridSearchCV, the best model was selected based on the highest accuracy score. The optimal hyperparameters, such as the number of hidden layers and neurons, were determined and applied to improve the model's performance.

  This project was a valuable exercise in neural network construction, model optimization, and hyperparameter tuning using scikit-learn. I learned a lot from NeuralNine's tutorial, and I deeply respect their commitment to delivering high-quality educational content.
* Day 191: 🚗 Vehicle Management System in Python 🚙
  Today, I developed a Vehicle Management System using Python, incorporating Object-Oriented Programming (OOP) principles such as inheritance, encapsulation, and abstraction. The project allows for the registration and management of different types of vehicles, such as Sports Cars, Minivans, and more. Below are the key highlights of the project:

  - **Encapsulation**: The `Vehicle` class encapsulates attributes like `make`, `model`, and `license_plate`, ensuring that sensitive information is protected by making them private. Controlled access is provided through getter methods, allowing secure data handling.

  - **Inheritance**: The system employs inheritance for different vehicle categories, such as `SportsCar` and `Minivan`, both derived from the base `Vehicle` class. This design allows for reusability of common attributes (like `make` and `model`) while providing specialized functionality for each subclass, enhancing flexibility and scalability.

  - **Abstraction**: The `Vehicle` class contains an abstract method `get_description`, which is implemented by each specific vehicle category. This ensures that every type of vehicle in the system has a tailored description, maintaining a consistent interface and making the code easily extensible.

  - **Category Management**: The system allows users to register vehicles in various categories (Sports Car, Minivan, etc.), record details such as mileage, owner information, and maintenance history, and retrieve comprehensive vehicle data. This feature-rich structure provides a realistic scenario for a vehicle management application.

  - **Data Handling**: The system tracks key details such as vehicle types, mileage, and ownership history. It also includes methods to retrieve and display this data in an organized manner, simulating a real-world vehicle management scenario.

  - **Menu Options**: A menu-driven interface facilitates interaction with the system, allowing users to register new vehicles, display vehicle details, and manage various aspects of each vehicle category. This makes the program user-friendly and practical for real-world applications.

  This project was an excellent exercise in applying OOP principles to create a structured and maintainable system. It provided a great opportunity to deepen my understanding of how abstraction, encapsulation, and inheritance can be effectively used to build a versatile and efficient vehicle management tool.


* Day 192: 💤💪 Health and Sleep Statistics [Kaggle](https://www.kaggle.com/datasets/hanaksoy/health-and-sleep-statistics/data) 

  * Today, I worked with the Health and Sleep Statistics dataset from Kaggle, focusing on data analysis and visualization. Below is a summary of the key activities and insights obtained:

    - **Data Loading**:
      - Imported the dataset using Pandas and conducted an initial examination to understand the data structure and key features.

    - **Data Cleaning**:
      - Checked for missing values and ensured the data's integrity.
      - Performed data type conversions, especially for dates and numerical fields, to prepare the data for analysis.

    - **Exploratory Data Analysis (EDA)**:
      - **Sleep and Health Analysis**:
        - Analyzed sleep patterns, including average sleep duration and sleep efficiency.
        - Created visualizations to explore relationships between sleep duration and factors like age, gender, and activity levels.
        - Investigated correlations between health metrics such as BMI, daily steps, and sleep quality.
      - **Physical Activity Insights**:
        - Visualized the distribution of daily steps, calories burned, and active minutes across different age groups and genders.
        - Explored the relationship between physical activity and sleep quality using scatter plots and heatmaps.
      - **General Health Metrics**:
        - Examined the distribution of BMI, resting heart rate, and other health indicators.
        - Generated insights into how these health metrics are influenced by sleep patterns and activity levels.

    - **Advanced Visualizations**:
      - Utilized Plotly to create interactive visualizations, such as:
        - **Heatmaps**: Showing correlations between sleep efficiency, activity levels, and health metrics.
        - **Line Graphs**: Illustrating trends in sleep duration and physical activity over time.
      - Developed sunburst plots and bar charts to provide deeper insights into health statistics across different demographics.

  * This analysis provided valuable insights into how sleep patterns and physical activity are connected to overall health. The visualizations revealed important trends and correlations that can be beneficial for individuals aiming to improve their health and sleep habits.
* Day 193: 🔍 Anagram Finder in Python 🧩 

  Today, I worked on an Anagram Finder project using Python. This program is designed to find all valid anagrams of a given set of letters based on a predefined dictionary, applying concepts of recursion and permutation generation. Below are the key highlights of the project:

  - **Dictionary Loading**: The program uses a text file `dictionary.txt` containing a list of valid words, which is loaded into a set. This enables fast lookup operations and ensures that only valid words are considered as anagrams.

  - **Permutation Generation**: By utilizing Python's `itertools.permutations` module, the program generates all possible permutations of the input letters, efficiently producing every combination without requiring manual iteration. This approach captures all potential anagram candidates in a compact manner.

  - **Anagram Validation**: Each generated permutation is checked against the loaded dictionary to determine if it forms a valid word. This step ensures that only meaningful words are included in the list of anagrams, filtering out nonsensical combinations.

  - **User Input and Output**: The system prompts the user to enter a set of letters and then displays all valid anagrams found in the dictionary. This interactive feature makes the program engaging and easy to use.

  - **Efficiency**: By using sets and efficient permutation generation, the program is optimized to handle larger sets of letters with minimal computational overhead, demonstrating the practical use of data structures and algorithm optimization.
  
  This project was an excellent opportunity to explore permutation generation and apply dictionary lookups efficiently. It provided valuable insights into handling recursive problems, optimizing data handling, and integrating external data into a Python program.
* Day 194: Technical Test "fullJustify" and "mySqrt" [LeetCode](https://leetcode.com/problems/)

  - **fullJustify**: Implemented a solution for the "Text Justification" problem, where the task is to format a list of words such that each line has exactly `maxWidth` characters and is fully justified. The solution packs words into lines using a greedy approach, ensuring that spaces are distributed as evenly as possible between words. For the last line, the text is left-justified, with any remaining spaces added to the end. The implementation efficiently handles the distribution of spaces, achieving the desired justification in O(n) time complexity, where n is the total number of words.
    [Problem Description: fullJustify](https://leetcode.com/problems/text-justification/description/)

  - **mySqrt**: Solved the "Sqrt(x)" problem, which involves finding the square root of a non-negative integer `x` rounded down to the nearest integer. The solution employs a binary search approach to efficiently calculate the integer square root without using built-in exponent functions or operators. The algorithm has a time complexity of O(log x), making it well-suited for handling large values of `x`.
    [Problem Description: mySqrt](https://leetcode.com/problems/sqrtx/description/)
* Day 195: 📊 Final Exam Score Calculator in Python 🎓 

  Today, I worked on a Final Exam Score Calculator using Python and Tkinter, with a strong emphasis on user interactivity, data validation, and GUI design principles. This project helps students calculate the required score for their final exam to pass their course, considering their current grades and weights. Here are the key highlights:

  - **User Interactivity**: The calculator provides an intuitive and dynamic interface for adding multiple scores and percentages. Users can easily input their grades and the corresponding weights, making the experience user-friendly and practical.

  - **Data Validation**: The system includes robust data validation to ensure that scores and percentages are within the allowed ranges (0.0 - 5.0 for scores and 0 - 100 for percentages). This ensures accurate calculations and prevents errors, with clear error messages guiding the user.

  - **Dynamic Entry Management**: The project allows users to add multiple input fields dynamically, making it adaptable for different scenarios. The entries can be reset at any time, allowing for multiple calculations without restarting the application.

  - **Progress Tracking**: A progress bar visually represents the total percentage of completed coursework, providing users with immediate feedback on how much weight they have already accumulated and how much is still required.

  - **Result Display**: The program calculates the score needed on the final exam and provides motivational feedback based on the result. This helps users understand their current standing and what they need to achieve to pass.

  - **Motivational Feedback**: The application offers encouraging messages based on the required final score, helping students stay motivated regardless of their current standing. This feature adds a personalized and supportive touch to the tool.

  This project was a fantastic opportunity to enhance my skills in GUI programming with Tkinter, focusing on data validation, dynamic UI updates, and user experience design. It demonstrates how practical applications can be created using Python to solve everyday problems, such as managing academic goals effectively.
* Day 196: 🧩 Sudoku Solver in Python 🔢 

  Today, I worked on a Sudoku Solver using Python, focusing on recursion and backtracking techniques. This project aimed to solve a 9x9 Sudoku puzzle while respecting the rules of the game. Below are the key highlights:

  - **Recursion**: The solution uses a recursive function to attempt filling the Sudoku grid cell by cell. If a valid number can be placed in a cell, the function proceeds to solve the rest of the grid recursively.

  - **Backtracking**: If a conflict arises or no valid number can be placed in a cell, the algorithm backtracks, resetting the cell and trying the next possible number. This systematic approach ensures that all possibilities are explored until the puzzle is solved.

  - **Sudoku Validation**: The solver includes a validation method that checks if placing a number in a specific row, column, or 3x3 grid adheres to the game's rules. This ensures that no invalid placements are made during the solving process.

  - **Grid Representation**: The Sudoku puzzle is represented as a 9x9 grid, where empty cells are denoted by `0`. The program attempts to fill these cells while respecting the constraints, ultimately arriving at a valid solution.

  - **Efficient Backtracking**: By using efficient backtracking, the solver quickly finds solutions to even the most complex puzzles. This process ensures that the program is both effective and optimized for speed.

  - **User Interface**: The project includes a simple function to display the Sudoku board before and after solving, making it easy to visualize the solution process.

  This project was a great opportunity to practice and apply recursion and backtracking, fundamental techniques for solving constraint satisfaction problems. It demonstrated how powerful these techniques can be when building a solution that explores possibilities efficiently. The project also reinforced the importance of validation checks to maintain the integrity of the solution, making it a valuable learning experience.
* Day 197: 🏀 Three-Point Shot Success Calculator in Flask 🎯 

  Today, I worked on a Three-Point Shot Success Calculator using Flask, focusing on creating a basic web application that calculates the success rate of three-point shots in basketball. This project allowed me to practice essential Flask concepts and build an interactive web-based calculator. Here are the key highlights:

  - **User Input Handling**: The web application allows users to input the number of attempted and successful three-point shots through a simple HTML form. This input is processed securely on the server side, ensuring accurate calculation of the success rate.

  - **Backend Calculation**: The application captures the data and performs a calculation to determine the percentage of successful three-point shots. This demonstrates how Python can be used on the backend to handle logic and return the result to the user.

  - **Session Management**: Implemented session management using `app.secret_key`, which ensures that user data remains secure during interactions with the web application. The secret key was generated using Python's `secrets` library, demonstrating the use of cryptographic methods for secure session handling.

  - **Flask Integration**: The project utilizes Flask's routing capabilities to handle different routes (`/` for the home page and `/calculate` for processing the calculation), showcasing how Flask can manage multiple endpoints in a web application.

  - **Error Handling**: Basic error handling is included to ensure that the program reacts appropriately to invalid or missing inputs, providing a smooth user experience.

  - **Interactive Feedback**: The calculated success rate is displayed back to the user in a user-friendly format, demonstrating how server-side calculations can be rendered on a web page.

  This project was an excellent opportunity to reinforce my understanding of how Flask can be used to build simple yet functional web applications. It helped me practice session management, user input handling, and backend calculations, all while applying them to a fun and practical example in the context of basketball statistics.
* Day 198: 🐾 Cats Dataset [Kaggle](https://www.kaggle.com/datasets/waqi786/cats-dataset/data) 

  Today, I worked on analyzing the Cats Dataset from Kaggle using Python. The focus was on data exploration and visualization using libraries such as Pandas, Seaborn, and Matplotlib. The project includes generating statistical summaries, visualizing distributions of numerical and categorical variables, and analyzing correlations between features. Below are the key highlights:

  - **Statistical Summary**: The project includes a function that generates a statistical summary of numerical variables, providing insights such as mean, median, and standard deviation. This helps in understanding the central tendency and spread of the data.

  - **Categorical Distribution**: I created a function to display the distribution of categorical variables, such as breed, color, and gender of the cats. This gives a clear view of how many instances exist for each category, aiding in categorical analysis.

  - **Numerical Distributions**: The code generates histograms for numerical variables, allowing for visual inspection of their distributions. This helps identify any skewness, outliers, or normality in the data.

  - **Bar Graphs for Categorical Variables**: I implemented bar graphs to visualize the distribution of each categorical variable. This enhances the ability to quickly grasp the frequency of categories visually.

  - **Correlation Analysis**: A correlation matrix is generated to analyze relationships between numerical variables. This provides insights into potential relationships that can be explored further, and is visualized with a heatmap for clarity.

  - **User-Friendly Functions**: The project includes functions for generating the full report, making it easy to run all analyses in one go. This modular approach enhances code readability and maintainability.

  This project was an excellent opportunity to deepen my understanding of data analysis techniques in Python, as well as to explore the Cats Dataset thoroughly. The experience reinforced the importance of visualizing data to extract meaningful insights and understand underlying patterns.


* Day 199: 📚 Book Subscription System in Python 📖

  Today, I developed a Book Subscription System using Python, focusing on the Model-View-Controller (MVC) architectural pattern along with Object-Oriented Programming (OOP) principles. The project allows readers to subscribe to different book genres, view reader details, and check the information of available books. Here are the key highlights of the project:

  - **Encapsulation**: The `Person` class, which serves as a base class for `Reader` and `Author`, encapsulates attributes such as `name` and `id_number`. These attributes are private and accessed via getter methods, ensuring data protection and controlled access.

  - **Inheritance**: The system demonstrates inheritance by having `Reader` and `Author` classes inherit from the `Person` abstract class. This allows for the reuse of common attributes like `name` and `id_number`, while enabling each subclass to extend with unique functionality, such as subscribing to genres or adding books.

  - **Abstraction**: The `Person` class features an abstract method `get_description`, which is implemented by both `Reader` and `Author` classes. This ensures a consistent interface across different types of persons in the system while allowing specific details to be tailored to each subclass.

  - **MVC Pattern**: The system is structured according to the MVC pattern:
    - **Model**: Represents the core data (Person, Reader, Author, and Book) and logic of the application.
    - **View**: Handles the display of information and interaction with the user.
    - **Controller**: Manages the communication between the Model and View, processing user input and updating the Model accordingly.

  - **Book Subscription Management**: Readers can subscribe to genres, and authors can add books to the system. The `Controller` class facilitates the logic to manage these interactions, providing a seamless experience for users to interact with the system.

  - **Book Details and Reader Information**: The project includes functionality to display detailed information about books and readers, helping users keep track of their subscriptions and explore different genres.

  - **User Interaction**: A menu-driven interface allows users to navigate the system, subscribe to genres, view reader details, and access book information, making it user-friendly and practical for real-world use.

  This project was a valuable experience in applying the MVC pattern along with OOP principles to build a well-structured and maintainable application. It provided a great opportunity to strengthen my understanding of encapsulation, inheritance, and abstraction while working with an architectural design that ensures a clean separation of concerns.
* Day 200: Technical Test "climbStairs" and "simplifyPath" [LeetCode](https://leetcode.com/problems/)
  
  - **climbStairs**: Implemented a solution for the "Climbing Stairs" problem, where the task is to determine the number of distinct ways to reach the top of a staircase with `n` steps, given that you can climb either 1 or 2 steps at a time. The solution employs a dynamic programming approach similar to the Fibonacci sequence to calculate the total number of ways to reach the top efficiently. The time complexity is O(n), where `n` represents the number of steps, as it iteratively calculates the possible ways without redundant computations.
    [Problem Description: climbStairs](https://leetcode.com/problems/climbing-stairs/)

  - **simplifyPath**: Solved the "Simplify Path" problem, which requires converting an absolute Unix-style file path into its canonical form. The approach utilizes a stack to process the path components, effectively handling elements like current (`.`), parent (`..`) directories, and redundant slashes (`//`). The final solution reconstructs the canonical path with a time complexity of O(n), where `n` is the length of the path, ensuring efficient processing of all path elements.
    [Problem Description: simplifyPath](https://leetcode.com/problems/simplify-path/description/)
* Day 201: 🌊 Count Islands in a Grid Using Recursion 🏝️ 

  Today, I worked on a project that counts the number of islands in a grid using Python, focusing on recursion and depth-first search (DFS). The main objective was to identify and count all distinct "islands" in a grid represented by `1`s (land) and `0`s (water). Below are the key highlights:

  - **Recursion**: The solution uses a recursive function to traverse the grid, identifying connected land cells (`1`s). For every unvisited land cell, the function explores all 8 possible directions (up, down, left, right, and the four diagonals) to mark the entire island as visited.

  - **Depth-First Search (DFS)**: By using a DFS approach, the algorithm ensures that every part of an island is explored fully before moving to the next. This allows the algorithm to handle islands of any shape or size, ensuring accurate counting.

  - **Grid Representation**: The grid is represented as a 2D list where `1`s denote land and `0`s represent water. The function recursively marks all connected `1`s as visited (changing them to `0`s), ensuring that each island is counted only once.

  - **Efficient Island Counting**: The project efficiently iterates through the grid, invoking the DFS function each time an unvisited `1` is found. This approach minimizes the number of recursive calls and ensures that all islands are correctly identified.

  - **Handling Edge Cases**: The algorithm effectively handles edge cases, such as single-cell islands or grids with no islands at all, making it robust for different input scenarios.

  - **Example Visualization**: The project includes an example grid and prints the total number of islands found, demonstrating the algorithm's effectiveness in various configurations.

  This project provided a valuable opportunity to apply recursion in a real-world scenario, reinforcing the importance of depth-first search for exploring connected components. It also showcased how recursive algorithms can be used to solve problems involving adjacency and connectivity in grids, which is a fundamental concept in graph theory.

* Day 202: 🃏 Flashcard Creator with Tkinter 🎓 

  Today, I worked on a **Flashcard Creator** using **Tkinter**, where users can create, edit, and review study flashcards, including an option for quizzes to track progress in learning different subjects. The project focuses on building an intuitive GUI for managing flashcards, and the code is designed with object-oriented principles in mind. Here are the main features:

  - **Flashcard Creation**: Users can create flashcards by entering a question or term (front) and its corresponding answer or definition (back). These flashcards are stored and can be navigated or edited as needed, offering flexibility for users to adapt to new topics or modify existing cards.

  - **Editing Flashcards**: The program allows users to edit the content of existing flashcards. This feature ensures that any mistakes or updates can be easily managed, without the need to recreate the flashcard.

  - **Flashcard Navigation**: A user-friendly interface provides navigation between flashcards with "Next" and "Previous" buttons, allowing users to browse through their entire set of cards effortlessly.

  - **Quiz Mode**: The application features a quiz mode where users can test their knowledge. The program randomly selects flashcards, prompting the user to provide the correct answer. After each attempt, feedback is provided (correct or incorrect), and a score is tracked throughout the quiz.

  - **Progress Tracking**: Once the quiz ends, users are presented with their final score, giving them an overview of how well they know the content. This is useful for self-assessment and tracking learning progress over time.

  - **Object-Oriented Design**: The project uses **classes** to represent both the individual flashcards and the flashcard manager, which handles operations like adding, editing, and navigating flashcards. This structure makes the code easy to maintain and extend in future iterations.

  - **User-Friendly Interface**: Built with Tkinter, the application features an intuitive and clean interface that is accessible to users with no prior programming experience. The GUI provides immediate feedback for user actions, making the learning process efficient.

  - **Practical Application**: This project is ideal for students, teachers, or anyone looking to reinforce their knowledge through flashcards. The flexibility of creating custom flashcards makes this tool applicable to various fields of study, from vocabulary building to technical subjects.

  This project was a great exercise in applying both GUI development and object-oriented programming in Python. It allowed me to refine my understanding of class-based structures while creating an educational tool that can easily be extended with additional features like progress charts or importing/exporting flashcards in the future.
* Day 203: ♟️ FEN Notation Converter for Chess in Python ♟️ 

  Today, I worked on a **FEN Notation Converter** project using Python, which allows converting between **Forsyth-Edwards Notation (FEN)** and a visual representation of a chessboard. This project was designed to help chess enthusiasts understand and visualize the FEN notation used in chess software to represent board positions. Below are the key highlights:

  - **FEN to Board Conversion**: The converter reads a FEN string (used to represent chess positions) and generates an 8x8 chessboard matrix. Each row and column is accurately translated to the corresponding chess pieces or empty squares.

  - **Board to FEN Conversion**: The program also allows reversing the process, taking a chessboard (represented as an 8x8 array) and converting it back into a valid FEN string. This was implemented by counting empty spaces and placing piece symbols according to FEN formatting rules.

  - **Visualization**: The board is printed in the console for a quick visual representation of the current chess position. This feature is useful for debugging or simply viewing the position described by the FEN string.

  - **Handling Edge Cases**: The project handles edge cases in FEN notation, such as positions with many empty squares or special symbols for castling rights, active color, and other fields.

  - **User-friendly Functions**: 
    - `fen_to_board(fen)`: Converts a FEN string into an 8x8 chessboard array.
    - `board_to_fen(board)`: Converts a chessboard array back into a FEN string.
    - `print_board(board)`: Prints the visual representation of the chessboard in the console.

  Working on this project gave me the opportunity to improve my skills in string manipulation and matrix operations in Python. Additionally, it deepened my understanding of how FEN notation works and how it can be utilized in chess software.
* Day 204: 🚗🔋 Electric Vehicle Charging Patterns Dataset [Kaggle](https://www.kaggle.com/datasets/valakhorasani/electric-vehicle-charging-patterns/data)

  Today, I focused on exploring the Electric Vehicle Charging Patterns Dataset from Kaggle. This dataset offers a comprehensive view of electric vehicle (EV) charging behaviors, capturing key metrics related to energy consumption, user patterns, and vehicle data. The project leverages Python for data analysis and visualization, employing libraries such as Pandas, Seaborn, Matplotlib, and Plotly. Below are the highlights of the day:

  - **Data Exploration**: The dataset contains various features such as user IDs, vehicle models, charging station IDs, and charging behaviors. The initial steps involved inspecting the data types, dimensions, and performing a basic statistical summary of the dataset. The dataset was then cleaned and missing values were addressed, ensuring reliable analysis.

  - **Feature Renaming**: I renamed the dataset's columns to remove spaces and special characters, simplifying further data handling. This step improves code readability and allows for easier manipulation of the dataset.

  - **Exploratory Data Analysis (EDA)**: Key insights were derived through visualizations of both categorical and numerical features:
    - **Count Plots**: Created for categorical features such as vehicle models, user types, charger types, and time of day to observe charging behavior trends.
    - **Distribution Plots**: Visualized numerical features like battery capacity, energy consumption, charging cost, and charging rate to understand their distributions and identify any skewness or outliers.
    - **Boxplots**: Used to detect outliers in numerical features and ensure that the data was well-prepared for further analysis.
    - **Correlation Heatmap**: Generated to analyze relationships between numerical features and identify any strong correlations that could be useful for predictive modeling.

  - **Clustering Analysis**: Applied **K-Means Clustering** to group similar charging patterns based on numeric features such as battery capacity, energy consumption, and charging rate. The results were visualized using **Principal Component Analysis (PCA)** to reduce dimensionality and display the clusters in a 2D space.

  - **Visualization with Annotations**: Created annotated plots, such as for charging cost, with clear labeling of key statistics like median values. These annotations enhanced the interpretability of the visualizations.

  This project was an excellent way to dive into real-world EV data, offering valuable insights into user behavior and charging patterns. The combination of statistical analysis and rich visualizations allowed for a deeper understanding of energy consumption trends and the factors influencing them.
* Day 205: 📚 Lesson Subscription and Management System in Python 🎓 

  Today, I completed a Lesson Subscription and Management System using Python, with a focus on the Model-View-Controller (MVC) architectural pattern and validation techniques. The project allows students to subscribe to lessons, and instructors to manage and teach these lessons, while ensuring proper input validation. Here are the key features and highlights:

  - **Input Validation**: To ensure data integrity, the system validates that names (for both students and instructors) contain only letters and spaces, preventing the entry of numbers or special characters. This enhances the quality of the data being processed.

  - **Model-View-Controller (MVC)**: The system is built around the MVC pattern, providing a clear separation of concerns:
    - **Model**: The `Person`, `Student`, and `Instructor` classes handle data-related logic. These models encapsulate attributes and implement behavior related to the core entities in the system.
    - **View**: The `View` class handles all user interactions, such as displaying menus, getting input, and showing results.
    - **Controller**: The `Controller` class acts as the intermediary, processing the user's input, updating models, and ensuring that the correct data is shown in the view.

  - **Encapsulation**: The `Person` class encapsulates sensitive attributes like `name` and `id_number`, providing controlled access through getter methods. This ensures that data is protected and follows proper OOP practices.

  - **Inheritance and Abstraction**: The `Student` and `Instructor` classes inherit from the `Person` abstract class, ensuring code reusability. The abstract method `get_description` is implemented by both classes to provide specific details for students and instructors.

  - **Lesson Management**: Instructors are responsible for managing lessons, and students can subscribe to those lessons. Each lesson is linked to an instructor, and students can view which lessons they are subscribed to.

  - **Instructor Lookup**: The system allows users to query which instructor is teaching a particular lesson. This feature makes it easier to organize lesson schedules and track instructor responsibilities.

  - **Error Handling**: The system includes robust error handling for invalid inputs (such as names containing numbers), providing meaningful feedback to users and ensuring smooth operation without crashes.

  - **Menu-Driven Interface**: A user-friendly, menu-driven interface allows for seamless interaction with the system. Users can subscribe students to lessons, view lesson details, and check which instructor is teaching a specific lesson.

  This project helped me deepen my understanding of the MVC architecture and how it can be applied to build modular and scalable software solutions. I also improved my input validation skills, ensuring that the system is reliable and handles edge cases effectively.
* Day 206: Technical Test "minDistance" and "setZeroes" [LeetCode](https://leetcode.com/problems/)

  - **minDistance**: Implemented a solution for the "Edit Distance" problem, where the goal is to transform one string into another using the minimum number of operations, such as inserting, deleting, or replacing characters. The solution uses dynamic programming to build a matrix that keeps track of the number of operations needed to transform substrings of `word1` into `word2`. The time complexity is O(m * n), where `m` and `n` are the lengths of the input strings. This approach ensures efficient calculation by avoiding redundant recalculations.
    [Problem Description: minDistance](https://leetcode.com/problems/edit-distance/description/)

  - **setZeroes**: Solved the "Set Matrix Zeroes" problem, which involves modifying a given matrix in-place such that if an element is 0, its entire row and column are set to 0. The solution utilizes the first row and the first column as markers to remember which rows and columns need to be zeroed. This method allows the problem to be solved in O(m * n) time complexity with O(1) additional space complexity, ensuring that the matrix is updated efficiently without using extra memory.
    [Problem Description: setZeroes](https://leetcode.com/problems/set-matrix-zeroes/description/)

* Day 207: 🎨 Painting Problem in Python 🌈

  Today, I worked on solving the "Painting Problem" using Python, focusing on recursion and backtracking techniques. The goal of the project was to color a grid of cells using a set of available colors, ensuring that no two adjacent cells share the same color. Here are the main highlights:

  - **Recursion**: The core of the solution revolves around a recursive function that attempts to color each cell of the grid. If a valid color is found for the current cell, the function recursively proceeds to the next cell. 

  - **Backtracking**: Whenever a conflict occurs, meaning no valid color can be placed in a specific cell without violating the adjacency constraint, the algorithm backtracks. It resets the current cell and tries the next available color, ensuring all possibilities are explored.

  - **Adjacency Validation**: A key part of the solution is the validation method, which ensures that no cell has the same color as its neighboring cells (top, bottom, left, and right). This check guarantees that all cells are colored according to the given rules.

  - **Grid Representation**: The grid is represented as a 2D list, and each cell is either colored with one of the available colors or left as `None` when uncolored. The recursive algorithm efficiently explores all possible configurations to find valid solutions.

  - **Exploring All Possibilities**: By using recursion and backtracking, the program explores every potential coloring configuration, printing each valid solution where no adjacent cells share the same color.

  - **Versatility**: The solution is flexible and works with any grid size and any number of available colors, making it adaptable for different problem instances.

  This project was an excellent way to deepen my understanding of how recursion and backtracking can be used to solve complex constraint satisfaction problems. It demonstrated the importance of validating constraints and systematically exploring all possible solutions while ensuring optimal performance.
* Day 208: ♟️ Chess Move Validator in Python ♟️ 

  Today, I worked on a **Chess Move Validator** program using Python, focusing on validating the legality of chess moves according to the rules of the game. The project supports different types of pieces, including special movements such as castling and en passant. Below are the key highlights:

  - **Chess Board Representation**: The chess board is represented as an 8x8 grid, with pieces initialized in their standard positions. The board uses a list of lists to manage the state of each square effectively.

  - **Move Validation**: The `is_move_legal` method validates moves for each type of piece, checking for:
    - **Pawns**: Standard moves, captures, and en passant.
    - **Rooks**: Straight line movements.
    - **Knights**: Unique L-shaped movements.
    - **Bishops**: Diagonal movements.
    - **Queens**: Combination of rook and bishop movements.
    - **Kings**: Single square movements and castling conditions.

  - **Error Handling**: The program provides feedback for illegal moves, detailing the specific reasons for each invalid action, such as moves that leave the player in check or moves that are not permissible for the specific piece type.

  - **Move Description**: When a legal move is identified, the program generates a descriptive output in chess notation style, detailing the piece's movement from the starting to the ending position.

  - **User Interaction**: The validator allows users to input moves in a tuple format, simulating the move's legality check. Additionally, the current state of the board is printed after each attempt to facilitate understanding of the game state.

  This project was a great exercise in applying programming principles to simulate the logic of chess movements, deepening my understanding of both the game itself and Python's capabilities. It was rewarding to build a tool that enhances engagement with chess by validating moves according to established rules.
* Day 209: 📱 Cellphone Inventory Management System in Python 📊 

  Today, I worked on a **Cellphone Inventory Management System** using Python, structured around the **Model-View-Controller (MVC)** design pattern. This project focused on managing an inventory of cellphone models, updating stock levels, and displaying the entire inventory. Below are the key highlights:

  - **Model**: The `Cellphone` class represents individual cellphone models with attributes like `model_name`, `brand`, and `stock`. The `Inventory` class manages a collection of these cellphones, allowing for searching and stock updates.

  - **View**: The `View` class handles user interactions, including displaying menu options, taking input for new cellphones, updating stock, and showing the current inventory. This separation allows for clear distinction between user interface logic and business logic.

  - **Controller**: The `Controller` class serves as the intermediary between the `Model` and `View`, processing user input from the `View`, manipulating the `Model`, and updating the user interface accordingly. This pattern enforces a clean, organized structure for managing data and logic separately.

  - **Add New Cellphones**: Users can input details like the model name, brand, and initial stock. These cellphones are then added to the inventory and stored for later access or updates.

  - **Update Stock**: The stock of any cellphone can be updated by searching for the model name and inputting the new stock level, ensuring that the inventory remains accurate.

  - **View Inventory**: The system allows users to view all cellphones currently in the inventory, displaying details such as model name, brand, and stock.

  - **User-Friendly Interface**: A menu-driven interface simplifies interactions, offering options to add new cellphones, update stock, view all cellphones, or exit the program. This intuitive design makes it easy to navigate and use.

  This project provided a solid understanding of how to apply the **MVC architecture** in Python, helping me to create a clean, maintainable, and scalable system. I particularly enjoyed the process of separating concerns between the model (data), view (user interface), and controller (logic), as this is a highly effective way to build software systems.
* Day 210: Technical Test "searchMatrix" and "sortColors" [LeetCode](https://leetcode.com/problems/)

  - **searchMatrix**: Implemented a solution for the "Search a 2D Matrix" problem. The matrix has rows sorted in non-decreasing order, and each row starts with a number greater than the last number of the previous row. The goal is to efficiently find if a target integer exists within the matrix. The solution uses binary search to achieve a time complexity of O(log(m * n)), where `m` is the number of rows and `n` is the number of columns, by treating the matrix as a flattened sorted array.
    [Problem Description: searchMatrix](https://leetcode.com/problems/search-a-2d-matrix/description/)

  - **sortColors**: Solved the "Sort Colors" problem using the Dutch National Flag algorithm. This problem asks to sort an array of integers where 0, 1, and 2 represent red, white, and blue colors respectively. The challenge was to sort the array in-place without using any built-in sort function. The approach uses three pointers (`low`, `high`, and `i`) to organize the array in one pass, achieving O(n) time complexity and O(1) space complexity.
    [Problem Description: sortColors](https://leetcode.com/problems/sort-colors/)
* Day 211: 🧩 Tiling Problem Solver in Python 🎲 

  Today, I worked on solving the classic **Tiling Problem** using a recursive approach in Python. The task was to count the total number of ways to tile a 2xN board using 2x1 tiles. This project helped strengthen my understanding of recursion and dynamic problem-solving. Below are the key highlights of the project:

  - **Recursion**: The problem was tackled using a recursive function that breaks the problem down into smaller subproblems. By reducing the size of the board step by step (either by placing a vertical tile or two horizontal tiles), the solution is built by combining these smaller problems. This demonstrates the power of recursion for solving complex tiling problems.

  - **Base Cases**: 
    - If the board has a length of `0`, there is exactly **one way** to tile it—by doing nothing.
    - If the board has a length of `1`, there is only **one possible tiling** (one vertical 2x1 tile).

  - **Recursive Case**: 
    - If you place a single vertical tile, you reduce the board to a size of 2x(N-1).
    - If you place two horizontal tiles, the board is reduced to 2x(N-2).
    - The total number of ways to tile a 2xN board is the sum of these two possibilities.

  - **Input Flexibility**: The user can input any board length (N) and get the total number of ways to tile it.

  - **Mathematical Insight**: This problem closely relates to the Fibonacci sequence. The number of ways to tile a 2xN board follows the same recurrence relation as Fibonacci numbers, with each solution building upon the previous ones.
* Day 212: 🎳 Bowling Scoreboard App in Python 🎯 

  Today, I worked on a **Bowling Scoreboard App** using **Python** and **Tkinter**, focusing on handling dynamic user input and maintaining a live scoreboard for multiple players. The project aimed to create an interactive user interface for entering scores, validating inputs, and automatically calculating bonuses like strikes and spares. Below are the key highlights:

  - **Dynamic Score Calculation**: The app allows multiple players to enter their scores for each frame. The total score is dynamically updated as players input their rolls, accounting for strikes and spares in the calculations. This ensures real-time feedback for users.

  - **Handling Strikes and Spares**: The project implements logic for handling bonuses from strikes (10 points plus the next two rolls) and spares (10 points plus the next roll). It ensures that incomplete frames don’t cause errors, as missing scores are handled gracefully.

  - **Tkinter GUI**: A user-friendly interface is built using Tkinter, where players' names can be added dynamically, and their frame-by-frame scores are input through entry fields. The app automatically moves the cursor to the next input field after each valid entry, improving the user experience.

  - **Validation of Inputs**: The app includes input validation to ensure that users only enter valid scores (0–10), and handles edge cases like strikes (10 pins on the first roll) by auto-filling the second roll with a 0. This keeps the score entry process smooth and error-free.

  - **Scoreboard Display**: Each player has their own row in the scoreboard with frames clearly displayed. The total score per frame is shown, updating immediately as users complete their rolls.

  - **Focus Management**: The app ensures the user interface is responsive by automatically shifting focus to the next input field after a roll, streamlining the data entry process for players.

  - **Real-Time Total Calculation**: For each player, the app calculates and displays the cumulative score after each frame, factoring in the correct bonus points for strikes and spares.

  This project was a great opportunity to apply my knowledge of **Tkinter** for building graphical user interfaces, as well as handling user inputs and calculations dynamically. It was challenging but rewarding to integrate real-time score updates and ensure that the app remained responsive, accurate, and easy to use throughout the game. I gained deeper insights into managing GUI-based applications with Python and learned how to ensure robust input validation and dynamic interaction.
* Day 213: 🛤️ Self-Avoiding Walk in Python 🚶‍♂️

  Today, I worked on a **Self-Avoiding Walk** simulation using Python, exploring the use of recursion and backtracking. The self-avoiding walk is a mathematical model that represents a path on a grid that never crosses itself. Below are the key highlights of the project:

  - **Recursion**: The solution is built using a recursive function that explores the grid step-by-step, attempting to find valid moves without revisiting any previously visited cells. The function continues to explore until either a full path is found or no valid moves remain.

  - **Backtracking**: If a path reaches a dead-end (i.e., no more valid moves), the algorithm backtracks by resetting the last visited cell to try a different direction. This ensures that all possibilities are explored.

  - **Grid Representation**: The grid is represented as an `n x n` matrix where each cell is either `True` (visited) or `False` (unvisited). The walk starts from the center of the grid, and the program attempts to navigate randomly without crossing the same path.

  - **Randomized Movement**: To simulate various outcomes, valid moves are shuffled randomly at each step. This randomness leads to different results on every execution of the walk.

  - **Termination and Success Check**: The walk can end in two ways: either it fills the entire grid successfully without crossing itself, or it fails due to lack of valid moves. A message indicating success or failure is displayed at the end.

  - **Practical Applications**: The self-avoiding walk has applications in areas such as combinatorics, physical simulations (like polymer chain modeling), and probability theory. It is an interesting problem that highlights the importance of recursion and efficient backtracking.

  This project provided valuable insight into recursive exploration and the challenges involved in simulating random processes on a grid.
* Day 214: Technical Test "minWindow" and "combine" [LeetCode](https://leetcode.com/problems/)

  - **minWindow**: Implemented a solution for the "Minimum Window Substring" problem, where the goal is to find the smallest substring in `s` that contains all characters in `t` (including duplicates). The solution uses the sliding window technique to dynamically adjust the window size while ensuring all characters in `t` are included. A dictionary is used to track the frequency of characters in the window, and a second dictionary ensures the frequency matches the required count for each character in `t`. This approach ensures an efficient solution with a time complexity of O(m + n), where `m` and `n` are the lengths of the strings `s` and `t`, respectively.
    [Problem Description: minWindow](https://leetcode.com/problems/minimum-window-substring/description/)

  - **combine**: Solved the "Combinations" problem, where the task is to generate all possible combinations of size `k` from a range of numbers from `1` to `n`. The solution utilizes backtracking to explore different combinations by recursively adding elements to a temporary list and backtracking when the combination size reaches `k`. This method efficiently generates all possible combinations, with a time complexity of O(C(n, k))—the number of ways to choose `k` elements from `n`.
    [Problem Description: combine](https://leetcode.com/problems/combinations/description/)
* Day 215: 🎳 Console-Based Bowling Game in Python 🕹️ 

  Today, I developed an interactive Bowling Game using Python, played entirely in the console. This project focuses on creating a simple yet fun bowling simulation using ASCII art to represent the pins and providing a real-time score after each roll. Below are the key highlights:

  - **ASCII Art**: The bowling pins are represented in the console using ASCII characters (`O` for standing pins and ` ` for knocked-down pins). The `display_pins` function visually organizes the pins in a triangular format, providing a clear representation of the current game state.

  - **Roll Simulation**: The game uses the `roll_ball` function to simulate each roll of the ball. This function randomly determines which pins are knocked down, simulating a real bowling experience where the outcome of each roll is unpredictable.

  - **Real-time Score Calculation**: After each roll, the `calculate_score` function counts the number of knocked-down pins, giving the player instant feedback on their performance. The total score is updated in real-time after each roll.

  - **Game Flow**: The game allows the player to take two rolls per frame. After the second roll, the player is given the option to either restart the game or exit. This makes the game easily replayable and provides a complete user experience.

  - **Reset and Exit Options**: After completing two rolls, players can choose whether to reset the game and try again or exit. This feature gives users flexibility in how long they wish to play.

  This project was a fun way to combine Python logic with interactive gameplay, using simple text-based output. It was also a great exercise in creating a user-friendly interface, even when working in a console environment. The real-time scoring and ability to reset or exit make this project engaging, and I look forward to building more games like this!
* Day 216: 📊 Leetcode Questions Dataset Analysis [Kaggle](https://www.kaggle.com/datasets/mohitkumar282/leetcode-questions-dataset/data)

  Today, I focused on exploring the Leetcode Questions Dataset from Kaggle. This dataset offers insights into various Leetcode questions, including their acceptance rates, difficulty levels, and whether they require a premium subscription. The project employs Python for data analysis and visualization, utilizing libraries such as Pandas, Seaborn, Matplotlib, and WordCloud. Below are the key highlights of today's analysis:

  - **Data Loading and Overview**:
    - Loaded the dataset and explored its structure, including the features: `Question_No`, `Question`, `Acceptance`, `isPremium`, `Difficulty`, `Question_Link`, and `Solution`.
    - Performed a brief inspection of data types and missing values to understand the initial data quality.

  - **Handling Missing Data**:
    - Verified the presence of any missing values across all features to determine if any data imputation was necessary.

  - **Exploratory Data Analysis (EDA)**:
    - Customized the figure settings for improved visualization aesthetics, including background color adjustments and font settings.
    - Created various plots to gain insights into the dataset:
      - **Count Plots**: Visualized distributions for categorical features such as `Difficulty` and `isPremium` to observe the balance of different categories.
      - **Histogram Plot**: Examined the distribution of `Difficulty` by `isPremium` status using a stacked histogram.
      - **Link Validity Check**: Verified the validity of `Question_Link` and `Solution` links, visualizing the proportion of valid and invalid links.
      - **Acceptance Rate Distribution**: Converted the `Acceptance` feature to a numerical format and analyzed its distribution.

  - **Data Cleaning and Feature Engineering**:
    - Removed special characters and converted the `Acceptance` rates from percentages to numerical values for consistency.
    - Ensured that the `Question_No` column had unique values to identify each question uniquely.

  - **Classification Model to Predict Difficulty**:
    - Encoded the `Difficulty` feature as numerical labels for machine learning purposes.
    - Trained a **Random Forest Classifier** using features such as `isPremium` and `Acceptance` to predict the difficulty level.
    - Evaluated the model's performance using **accuracy** and a **classification report**, providing insights into prediction quality.
    - **Feature Importance Analysis**: Visualized feature importances to understand which factors most influenced the difficulty predictions.

  - **Text Analysis and WordCloud**:
    - Generated a **WordCloud** from the question titles to visualize the most frequently used words.
    
  This project provided a practical approach to exploring and modeling data related to Leetcode questions, combining data cleaning, EDA, and machine learning for predictive analysis. The visualization efforts highlighted patterns in question difficulty, while the classification model demonstrated the feasibility of predicting difficulty levels based on specific features.
* Day 217: 🖼️ Art Store Management System in Python 🎨 

  Today, I worked on an Art Store Management System using Python, designed using the MVC (Model-View-Controller) architecture and Object-Oriented Programming (OOP) principles. The project allows users to manage an inventory of art pieces, including adding, viewing, and removing items. Below are the key highlights:

  - **Model-View-Controller (MVC) Architecture**: The system is divided into three main components:
    - **Model**: Responsible for representing the data and business logic, the `ArtPiece` class captures the attributes of each art piece, and the `Inventory` class manages the collection of art pieces.
    - **View**: Handles the user interface and interaction, allowing users to input and retrieve data. The `ArtStoreView` class displays options and receives inputs like new art piece details or the ID of a piece to be removed.
    - **Controller**: Acts as a bridge between the model and the view. The `ArtStoreController` class controls the flow of data between the inventory and the user interface, ensuring that actions like adding or removing art pieces are handled correctly.

  - **Object-Oriented Principles**: The system leverages OOP principles to ensure clarity, reusability, and modularity:
    - **Encapsulation**: Art piece details are stored and managed securely within the `ArtPiece` class, with clearly defined methods to add or remove pieces from the inventory.
    - **Abstraction**: The program abstracts the details of managing the inventory by providing clear interfaces through methods in the controller and model classes, hiding unnecessary complexity from the user.
    - **Modularity**: Each class has a single responsibility, allowing for easy extension of the system with new functionalities.

  - **Inventory Management**: Users can perform several actions related to the art pieces:
    - **View All Art Pieces**: Displays a list of all art pieces currently in the inventory.
    - **Add New Art Piece**: Allows users to input details for a new art piece, including title, artist, price, and stock.
    - **Remove Art Piece**: Provides the option to remove an art piece by its unique ID.

  - **Menu-Driven Interface**: The system offers a user-friendly menu that provides options for managing art pieces. Users can view all items, add new items, remove items, and exit the system, ensuring a smooth interaction experience.

  This project was an excellent exercise in applying the MVC pattern and solidifying my understanding of OOP principles such as encapsulation, abstraction, and modularity. By using this architecture, I was able to separate concerns effectively, creating a more maintainable and scalable system for managing an art store's inventory.
* Day 218: Technical Test "Subsets" and "WordSearch" [LeetCode](https://leetcode.com/problems/)

  - **Subsets**: Implemented a solution for the "Subsets" problem, where the task is to generate all possible subsets (the power set) from a given list of unique elements. The approach uses an iterative method that starts with an empty subset and adds new subsets by iterating through the input list. Each new element is added to all existing subsets to create new ones. The time complexity of the solution is O(2^n), where n is the number of elements in the input list.
    [Problem Description: Subsets](https://leetcode.com/problems/subsets/description/)

  - **WordSearch**: Solved the "Word Search" problem, which involves determining if a given word can be found in a 2D grid of characters. The word must be formed by letters of sequentially adjacent cells (horizontally or vertically), and each cell can only be used once in the path. The approach uses Depth-First Search (DFS) to explore all possible paths from each cell. The algorithm carefully marks cells as visited during the search to prevent reuse and restores them once the search backtracks. The solution runs with a time complexity of O(m * n * 4^L), where m and n are the dimensions of the grid and L is the length of the word.
    [Problem Description: WordSearch](https://leetcode.com/problems/word-search/description/)
* Day 219: 🎨 Tkinter Color Picker 

  Today, I worked on developing a **Color Picker** application using **Tkinter** in Python. This project is designed for designers and programmers, allowing them to select a color and instantly view its corresponding **Hexadecimal** and **RGB** values. Below are the key highlights of the project:

  - **Color Picker Functionality**: The core of the project is a color picker dialog that allows users to choose a color from a palette. The color is then displayed in a preview section, along with its Hex and RGB codes. This is useful for applications where precise color selection is required.

  - **Hexadecimal and RGB Display**: After selecting a color, the application automatically displays both the Hex code (e.g., `#FF5733`) and the RGB values (e.g., `(255, 87, 51)`), making it convenient to copy the values for further use in design or development work.

  - **Interactive User Interface**: The app provides an intuitive and simple UI, with a button to open the color picker and labels that update dynamically based on the selected color.

  - **Dynamic Background Update**: The background of the display section changes according to the selected color, providing a real-time preview of the chosen color.

  - **Code Modularity**: The code is modular and organized into functions, making it easy to understand, extend, and maintain. Each function serves a specific purpose, ensuring a clean and readable codebase.

  This project helped me further develop my skills in **Tkinter**, particularly in handling user inputs and updating the GUI dynamically based on interactions. It also reinforced the importance of designing simple and intuitive interfaces for utility-based applications.
* Day 220: 💰 Tip Calculator with Tkinter

  Today, I worked on developing a **Tip Calculator** using Tkinter in Python. This simple and interactive tool allows users to input their bill total and desired tip percentage, automatically calculating both the tip amount and the total amount to be paid. The project highlights the power of Tkinter for building user-friendly interfaces. Below are the key aspects:

  - **User Input for Bill Amount and Tip Percentage**: The program includes fields where users can enter the total bill amount and tip percentage. This makes it easy for users to quickly calculate tips based on their preferences.
  
  - **Tip Calculation**: A core function calculates the tip amount by multiplying the bill by the percentage input. This ensures an accurate calculation every time.

  - **Total Amount Display**: In addition to showing the tip amount, the program calculates and displays the total amount to be paid, including both the bill and the tip.

  - **Error Handling**: The program includes error handling to manage invalid inputs (e.g., non-numeric entries) using a simple error message dialog. This enhances user experience by preventing crashes.

  - **Clean User Interface**: Built with simplicity in mind, the interface is straightforward and easy to navigate, making it accessible for a wide range of users.

  This project allowed me to further improve my skills in creating real-world applications using **Tkinter** while emphasizing user interaction and error handling. It demonstrates how small, practical tools can enhance everyday tasks and offer convenience in situations like dining out or splitting bills.
* Day 221: 🌍 Choropleth Map Generator with Flask 🗺️ 

  Today, I worked on a project using Flask to create an interactive choropleth map generator where users can input country names and associated values. The application generates a choropleth map to visually represent the input data. Below are the key highlights:

  - **User-Friendly Interface**: The project provides a web interface using Flask, allowing users to easily input country names and corresponding values via a simple HTML form. This makes the process intuitive for any user, without the need for technical knowledge of how the data will be processed.

  - **Form Validation**: The system validates each country name using the `pycountry` library, ensuring that only valid country names are used in the map. If an invalid country is entered, the user is notified, and no map is generated until the input is corrected.

  - **Dynamic Choropleth Map**: The choropleth map is dynamically generated based on the valid country names and values provided by the user. The map uses Plotly for visualization and is displayed directly in the browser, making it easy to interpret and understand the data visually.

  - **Data Customization**: Users can associate specific numeric values with each country, allowing for the visualization of various metrics (e.g., population, economic data) through the choropleth map. The data is customizable and easy to extend for different use cases.

  - **Real-Time Feedback**: Once the form is submitted, the map is displayed directly on the same page using an embedded HTML frame, giving users immediate feedback on their input and the resulting map.

  - **Error Handling**: The project handles user input errors gracefully. If the user inputs an invalid country name or a non-numeric value, an error message is displayed on the page, guiding the user to correct their input.

  - **Tech Stack**: This project utilized Flask as the web framework, Plotly for creating the interactive maps, `pycountry` for validating country names, and Pandas for handling the data. The generated map is rendered using Plotly’s choropleth functionality and saved as an HTML file, which is then embedded into the webpage for visualization.

  This project allowed me to integrate web development with data visualization. It was a great opportunity to create an interactive, user-friendly tool while improving my Flask skills and working with Plotly for dynamic data representation. The combination of data validation and real-time visual feedback made this a practical and enjoyable project to build.
* Day 222: 💼 LevelUp Jobs - MVC Python Application 🖥️ 

  Today, I developed a job management system called **LevelUp Jobs** using Python with the **Model-View-Controller (MVC)** design pattern. The focus of the project was to create a system where users can register for job offers, and employers can post new job openings. Below are the key highlights of this project:

  - **Model-View-Controller (MVC)**: The application is structured using the MVC pattern, dividing the code into three interconnected components: 
    - **Model**: Handles the logic and data of the job offers and users.
    - **View**: Manages the interface and interaction with the user.
    - **Controller**: Bridges the model and view, handling user input and updating both the model and view accordingly.

  - **Job Registration**: Employers can input detailed job information, such as:
    - Job title
    - Company name
    - Salary (validated to ensure only numeric inputs)
    - Required experience (years)
    - Description and benefits
    - Work schedule
    - Job type (remote or on-site)

    Each job is automatically assigned a unique job ID to ensure easy tracking and management.

  - **User Validation**: The system performs validation checks on the user’s inputs:
    - Ensures that names do not contain numbers.
    - Ensures that the salary and phone numbers are valid numeric inputs.
    - Validates that remote options are entered as 'y' or 'n'.

  - **Edit and Remove Job Offers**: Employers can edit existing job offers by searching for a job via its ID. They can also remove job offers if needed. The system ensures that all input fields are validated during the edit process to prevent invalid data entry.

  - **Job Listings**: Users can view all available job offers, which are displayed in a clean and organized manner. The system shows details such as the job title, company, salary, required experience, and whether the job is remote or on-site.

  - **OOP Principles**: 
    - **Encapsulation**: Each model class encapsulates attributes and provides methods to access or modify these properties.
    - **Abstraction**: The job creation and management process is abstracted from the user, allowing for smooth interaction.
    - **Inheritance**: The system can be extended to allow different types of users, such as job seekers and employers.

  - **Menu-Driven Interface**: The application provides a simple menu for users to:
    1. View all job offers
    2. Add new job offers
    3. Edit existing job offers
    4. Remove job offers
    5. Exit the system
    
    This makes it easy to interact with the system and manage job offers efficiently.

  This project was an excellent opportunity to apply the MVC pattern in a practical scenario, allowing me to separate concerns between the model, view, and controller, making the code more modular and maintainable. Through this experience, I enhanced my skills in data validation, Python's OOP principles, and the development of user-friendly applications.
* Day 223: Technical Test "removeDuplicatesII" and "searchII" [LeetCode](https://leetcode.com/problems/)

  - **removeDuplicatesII**: Implemented a solution for the "Remove Duplicates from Sorted Array II" problem, where the task is to modify a sorted array such that each unique element appears at most twice. The solution uses two pointers to track the position of the current element and to overwrite duplicates beyond the second occurrence. The algorithm processes the array in-place with O(1) extra space. The time complexity is O(n), where n is the number of elements in the array.
    [Problem Description: removeDuplicatesII](https://leetcode.com/problems/remove-duplicates-from-sorted-array-ii/description/)

  - **searchII**: Solved the "Search in Rotated Sorted Array II" problem, which requires determining whether a target value exists in a rotated sorted array, where the array may contain duplicates. The solution uses a modified binary search to handle the rotation and duplicates efficiently, adjusting the search space based on the sorted half of the array. In the worst case (due to duplicates), the time complexity is O(n), but on average, it runs in O(log n).
    [Problem Description: SearchII](https://leetcode.com/problems/search-in-rotated-sorted-array-ii/description/)
* Day 224: 💵 Recursive Investment Growth Calculator in Python 📈

  Today, I developed a Recursive Investment Growth Calculator in Python to project the future value of an investment in USD based on compound interest. The project demonstrates recursion by calculating the year-over-year growth of an investment, with a focus on breaking down the compound interest formula into recursive function calls. Key features and highlights of the project are outlined below:

  - **Recursion for Compound Interest**: The core of the project is a recursive function, `compound_interest_recursive`, that calculates the compounded investment amount by repeatedly applying the interest rate over the specified years. This function takes the principal, annual interest rate, and remaining years as inputs, stopping once all years have been processed.

  - **Investment Report**: Using the `investment_growth_report` function, the program generates a report that displays the balance at the end of each year, allowing the user to observe the compounding effect of the investment over time. This report is easy to read and provides a year-by-year breakdown of the investment's growth.

  - **User-Friendly Output**: Each year’s projected balance is displayed with a simple and clear format, helping users understand the impact of compounding interest and how investments grow over time. 

  - **Practical Financial Application**: This project showcases how recursion can be applied to financial calculations, especially for simulating the growth of investments. It serves as a basic model that can be expanded with additional features, such as varying interest rates or different compounding frequencies (e.g., monthly, quarterly).

  - **Python Basics in Finance**: This project is not only a good example of recursion but also introduces fundamental financial concepts like compound interest, making it accessible for those interested in combining Python programming with finance.

  This Recursive Investment Growth Calculator was a valuable project to deepen my understanding of recursion and how it can simplify complex calculations like compound interest. It also served as a practical demonstration of how Python can be applied to model real-world financial scenarios, making it a useful tool for anyone interested in finance and programming.
* Day 225: 🌳 Company Organizational Structure Tree in Python 📊 

  Today, I developed a Company Organizational Structure Tree in Python to model and explore hierarchical relationships within an organization. This project utilizes a binary tree structure to represent positions, with each node holding a company role, enabling traversal and understanding of the company's structure. The tree allows for traversal using **pre-order**, **in-order**, and **post-order** methods, providing insights into managerial hierarchies, employee details, and team structures. Below are the main highlights of the project:

  - **Binary Tree Structure**: The company’s organizational structure is represented as a binary tree, where each node corresponds to a company role, with left and right children representing subordinate relationships.

  - **Pre-order Traversal (Management Hierarchy)**: The pre-order traversal visits the nodes in top-down management order, which is helpful for understanding the hierarchy from executives to individual team members.

  - **In-order Traversal (Detailed Structure)**: The in-order traversal lists the structure left-to-right, which can help identify team structures in a balanced manner, making it ideal for reviewing employee details by levels.

  - **Post-order Traversal (Team Completion)**: The post-order traversal processes each team before its respective manager, which is useful for ensuring all sub-levels are accounted for before each managerial level.

  - **Encapsulation**: Each node contains `position` and `name` attributes, encapsulated within the `TreeNode` class. This structure ensures a clear distinction between the nodes, making it easier to extend the tree with additional attributes if needed.

  - **Methodical Structure**: The `OrgStructureTree` class includes traversal methods, making it easy to manage and interact with the tree structure. This design promotes modularity and maintainability, allowing for flexible additions to the tree structure or traversal methods in the future.

  This project provided valuable experience in structuring and traversing hierarchical data, showcasing how binary trees can be adapted to real-world scenarios. The traversal methods add flexibility, making it straightforward to analyze the company hierarchy from different perspectives.
* Day 226: 📱 Mobile Device Usage and User Behavior Dataset 📱 [Kaggle](https://www.kaggle.com/datasets/valakhorasani/mobile-device-usage-and-user-behavior-dataset/data)

  Today, I focused on analyzing the Mobile Device Usage and User Behavior Dataset from Kaggle using Python. The project emphasized data exploration and visualization through libraries such as Pandas, Seaborn, and Matplotlib. Below are the key highlights:

  - **Data Overview**: The dataset includes attributes such as User ID, Device Model, Operating System, App Usage Time, Screen On Time, Battery Drain, Number of Apps Installed, Data Usage, Age, Gender, and User Behavior Class. Each attribute plays a crucial role in understanding user behavior.

  - **Handling Missing Data**: A thorough check for missing values was performed to ensure data integrity before proceeding with analysis.

  - **Exploratory Data Analysis (EDA)**: Various visualizations were created to explore relationships among features. This included:
    - **Count Plots**: Displaying the distribution of categorical features like Operating System and Gender.
    - **Distribution Plots**: Analyzing numeric variables such as App Usage Time and Battery Drain to identify patterns.
    - **Correlation Heatmap**: Visualizing correlations among numeric variables to understand relationships.

  - **Modeling for Classification**: I implemented several classification algorithms (Logistic Regression, Random Forest, Gradient Boosting, SVC, XGBoost, K-Nearest Neighbors) to predict user behavior classes based on device usage patterns. Performance metrics such as accuracy and confusion matrices were generated for each model.

  - **Prediction of Battery Drain**: Regression models (Linear Regression, Random Forest Regressor, Gradient Boosting Regressor, XGBoost Regressor) were trained to predict battery drain based on user behavior data. Evaluation metrics like Mean Squared Error and R² Score provided insights into model performance.

  - **Visualization Techniques**: Advanced visualizations such as pair plots and joint plots were utilized to identify potential relationships among variables. These visualizations help in understanding the complex interactions within the dataset.

  This project offered a valuable opportunity to enhance my skills in data analysis and visualization techniques in Python while providing insights into mobile device usage patterns. The experience underscored the significance of exploratory analysis in uncovering meaningful trends and relationships within data.
* Day 227: 🍏 Food Inventory Management System in Python 🥦

  Today, I developed a Food Inventory Management System using Python, focusing on Object-Oriented Programming (OOP) principles. This project allows users to manage food items, track their expiration dates, and maintain an inventory history. Below are the key highlights:

  - **Encapsulation**: The `FoodItem` class encapsulates attributes such as `name`, `category`, `quantity`, `price`, and `expiration_date`. This ensures that the data is protected and can only be manipulated through defined methods.

  - **Inventory Management**: Users can add and remove food items from the inventory. The system keeps track of each action in an inventory history log, allowing users to see what changes have been made over time.

  - **Expiration Tracking**: The system checks for items that are near expiration (within 7 days) and provides a method to view these items. This feature helps users manage their inventory effectively and reduce food waste.

  - **Data Import/Export**: Users can import food item data from a CSV file and export the current inventory to a CSV file. This functionality makes it easy to manage large datasets and integrate with other systems.

  - **Search Functionality**: The system allows users to search for food items by name and category. This makes it easy to find specific items in a potentially large inventory.

  - **User-Friendly Interface**: A menu-driven interface guides users through the various functionalities of the system, making it intuitive and easy to use for anyone managing food inventory.

  This project was an excellent opportunity to apply OOP principles in creating a structured and maintainable system. I enhanced my understanding of how encapsulation, inheritance, and abstraction work together to produce clean, reusable code while building a practical tool for food inventory management.
* Day 228: Technical Test "deleteDuplicates" and "deleteDuplicatesll" [LeetCode](https://leetcode.com/problems/)

  - **deleteDuplicates**: Implemented a solution for the "Remove Duplicates from Sorted Array II" problem, which involves modifying a sorted array in place to remove duplicates such that each element appears at most twice. The approach uses a two-pointer technique to efficiently traverse the array and manage the count of duplicates, ensuring that the final array maintains the required order. The time complexity is O(n), where n is the number of elements in the array.
    [Problem Description: deleteDuplicates](https://leetcode.com/problems/remove-duplicates-from-sorted-array-ii/description/)

  - **deleteDuplicatesll**: Developed a solution for the "Remove Duplicates from Sorted List" problem, which requires removing all duplicates from a sorted linked list. The solution involves traversing the linked list while checking for duplicate values and adjusting the pointers accordingly to skip over any duplicate nodes. This ensures that only unique values remain in the list. The time complexity is O(n), where n is the number of nodes in the linked list.
    [Problem Description: deleteDuplicatesll](https://leetcode.com/problems/remove-duplicates-from-sorted-list/description/)
* Day 229: ⏳ Recursive Countdown Timer in Python ⏲️

  Today, I developed a **Recursive Countdown Timer** using Python, which demonstrates the power of recursion in programming. This timer counts down from a specified number of minutes and seconds, providing real-time updates on the remaining time. Below are the key highlights of this project:

  - **Recursion**: The core functionality of the timer is implemented using a recursive function `recursive_timer`. This function calls itself with updated time values until the countdown reaches zero, showcasing how recursion can simplify complex repetitive tasks.

  - **Time Formatting**: The timer displays the remaining time in a user-friendly format (MM:SS), ensuring that users can easily read the countdown. The use of formatted strings enhances clarity and presentation.

  - **Real-Time Simulation**: To simulate real-time countdown, the program uses `time.sleep(1)`, which pauses execution for one second between updates. This feature provides an accurate representation of the passage of time during the countdown.

  - **Base Case Handling**: The implementation includes a well-defined base case that checks if both minutes and seconds have reached zero. When this condition is met, it prints "Time's up!" and terminates the recursion, demonstrating effective control flow.

  - **Example Usage**: The timer can be initiated with any starting time, as shown in the example usage comment. For instance, calling `recursive_timer(0, 10)` starts a countdown from 10 seconds, allowing for easy testing and demonstration of functionality.

  This project was an excellent exercise in understanding recursion and its practical applications in creating a simple yet effective countdown timer. It reinforced my knowledge of Python programming concepts while providing a useful tool for timing applications.
* Day 230: 🎃 Jack-o'-Lantern in Python with Turtle Graphics 🎨

  Today, I created a fun Halloween-themed drawing of a Jack-o'-Lantern using Python's Turtle graphics library. This project allowed me to explore basic graphics programming while enhancing my understanding of functions and object-oriented principles in Python. Below are the key highlights of the project:

  - **Turtle Graphics**: Utilized the Turtle module to create graphical representations, focusing on shapes and colors that reflect a Halloween theme. The drawing includes features like eyes, a nose, a mouth, and a stem, all designed to resemble a classic Jack-o'-Lantern.

  - **Functionality**: The program is structured around several functions:
    - `drawcircle(x, y)`: Draws filled circles representing the eyes of the pumpkin.
    - `triangle(x, y)`: Draws triangles for the pupils and nose.
    - `mouth()`: Creates a spooky mouth with a unique shape.
    - `stem()`: Draws the pumpkin's stem with an organic shape.

  - **Customizable Aesthetics**: The colors used in the drawing are carefully chosen to enhance the Halloween spirit:
    - Orange for the pumpkin body.
    - Red for the pupils.
    - Yellow for the mouth.
    - Dark green for the stem.

  - **Message Display**: Added a function to display a festive message: "Happy Halloween, October 31, 2024," below the drawing. This enhances user engagement and adds to the overall theme of the project.

  - **User Interaction**: The program runs in a window that remains open until closed by the user, allowing them to enjoy the completed artwork.

  This project was an enjoyable way to combine creativity with programming. It provided an opportunity to practice using functions effectively and understand how to manipulate graphical elements in Python. Overall, it was a delightful exercise in creating something visually appealing while celebrating Halloween!
* Day 231: 🔐 Password Manager in Python 🛡️

  Today, I developed a Password Manager application using Python and Tkinter, focusing on secure password storage and management. The project allows users to store, generate, and view passwords for various accounts while ensuring data security through encryption. Below are the key highlights:

  - **User Interface**: The application features a user-friendly interface built with Tkinter, providing input fields for the site name, username, and password. The dark-themed background enhances usability and reduces eye strain.

  - **Password Generation**: Users can generate strong, random passwords with a single click. The generated password is automatically inserted into the password field, ensuring that users can easily copy or modify it before saving.

  - **Data Encryption**: The application employs the `cryptography` library to encrypt passwords before storing them in a text file. This ensures that sensitive information remains secure and protected from unauthorized access.

  - **Saving Entries**: Users can save their passwords along with associated site names and usernames. The application appends new entries to a text file (`passwords.txt`), making it easy to manage multiple accounts.

  - **Viewing Saved Passwords**: A feature allows users to view all saved passwords in a secure manner. When requested, the application reads the stored entries, decrypts the passwords, and displays them in a message box for easy reference.

  - **Error Handling**: Basic error handling is implemented to manage potential issues when reading from or writing to the file. This ensures that users receive informative feedback if something goes wrong.

  - **Future Enhancements**: This project lays the groundwork for future enhancements such as editing or deleting saved entries, implementing user authentication, and transitioning to a more robust database solution for storing credentials.

  This project was an excellent opportunity to apply my knowledge of Python and Tkinter while focusing on security best practices. It reinforced my understanding of encryption techniques and how to create intuitive user interfaces, all while building a practical tool for managing passwords securely.
* Day 232: 🎮 Pong Game in Python with Kivy 🕹️

  Today, I developed a simple Pong game using Python and the Kivy framework. This project focuses on creating an interactive game that allows two players to control paddles and compete against each other. Below are the key highlights:

  - **Game Structure**: The game consists of three main classes: `PongPaddle`, `PongBall`, and `PongGame`. Each class is responsible for specific functionalities, promoting a clear separation of concerns.

  - **Paddle Mechanics**: The `PongPaddle` class handles the player paddles, including scoring and bouncing the ball. The `bounce_ball` method detects collisions with the ball and adjusts its velocity based on where it hits the paddle, adding a dynamic element to gameplay.

  - **Ball Movement**: The `PongBall` class manages the ball's position and velocity. The `move` method updates the ball's position based on its current velocity, allowing it to travel across the screen.

  - **Game Logic**: The `PongGame` class orchestrates the overall game flow. It includes methods for serving the ball, updating positions, handling collisions with paddles and screen boundaries, and scoring points when the ball goes off-screen.

  - **User Interaction**: Player controls are implemented through touch events. The `on_touch_move` method allows players to move their paddles vertically by dragging their fingers across the screen, providing an intuitive control scheme.

  - **Real-time Updates**: The game runs at 60 frames per second using Kivy's clock scheduling. This ensures smooth animations and responsive gameplay, enhancing the user experience.

  - **Scoring System**: Each player has a score tracked by the `score` property in the `PongPaddle` class. When a player fails to intercept the ball, their opponent scores a point, and the game resets with a new serve.

  This project was an enjoyable exercise in game development using Kivy. It provided valuable insights into handling user inputs, managing object interactions, and implementing real-time updates in a graphical environment. I gained practical experience in structuring a game application while enhancing my programming skills in Python.
* Day 233: 🍬 Candy Inventory Management System in Python 🍭

  Today, I developed a Candy Inventory Management System using Python, focusing on Object-Oriented Programming (OOP) principles. This project allows users to manage their candy inventory by adding, removing, and displaying candy types and quantities. Below are the key highlights:

  - **Class Structure**: The `CandyInventory` class serves as the main structure for managing the candy inventory. It utilizes a dictionary to store different types of candies along with their quantities, ensuring efficient data management.

  - **Adding Candies**: The `add_candy` method allows users to add a specified quantity of a given type of candy. It includes validation to ensure that the quantity is greater than zero and updates the inventory accordingly.

  - **Removing Candies**: The `remove_candy` method implements a recursive approach to check if there are enough candies available for removal. If the quantity reaches zero after removal, the candy type is deleted from the inventory, maintaining a clean and accurate record.

  - **Displaying Inventory**: The `display_inventory` method provides a user-friendly way to view all candies currently in stock. If the inventory is empty, it informs the user, enhancing usability.

  - **Error Handling**: The system includes error handling for various scenarios, such as attempting to remove more candies than are available or adding an invalid quantity. This ensures robustness and improves user experience.

  - **User Interaction**: The program can be run as a standalone script, allowing users to interact with the candy inventory through simple method calls. This makes it easy to test and extend with additional features in the future.

  This project was an enjoyable exercise in applying OOP principles to create a functional and maintainable system. It provided me with valuable experience in managing data structures and implementing recursive logic in Python while building a practical tool for candy inventory management.
* Day 234: Technical Test "largestRectangleArea" and "maximalRectangle" [LeetCode](https://leetcode.com/problems/)

  - **largestRectangleArea**: Implemented a solution for the "Largest Rectangle in Histogram" problem, which involves finding the area of the largest rectangle that can be formed within a histogram represented by an array of heights. The solution utilizes a stack-based approach to efficiently compute the maximum rectangular area by iterating through each bar in the histogram and calculating possible rectangle areas based on bar heights. The time complexity is \(O(n)\), where \(n\) is the number of bars in the histogram.
    [Problem Description: largestRectangleArea](https://leetcode.com/problems/largest-rectangle-in-histogram/description/)

  - **maximalRectangle**: Solved the "Maximal Rectangle" problem, which finds the largest rectangle consisting of only `1`s in a binary matrix. By treating each row of the matrix as the base of a histogram, the solution calculates the maximum area of rectangles row by row, using the `largestRectangleArea` function for each updated histogram height array. The approach ensures efficient processing with a time complexity of \(O(rows \times cols)\), where `rows` and `cols` are the dimensions of the matrix.
    [Problem Description: maximalRectangle](https://leetcode.com/problems/maximal-rectangle/description/)
* Day 235: 🏠 Rent Houses Management System in Python 🏡

  Today, I developed a Rent Houses Management System using Python, employing the Model-View-Controller (MVC) architectural pattern. This project allows users to manage rental properties, including adding new houses, viewing available houses, and removing houses from the list. Below are the key highlights:

  - **Model-View-Controller (MVC) Structure**: The application is organized into three distinct components:
    - **Model**: Manages the data and business logic related to houses. The `HouseModel` class handles operations like adding, removing, and retrieving house listings.
    - **View**: Responsible for user interaction. The `HouseView` class provides a menu-driven interface for users to interact with the system and validates user input.
    - **Controller**: Acts as an intermediary between the model and view. The `HouseController` class orchestrates user actions and updates the model accordingly.

  - **Data Management**: The `House` class encapsulates attributes such as ID, address, rent amount, number of bedrooms and bathrooms, and availability status. This structure allows for easy management of rental properties.

  - **User Interaction**: A simple text-based menu allows users to choose from various options, including viewing all houses, adding new houses, or removing existing ones. Input validation ensures that data entered by users is accurate and consistent.

  - **Dynamic ID Assignment**: Each house is assigned a unique ID upon creation, which simplifies the process of managing listings and ensures that each property can be easily referenced.

  - **Error Handling**: The application includes robust error handling to manage invalid inputs gracefully. Users receive clear feedback when they make mistakes, enhancing the overall user experience.

  - **Extensibility**: The modular design of the application makes it easy to extend functionality in the future. Additional features such as searching for houses based on criteria or integrating a database can be implemented without significant restructuring.

  This project was an excellent opportunity to deepen my understanding of MVC architecture in Python while creating a practical tool for managing rental properties. It reinforced my skills in structuring code for maintainability and usability while providing a functional application that could be further developed.
* Day 236: 🥗 Total Daily Energy Expenditure (TDEE) Calculator in Python ⚖️

  Today, I developed a Total Daily Energy Expenditure (TDEE) Calculator using Python, which incorporates fundamental programming concepts such as functions, recursion, and data handling. This project calculates the TDEE based on individual health metrics and activity levels, providing valuable insights into daily caloric needs. Below are the key highlights:

  - **Basal Metabolic Rate (BMR) Calculation**: The project implements the Harris-Benedict equation to calculate BMR based on weight, height, age, and gender. This foundational metric is crucial for understanding an individual's caloric needs at rest.

  - **Activity Level Integration**: The TDEE is calculated by multiplying the BMR by an activity factor that corresponds to different levels of physical activity (sedentary, light, moderate, active, very active). This allows for a more personalized assessment of daily energy expenditure.

  - **Recursive Data Processing**: A recursive function processes a list of individuals' health data to calculate both BMR and TDEE. This approach demonstrates how recursion can simplify repetitive tasks and enhance code readability.

  - **Sample Data Handling**: The program includes sample data representing various individuals with different weights, heights, ages, genders, and activity levels. This showcases the calculator's versatility and ability to handle diverse inputs.

  - **Results Presentation**: The final output clearly displays each individual's weight, height, age, gender, BMR, and TDEE in a user-friendly format. This enhances the usability of the program and makes it easy to interpret results.

  - **Health Insights**: By calculating TDEE, users can gain insights into their caloric needs for weight maintenance or adjustment. This project serves as a practical tool for individuals looking to manage their health and fitness goals effectively.

  This project was an excellent opportunity to apply programming concepts in a meaningful way while contributing to health awareness. It reinforced my understanding of how functions and recursion can be utilized to create efficient and organized code for real-world applications.
* Day 237: 📝 Word Counter Application in Python 🖥️

  Today, I developed a Word Counter application using Python's Tkinter library. The application allows users to input text and provides a count of both words and characters, all within a user-friendly graphical interface. Below are the key features and highlights of the project:

  - **User Interface**: The application features a clean and intuitive GUI, built using Tkinter. Users can easily enter their text in a multi-line text box and see the results displayed in real-time.

  - **Word and Character Count**: The core functionality includes counting the number of words and characters in the input text. Users can click a button to trigger the counting process, which updates the displayed counts dynamically.

  - **Dark Theme**: To enhance user experience, the application is designed with a dark theme. The background color is set to a dark shade, with contrasting text colors for better visibility, making it easier for users to read their input.

  - **Clear Functionality**: A "Clear Text" button allows users to quickly reset the text box and clear the counts, providing a seamless experience for repeated use.

  - **Responsive Design**: The layout is designed to be responsive, ensuring that it looks good on various screen sizes while maintaining usability.

  - **Code Structure**: The code is structured for readability and maintainability. Functions are clearly defined for counting words, clearing text, and updating the user interface, making it easy to extend or modify in the future.

  This project was a great opportunity to practice GUI development in Python and enhance my skills with Tkinter. It reinforced my understanding of event-driven programming and how to create interactive applications that are both functional and visually appealing. I look forward to exploring more complex GUI applications in future projects!
* Day 238: 📚 Data Structure Management System in Python 📊

  Today, I developed a Data Structure Management System in Python, focusing on implementing a stack and a singly linked list. This project allows users to manage player data effectively through a menu-driven interface. Below are the key highlights:

  - **Singly Linked List**: The system utilizes a singly linked list to store player names. Each player is represented as a node, allowing for efficient insertion and traversal. This structure demonstrates how linked lists can dynamically manage collections of data.

  - **Stack Implementation**: A stack (Last In, First Out - LIFO) is implemented to manage player names. Users can push player names onto the stack and pop them off, showcasing basic stack operations such as `push`, `pop`, and `peek`. This illustrates the utility of stacks in managing data in a controlled manner.

  - **Menu-Driven Interface**: The program features a user-friendly menu that allows users to add players to the linked list, display players, and manage them using stack operations. This interactive approach enhances user experience and makes the system intuitive to navigate.

  - **Data Management Operations**: Users can perform various operations:
    - Add new players to the linked list.
    - Display all players currently stored in the list.
    - Push players onto the stack for temporary storage.
    - Pop players from the stack and view the top player without removing it.

  - **Error Handling**: The system includes basic error handling for invalid menu selections and empty stack scenarios, ensuring robustness and reliability during operation.

  - **Code Structure**: The code is organized into classes (`Node`, `SinglyLinkedList`, and `Stack`), promoting modularity and reusability. Each class encapsulates specific functionalities, making it easier to maintain and extend in the future.

  This project was an enriching experience that deepened my understanding of fundamental data structures in Python. It provided practical insights into how stacks and linked lists operate, along with the importance of user interaction through menu systems. Overall, this exercise enhanced my coding skills while building a functional data management tool.
* Day 239: 🏀 Basketball Team Manager in Python 🏆

  Today, I developed a Basketball Team Manager using Python, focusing on Object-Oriented Programming (OOP) principles. This project allows users to manage a basketball team by adding players, tracking their statistics, and calculating the team's average points scored. Below are the key highlights:

  - **Encapsulation**: The `Player` class encapsulates attributes like `name`, `position`, and `points`. This ensures that player statistics are managed internally while providing methods to interact with these attributes, such as scoring points and retrieving stats.

  - **Team Management**: The `Team` class manages a roster of players. It includes methods for adding players, displaying their statistics, and calculating average points scored by the team. This structure allows for easy updates and maintenance of player data.

  - **Scoring System**: Players can score points through the `score_points` method, which updates their total points. This feature simulates real-game scenarios where players contribute to the team's score.

  - **Average Points Calculation**: The program calculates the average points scored by all players in the team, providing insights into team performance. This functionality can be useful for coaches and managers when evaluating player contributions.

  - **User Interaction**: The `main` function serves as the entry point for the program, creating a user-friendly experience by allowing easy additions of players and displaying their statistics in a clear format.

  - **Future Enhancements**: This project lays a solid foundation for future enhancements, such as adding more player statistics (rebounds, assists), implementing game simulations, or incorporating a user interface for better interaction.

  This project was an excellent opportunity to apply OOP principles in a practical context. I refined my understanding of encapsulation and class interactions while building a useful tool for basketball team management. I'm excited about the potential to expand this project further and explore more complex functionalities!
* Day 240: Technical Test "partitionList" and "isScramble" [LeetCode](https://leetcode.com/problems/)

  - **partitionList**: Developed a solution for the "Partition List" problem, where the objective is to reorder a linked list based on a given integer `x`. All nodes with values less than `x` are moved to the left of nodes with values greater than or equal to `x`, while preserving their original relative order. This is achieved by using two dummy nodes to create two partitions ("less than `x`" and "greater than or equal to `x`"), which are later connected. The final solution has a time complexity of O(n), where `n` is the length of the linked list, as it iterates through the list once.
    [Problem Description: partitionList](https://leetcode.com/problems/partition-list/description/)

  - **isScramble**: Implemented the solution for the "Scramble String" problem, which determines if one string is a scrambled version of another. A string is considered scrambled if it can be obtained by recursively swapping its substrings. The solution uses recursion and memoization to efficiently check all possible partitions and swaps, ensuring optimal performance. With memoization, the approach avoids redundant computations, significantly improving runtime for larger strings. This solution has a time complexity of O(n^4) due to recursive checking of substring partitions.
    [Problem Description: isScramble](https://leetcode.com/problems/scramble-string/description/)
* Day 241: 📈 Fibonacci Sequence Calculator in Python 🔢
  Today, I focused on implementing a Fibonacci Sequence Calculator using Python, emphasizing the concept of recursion. The project demonstrates how recursive functions can be utilized to solve problems that can be broken down into smaller, similar subproblems. Here are the key highlights:

  - **Recursion**: The main feature of this project is the recursive function `fibonacci(n)`, which calculates the nth Fibonacci number. The function calls itself with smaller values until it reaches the base case, demonstrating the power and simplicity of recursion.

  - **Base Case**: The function includes a base case that returns `n` when it is 0 or 1. This is crucial for stopping the recursion and preventing infinite loops, ensuring that the function eventually returns a result.

  - **Recursive Case**: For values greater than 1, the function computes the Fibonacci number by summing the results of two recursive calls: `fibonacci(n - 1)` and `fibonacci(n - 2)`. This showcases how complex problems can be solved by combining solutions to simpler problems.

  - **Example Usage**: The code includes an example usage section where users can easily modify the position in the Fibonacci sequence they wish to calculate. This makes it straightforward to test and understand how the function operates.

  - **Performance Consideration**: While this recursive approach is elegant and easy to read, it is important to note that it may not be efficient for larger values of `n` due to exponential time complexity. Future improvements could include memoization or iterative solutions to enhance performance.

  This project was a valuable exercise in understanding recursion and its applications in programming. It reinforced my ability to break down problems into manageable parts and implement solutions in a clear and concise manner. Overall, it was a rewarding experience that deepened my understanding of recursive algorithms in Python.
* Day 242: ♟️ Simple Chess Game in Python ♟️

  Today, I developed a simple console-based chess game using Python. The project focuses on Object-Oriented Programming (OOP) principles and provides a basic structure for two players to play against each other. Below are the key highlights of the project:

  - **Chess Board Representation**: The `ChessBoard` class initializes an 8x8 grid representing the chessboard, setting up all pieces in their starting positions. The board is displayed in a user-friendly format, making it easy to visualize the game state.

  - **Chess Pieces**: The `ChessPiece` class represents individual chess pieces, encapsulating attributes such as color and type. Each piece can be identified by its abbreviated representation (e.g., `wP` for white pawn).

  - **Move Validation**: The game includes a basic move validation method within the `ChessBoard` class. This method checks whether a move is valid based on simple rules, such as ensuring that players cannot capture their own pieces.

  - **User Interaction**: The game runs in a loop that prompts players for their moves. Players enter the starting and ending coordinates of the piece they wish to move, allowing for an interactive gameplay experience.

  - **Turn Management**: The game alternates turns between the two players (White and Black), ensuring that each player has an equal opportunity to make their moves. This adds a strategic element to the gameplay.

  - **Future Enhancements**: While the current implementation covers basic functionalities, there are numerous opportunities for expansion, such as implementing specific movement rules for each piece, handling check/checkmate scenarios, and adding a graphical user interface (GUI) for improved user experience.

  This project was an excellent exercise in applying OOP principles to create a functional and engaging game. It allowed me to deepen my understanding of class design, encapsulation, and user interaction while building a classic game of chess. I look forward to enhancing this project further and exploring more complex chess mechanics!
* Day 243: 🧴 Lotion Management System in Python 🌿

  Today, I developed a Lotion Management System using Python, focusing on Object-Oriented Programming (OOP) principles. This project allows users to manage a collection of lotions, including adding, removing, viewing, and updating stock levels. Below are the key highlights:

  - **Encapsulation**: The `Lotion` class encapsulates attributes such as `lotion_id`, `name`, `brand`, `price`, and `stock`. This ensures that the details of each lotion are kept together and can be managed through methods that control access to these attributes.

  - **Model-View-Controller (MVC) Architecture**: The application is structured using the MVC design pattern, separating the logic into three components:
    - **Model**: The `LotionModel` class manages the data and business logic, including methods for adding, removing, and retrieving lotions.
    - **View**: The `LotionView` class handles user interaction, displaying menus and messages while gathering input from users.
    - **Controller**: The `LotionController` class orchestrates the flow of data between the model and view, responding to user inputs and updating the model accordingly.

  - **User Interaction**: A menu-driven interface allows users to interact with the system easily. Users can choose options to view all lotions, add new lotions, remove existing ones, or update stock levels. This enhances usability and makes the application practical for everyday use.

  - **Data Management**: The system maintains a list of lotions in memory. Users can add new lotions with details such as ID, name, brand, price, and stock quantity. The application checks for valid inputs when removing or updating lotions to ensure data integrity.

  - **Feedback Mechanism**: The application provides feedback for user actions through success and error messages. This helps users understand whether their actions were successful or if they need to correct any mistakes.

  This project was a valuable exercise in applying OOP principles to create a functional and maintainable system. I enhanced my understanding of how encapsulation works in practice while implementing an MVC architecture that promotes separation of concerns. Overall, this lotion management tool serves as a practical application of my programming skills in Python.
* Day 244: Guava Fruit Disease Dataset [Kaggle](https://www.kaggle.com/datasets/asadullahgalib/guava-disease-dataset/data)

  Today, I focused on developing a convolutional neural network (CNN) to classify diseases in guava fruits using the Guava Disease Dataset from Kaggle. The project involved data preprocessing, model training, and evaluation using TensorFlow and Keras. Below are the key highlights:

  - **Data Loading and Preprocessing**: I utilized TensorFlow's `image_dataset_from_directory` function to load the dataset, which automatically infers labels from the directory structure. The images were resized to a uniform size of 180x180 pixels and split into training and validation sets.

  - **Data Visualization**: I created visualizations to display sample images from the dataset along with their corresponding labels. This helped in understanding the types of diseases present in the dataset and ensured that the data was loaded correctly.

  - **Model Architecture**: I implemented several CNN architectures, including:
    - A **basic CNN** model with multiple convolutional and pooling layers.
    - A **CNN with Dropout** layers to mitigate overfitting.
    - A **transfer learning model** using MobileNetV2, which leverages pre-trained weights for better performance.

  - **Model Compilation and Training**: Each model was compiled using the Adam optimizer and trained for a specified number of epochs. The training process included monitoring both training and validation accuracy to assess model performance.

  - **Performance Evaluation**: After training, I evaluated each model on the validation set, reporting metrics such as validation loss and accuracy. This step provided insights into how well each model generalized to unseen data.

  - **Visualization of Results**: I plotted graphs to compare training and validation accuracy and loss for each model type. This visualization aids in understanding the models' learning behavior over epochs.

  - **Model Saving**: The best-performing model based on validation accuracy was saved for future use, ensuring that the results can be reproduced or deployed later.

  This project provided an excellent opportunity to apply deep learning techniques to image classification tasks. It reinforced my understanding of CNNs, data preprocessing, and the importance of model evaluation in machine learning workflows. Additionally, working with real-world datasets like the Guava Disease Dataset highlighted the challenges and considerations involved in agricultural image classification tasks.
* Day 245: Technical Test "merge" and "grayCode" [LeetCode](https://leetcode.com/problems/)

- **merge**: Implemented a solution for the "Merge Sorted Array" problem, where the goal is to merge two sorted arrays into one sorted array. The first array has enough space to hold the elements of both arrays. The approach involves using two pointers to traverse each array from the end towards the beginning, ensuring that elements are merged in-place without requiring additional space. The time complexity of this solution is O(m + n), where m and n are the sizes of the two arrays.
  [Problem Description: merge](https://leetcode.com/problems/merge-sorted-array/description/)

- **grayCode**: Developed a solution for generating an n-bit Gray code sequence. The Gray code is a binary numeral system where two successive values differ in only one bit. The implementation uses a mathematical formula to compute the Gray code directly from its index, allowing efficient generation of the sequence. This method runs in O(2^n) time, as it generates all 2^n Gray codes for n bits.
  [Problem Description: grayCode](https://leetcode.com/problems/gray-code/description/)
* Day 246: 🗂️ Task Prioritization Matrix in Python 📊

  Today, I focused on developing a **Task Prioritization Matrix** application using Python, leveraging the **Tkinter** library for the graphical user interface (GUI). This project is designed to help users categorize and manage tasks based on their urgency and importance. Below are the key highlights:

  - **Object-Oriented Design**: The application utilizes OOP principles to create a clean and maintainable code structure. The `Task` class encapsulates task-related attributes such as `description` and `category`, allowing for easy management of task data.

  - **User Interface**: The GUI consists of four quadrants representing different categories of tasks:
    - **Urgent & Important**
    - **Urgent & Not Important**
    - **Not Urgent & Important**
    - **Not Urgent & Not Important**
    
    Each quadrant features a list box displaying tasks, enabling users to interact with their task lists intuitively.

  - **Task Management Features**:
    - **Add Task**: Users can add new tasks by specifying a description and selecting a category. The application provides prompts for input, ensuring a user-friendly experience.
    - **Edit Task**: Users can select an existing task to edit its description, allowing for updates as priorities change.
    - **Delete Task**: Selected tasks can be removed from the list, helping users keep their task lists relevant.
    
  - **Drag-and-Drop Functionality**: Users can drag tasks between different quadrants, facilitating easy reorganization based on changing priorities.

  - **Weekly Report Generation**: The application includes functionality to generate a weekly report of tasks categorized by urgency and importance. The report is saved in JSON format, making it easy to share or analyze later.

  - **Colorful UI Elements**: Buttons are designed with friendly colors to enhance usability and make the interface visually appealing. For example:
    - Add Task button: Green
    - Edit Task button: Blue
    - Delete Task button: Red
    - Generate Report button: Yellow
* Day 247: 🏥 Medication Reminder System in Flask 💊

  Today, I worked on a **Medication Reminder System** using Flask, which allows nurses to manage medication schedules for patients effectively. The application provides features for adding, editing, and deleting patient records, as well as setting reminders for medication times. Below are the key highlights:

  - **Responsive Design**: The application is fully responsive and centers its content for an optimal user experience across various devices. This ensures that nurses can easily access and manage patient information on tablets or smartphones.

  - **Real-Time Clock**: A large real-time clock is displayed at the top of the interface, allowing nurses to quickly reference the current time and plan medication schedules accordingly.

  - **Patient Management**: Nurses can add patients with detailed information including ID, name, room number, medications (which can be multiple), allergies, and medication times. The application supports multiple medications with different administration times.

  - **Dynamic Fields**: The system allows users to dynamically add multiple medication time fields for each patient. This flexibility is crucial for patients who require multiple doses throughout the day.

  - **Edit and Delete Functionality**: Each patient's information can be edited or deleted as necessary. This feature ensures that the system remains up-to-date with any changes in patient care plans.

  - **Medication Reminders**: The application runs a background thread that checks the current time against each patient's medication schedule, providing reminders when it's time to administer medication. This helps prevent missed doses.

  - **Weekly Report Generation**: A feature to generate a weekly report in JSON format is included, allowing for easy tracking and documentation of patient medication schedules.

  - **User-Friendly Interface**: The interface is designed with a dark theme and colorful buttons for better usability. Each button serves a distinct function, making navigation intuitive for users.

  This project was an excellent opportunity to deepen my understanding of web development with Flask while implementing features that are practical and beneficial in a healthcare setting. I learned how to manage stateful data in a web application and ensure that user interactions are seamless and efficient. Overall, it was a rewarding experience to create a tool that can help improve patient care through better medication management.
* Day 248: ⏱️ Chess Clock Simulation in Python ♟️

  Today, I developed a Chess Clock Simulation using Python, designed for players to engage in quick-paced games, such as blitz chess. The project focuses on creating a user-friendly command-line interface that allows players to manage their time effectively during matches. Here are the key highlights:

  - **Timer Management**: The `ChessClock` class manages the countdown timers for two players. It tracks the remaining time and ensures that the clock runs accurately for the active player.

  - **Multithreading**: The timer runs in a separate thread, allowing the main program to remain responsive. This enables players to switch turns without interrupting the countdown, ensuring smooth gameplay.

  - **Time Modes**: The simulation supports various time controls (e.g., "5+0" and "3+2"), allowing users to select their preferred game format. Each mode initializes the players' times accordingly.

  - **Player Switching**: Players can easily switch turns by pressing a key, which updates the active player and resumes their timer. This feature enhances the interactivity of the simulation.

  - **User Interface**: A simple command-line interface displays the remaining time for both players in a clear format. Players can view their time and choose to switch or quit at any moment during the game.

  - **Final Time Display**: When the game ends, either by running out of time or user intervention, the remaining times for both players are displayed in an easy-to-read format, providing a clear conclusion to the match.

  This project was an engaging exercise in applying programming concepts such as multithreading and user input handling. It allowed me to explore how to create an interactive tool that enhances the chess-playing experience. I also gained valuable insights into managing state and ensuring thread safety in a real-time application.
* Day 249: 🏀 Basketball Tournament Management System in Python 🏆

  Today, I developed a Basketball Tournament Management System using Python, focusing on Object-Oriented Programming (OOP) principles. The system allows users to register teams and players, create match schedules, record results, and display standings. Below are the key highlights:

  - **Encapsulation**: The `Player` and `Team` classes encapsulate attributes such as `name`, `position`, and match records (wins and losses). This ensures that the internal state of these objects is protected and can only be modified through defined methods.

  - **Class Relationships**: The system features a clear relationship between classes:
    - The `Tournament` class manages multiple `Team` instances and their associated `Match` instances.
    - The `Match` class handles the details of individual matches between two teams, including scheduling and result recording.

  - **Match Scheduling**: The system creates a randomized match schedule for registered teams. This feature ensures that teams are paired fairly and allows for easy extension to include more complex scheduling algorithms in the future.

  - **Statistics Tracking**: After matches are played, results can be recorded, and the system automatically updates each team's win-loss record. This functionality provides real-time feedback on team performance throughout the tournament.

  - **User Interaction**: A menu-driven interface allows users to interact with the system seamlessly. Users can register teams and players, create schedules, record results, and view current standings in an intuitive manner.

  - **Future Enhancements**: The current implementation serves as a solid foundation for future enhancements, such as adding player statistics, integrating a database for persistent storage, or developing a graphical user interface (GUI) for better user experience.

  This project was an excellent opportunity to apply OOP principles while creating a functional system for managing basketball tournaments. I gained valuable experience in designing classes with clear responsibilities and interactions, resulting in clean and maintainable code. Overall, this Basketball Tournament Management System is both practical and scalable for future development.
* Day 250: Technical Test "subsetsWithDup" and "numDecodings" [LeetCode](https://leetcode.com/problems/)

  - **subsetsWithDup**: Implemented a solution for the "Subsets II" problem, which generates all possible subsets of a given integer array that may contain duplicates. The approach involves sorting the input array to handle duplicates effectively and using backtracking to explore all combinations. The solution ensures that no duplicate subsets are included in the final result by skipping over repeated elements during the generation process. The time complexity is O(2^n), where n is the number of elements in the input array.
    [Problem Description: subsetsWithDup](https://leetcode.com/problems/subsets-ii/description/)

  - **numDecodings**: Developed a solution for the "Decode Ways" problem, which counts the number of ways to decode a given string of digits based on a specific mapping (1 to A, 2 to B, ..., 26 to Z). The solution employs dynamic programming to efficiently compute the number of valid decodings by considering both one-digit and two-digit possibilities at each step. It initializes a dp array to store the number of ways to decode substrings and iterates through the string while checking for valid digit combinations. The time complexity is O(n), where n is the length of the input string.
    [Problem Description: numDecodings](https://leetcode.com/problems/decode-ways/description/)
* Day 251: 🍞 Bakery Management System in Python 🥐

  Today, I developed a Bakery Management System using Python, emphasizing Object-Oriented Programming (OOP) principles. This project allows users to manage bakery items, including adding, removing, updating, and searching for items, as well as calculating the total inventory value. Below are the key highlights:

  - **Encapsulation**: The `BakeryItem` class encapsulates attributes like `name`, `price`, and `quantity`. This ensures that each item has controlled access to its properties, promoting data integrity within the system.

  - **Data Management**: The system allows for comprehensive management of bakery items. Users can add new items with details such as name, price, and quantity. The application supports removing items and updating existing ones, making it flexible for various bakery operations.

  - **Search Functionality**: Users can search for bakery items by name. This feature enhances usability by allowing quick access to specific items without having to sift through the entire inventory.

  - **Total Inventory Value Calculation**: The application calculates and displays the total value of all items in the inventory. This feature is crucial for understanding stock value and making informed business decisions.

  - **User-Friendly Interface**: A menu-driven interface provides an intuitive way for users to interact with the system. Options include viewing all items, adding new items, removing or updating existing items, searching by name, and displaying total inventory value.

  - **Modular Design**: The project follows the Model-View-Controller (MVC) architecture pattern. This separation of concerns ensures that the code is organized and maintainable. The model handles data representation, the view manages user interaction, and the controller processes user inputs and updates the model accordingly.

  This project was a valuable exercise in applying OOP principles to create a functional and maintainable system. It allowed me to deepen my understanding of encapsulation and modular design while building a practical tool tailored for bakery management.
* Day 252:  🎶 Music Melody Generator in Python 🎵

  Today, I developed a **Music Melody Generator** using Python, which leverages recursion and object-oriented programming principles to create random melodies based on predefined musical rules. The project focuses on generating sequences of musical notes, showcasing how simple rules can lead to complex and interesting outputs. Here are the key highlights:

  - **Class Structure**: The `MusicGenerator` class encapsulates the logic for melody generation. It defines production rules that determine which notes can follow each other, allowing for a structured approach to generating music.

  - **Recursive Melody Generation**: The core functionality is implemented in the `generate_melody` method, which uses recursion to build a melody of specified depth. Starting from a given note, the method explores possible next notes based on the defined rules, creating a unique melody each time it is executed.

  - **Random Note Selection**: To add variety and unpredictability to the generated melodies, the program randomly selects the next note from the available options. This randomness ensures that each melody produced is distinct and engaging.

  - **Base Case Handling**: The recursion includes a base case that stops further note generation when the specified depth is reached or when there are no valid next notes. This ensures that the program runs efficiently and produces coherent melodies.

  - **User-Friendly Output**: The generated melodies are printed in a clear format, making it easy for users to listen to or analyze the output. This feature enhances user engagement and provides immediate feedback on the program's functionality.

  - **Potential for Expansion**: This project lays the groundwork for future enhancements, such as adding more complex musical rules, incorporating user input for starting notes or melody lengths, or even integrating sound playback capabilities.

  This project was an exciting exploration of how programming can intersect with music theory. It allowed me to apply concepts of recursion and object-oriented design while creating something artistic and fun. I look forward to expanding this generator further and experimenting with different musical structures!
* Day 253: 🧠 Stroke Prediction Dataset [Kaggle](https://www.kaggle.com/datasets/fedesoriano/stroke-prediction-dataset/data)

  Today, I worked on analyzing the Stroke Prediction Dataset from Kaggle using Python. The focus was on data preprocessing, model training, and evaluation using various machine learning algorithms. This project aims to predict the likelihood of strokes based on health-related features. Below are the key highlights:

  - **Data Loading and Inspection**: The dataset was loaded using Pandas, and initial inspection was performed to understand its structure and identify any missing values.

  - **Data Preprocessing**: 
    - **Handling Missing Values**: Missing values were addressed by filling them with the mean of the respective columns for numerical data.
    - **Encoding Categorical Variables**: Categorical features such as gender, marital status, work type, residence type, and smoking status were encoded into numerical values using `LabelEncoder`.

  - **Feature Selection**: The features were separated from the target variable (stroke), ensuring that only relevant data was used for training the models.

  - **Model Training**: Various classification models were implemented to predict strokes:
    - **Logistic Regression**
    - **Support Vector Classifier**
    - **Random Forest Classifier**
    - **Decision Tree Classifier**
    - **Gradient Boosting Classifier**

  - **Model Evaluation**: Each model's performance was evaluated using accuracy scores and classification reports that included precision, recall, and F1-score. This provided insights into how well each model performed in predicting stroke occurrences.

  - **Results Summary**: The results for each model were compiled, showcasing their accuracy and detailed classification metrics. This analysis helped identify which model performed best for this particular dataset.

  - **User-Friendly Functions**: The project included modular functions that allowed for easy execution of the entire analysis process, enhancing code readability and maintainability.

  This project provided a valuable opportunity to deepen my understanding of machine learning techniques in Python while working with a critical health-related dataset. The experience emphasized the importance of data preprocessing and model evaluation in building effective predictive models.
* Day 254: 📝 Note Taking Application in Python 🗒️

  Today, I developed a Note Taking Application using Python and Tkinter, focusing on creating a user-friendly interface with essential functionalities for managing notes. The project allows users to add, edit, delete, search, and save notes persistently. Below are the key highlights:

  - **User Interface**: The application features a clean and intuitive GUI built with Tkinter. It includes a text area for displaying notes and buttons for various actions, all styled with a dark theme for better visibility.

  - **Persistent Storage**: Notes are saved to a JSON file (`notes.json`) when added or modified. This ensures that users can access their notes even after closing the application. The application loads existing notes at startup, providing a seamless experience.

  - **CRUD Operations**: The application supports full CRUD (Create, Read, Update, Delete) functionality:
    - **Add Note**: Users can create new notes through a simple dialog.
    - **Edit Note**: Existing notes can be modified by selecting the note's index.
    - **Delete Note**: Users can remove notes with a confirmation dialog to prevent accidental deletions.
    - **Search Note**: A search feature allows users to find specific notes based on keywords.

  - **Error Handling**: The application includes error handling for user inputs, ensuring that invalid operations (like editing or deleting non-existent notes) are managed gracefully with informative error messages.

  - **User Experience Enhancements**: 
    - Buttons have distinct colors for different actions, enhancing usability and aesthetics.
    - Hover effects provide visual feedback when interacting with buttons.
    - The text area supports easy navigation and readability.

  - **Future Improvements**: Potential enhancements could include text formatting options (bold, italic), color coding for notes, and keyboard shortcuts for common actions. Additionally, implementing advanced search capabilities could further improve functionality.

  This project was an excellent exercise in applying Python programming skills and working with GUI development using Tkinter. It provided valuable experience in managing data persistently and designing user-friendly interfaces while building a practical tool for note-taking.
* Day 255: 🛒 Shopping List Notification System in Python 📬

  Today, I developed a Shopping List Notification System using Python, leveraging the `plyer` library to send desktop notifications. This simple yet effective project helps users keep track of their shopping items by alerting them with a notification on their Windows desktop. Below are the key highlights:

  - **Notification Feature**: The primary functionality of the system is to send a desktop notification containing the user's shopping list. This is accomplished using the `plyer` library, which provides a straightforward interface for creating notifications across different platforms.

  - **Dynamic Shopping List**: The system allows users to define their shopping list as a list of items. This flexibility enables easy updates and modifications to the list before sending the notification.

  - **User-Friendly Interface**: Although this version is a simple script, it can be easily extended with a user interface (UI) in the future. For now, users can modify the shopping list directly in the code and run the script to receive their notifications.

  - **Code Structure**: The code is organized into a function (`send_shopping_list_notification`) that handles the creation and display of the notification. This modular approach makes it easy to integrate additional features or enhancements later.

  - **Installation Requirements**: Users need to install the `plyer` library to run the script. This can be done easily via pip, ensuring that anyone can set up the project without hassle.

  - **Actionable Notifications**: The notifications provide a clear overview of what items need to be purchased, helping users stay organized and efficient during their shopping trips.

  This project was an engaging exercise in using Python for practical applications beyond just command-line interfaces. It reinforced my understanding of how libraries can enhance functionality and improve user experience through notifications. I look forward to expanding this project with additional features such as user input for dynamic list management or integration with online grocery services.
* Day 256: 📚 Study Notification System in Python ⏰

  Today, I developed a Study Notification System using Python, aimed at helping students manage their study schedules by sending timely notifications for various subjects. This project focuses on enhancing study habits and ensuring that important topics are reviewed in a timely manner. Here are the key highlights:

  - **Scheduled Notifications**: The system sends notifications at specified times for different subjects, utilizing the `schedule` library to manage timing effectively. This ensures that students receive reminders when they need them most.

  - **Dynamic Subject List**: Users can easily define and modify a list of subjects along with their corresponding review times and helpful tips directly in the code. This flexibility allows for quick adjustments to the study schedule as needed.

  - **Helpful Tips**: Each notification includes a relevant tip related to the subject being reviewed. This feature provides additional context and guidance, enhancing the overall study experience.

  - **Code Structure**: The code is organized into functions that handle both the scheduling and sending of notifications. This modular approach promotes maintainability and makes it easy to add new features in the future.

  - **Installation Requirements**: To run the script, users need to install both the `plyer` and `schedule` libraries. These can be installed easily via pip, making it accessible for anyone interested in improving their study habits.

  - **User Engagement**: The notifications serve as actionable reminders, helping students focus on specific topics while providing tips that can improve their understanding and retention of material.

  This project was an excellent opportunity to apply Python in an educational context, demonstrating how technology can assist in effective learning strategies. I look forward to expanding this system with features such as user input for dynamic scheduling or integration with calendar applications.
* Day 257: Technical Test "reverseBetween" and "restoreIpAddresses" [LeetCode](https://leetcode.com/problems/)

  - **reverseBetween**: Implemented a solution for the "Reverse Linked List II" problem, where the task is to reverse a portion of a singly linked list between two given positions, `left` and `right`. The approach uses a two-pointer technique to identify the nodes before and after the segment to be reversed, and then performs the reversal in place. The time complexity is O(n), where n is the number of nodes in the list, as we traverse the list at most twice.
    [Problem Description: reverseBetween](https://leetcode.com/problems/reverse-linked-list-ii/description/)

  - **restoreIpAddresses**: Developed a solution for the "Restore IP Addresses" problem, which generates all possible valid IP addresses from a string of digits. The solution employs backtracking to explore all possible placements of dots in the string while ensuring that each segment formed adheres to the rules for valid IP addresses (0-255 and no leading zeros). The time complexity is O(1) in terms of processing since there are at most 256 valid IP addresses that can be formed from a given string.
    [Problem Description: restoreIpAddresses](https://leetcode.com/problems/restore-ip-addresses/description/)
* Day 258: 🏨 Hotel Booking System in Python 🛏️

  Today, I developed a Hotel Booking System using Python, focusing on recursion to manage room bookings. The project simulates a simple hotel environment where users can book rooms until they choose to stop. Below are the key highlights:

  - **Recursion**: The core functionality of the booking system is implemented using a recursive function. This allows users to book multiple rooms in a seamless manner, where each booking prompts for guest details and confirms the reservation.

  - **User Interaction**: The program engages users by asking for their name and the number of nights they wish to stay. After confirming each booking, it inquires whether they would like to make another reservation, demonstrating an interactive experience.

  - **Room Availability Management**: The system tracks the number of available rooms. If no rooms are available, it informs the user and exits gracefully, ensuring that the user experience remains smooth and informative.

  - **Data Handling**: Although this implementation is basic, it lays the groundwork for managing guest information and room availability. Future enhancements could include storing guest details in a database or file for persistent data management.

  - **Simplicity and Clarity**: The code is structured to be straightforward and easy to understand, making it accessible for beginners learning about recursion and user input handling in Python.

  This project was an excellent opportunity to practice recursion and enhance my skills in creating interactive command-line applications. It allowed me to explore how recursive functions can simplify complex tasks, such as managing repeated user interactions in a hotel booking scenario. I look forward to expanding this system with more features, such as payment processing and room types!
* Day 259: 📊 Data Processing Pipeline in Python 🐍

  Today, I developed a simple Data Processing Pipeline in Python, focusing on the Extract, Transform, Load (ETL) process. This project demonstrates how to efficiently manage data from extraction to transformation and finally loading it into a new format. Below are the key highlights:

  - **Data Extraction**: The pipeline begins by extracting data from a CSV file using the `pandas` library. The `extract_data` function reads the input file and returns a DataFrame containing the raw data. This step is crucial for ensuring that we have a structured format to work with.

  - **Data Transformation**: In the transformation phase, I implemented filtering and additional calculations. Specifically, I filtered out records where the salary is less than $60,000 and added a new column for tax, calculated as 20% of the salary. This step enhances the dataset by providing relevant insights and preparing it for further analysis.

  - **Data Loading**: The final stage involves loading the transformed data into a new CSV file. The `load_data` function saves the processed DataFrame to a specified output path, making it easy to access and utilize in future analyses or applications.

  - **Handling Warnings**: During development, I encountered a `SettingWithCopyWarning`. To resolve this, I ensured that modifications were made on a copy of the DataFrame slice using `.copy()` and utilized `.loc[]` for assignments. This practice not only avoids warnings but also promotes clarity in data manipulation.

  - **Project Structure**: The project is organized into a clear directory structure, with separate folders for input data and output results. This organization facilitates easy access to files and improves maintainability.

  - **User-Friendly Output**: The pipeline outputs a well-structured CSV file containing only relevant records along with calculated fields. This enhances usability for downstream applications or further data analysis tasks.

  This project was an excellent opportunity to apply my knowledge of data processing techniques in Python. It reinforced my understanding of how to build efficient ETL pipelines while managing data integrity and clarity throughout the process. Overall, this experience has equipped me with practical skills that are essential for handling real-world data workflows effectively.
* Day 260: 🌌 Koch Curve Fractal in Python 🌊

  Today, I developed a program to generate and visualize the Koch Curve, a fascinating fractal known for its intricate and self-similar structure. The project utilizes recursion to create the curve and employs Matplotlib for visualization. Here are the key highlights:

  - **Recursion**: The Koch curve is constructed using a recursive approach, where each line segment is divided into thirds and an equilateral triangle is added to create the fractal pattern. This method exemplifies how recursion can simplify complex geometric constructions.

  - **Matplotlib Visualization**: The program uses Matplotlib to plot the generated points of the Koch curve. By extracting the x and y coordinates from the computed points, we can visualize the fractal in a clear and engaging manner.

  - **Modularity**: The code is structured into two main functions: `koch_curve` for generating the fractal points and `plot_koch_curve` for handling the plotting. This modular design enhances readability and allows for easy modifications or extensions of functionality.

  - **Customization**: Users can specify the recursion depth when running the program. This feature enables exploration of different levels of complexity in the Koch curve, allowing for both simple and intricate designs.

  - **Mathematical Insight**: The project provides an opportunity to explore mathematical concepts related to fractals, such as self-similarity and infinite detail. The resulting curves exhibit properties that are both beautiful and mathematically significant.

  - **User-Friendly Interface**: The program is designed to be straightforward to run, requiring minimal input from the user while providing a visually appealing output. This makes it accessible even for those who may not have a strong programming background.

  This project was an exciting way to delve into fractals and their recursive nature while enhancing my skills in Python programming and data visualization. It reinforced my understanding of recursion and its applications in generating complex shapes, all while creating a visually stunning representation of mathematical beauty.
* Day 261: ⏳ Pomodoro Timer System in Python 🍅

  Today, I developed a Pomodoro Timer system using Python, focusing on providing a user-friendly experience for managing work and break sessions. The project implements notifications to alert users when it’s time to work or take a break, following the popular Pomodoro Technique. Here are the key highlights:

  - **Session Management**: The timer allows users to configure the duration of work sessions and break periods. By default, it is set to 25 minutes for work and 5 minutes for breaks, with the option to customize these settings.

  - **Desktop Notifications**: Utilizing the `plyer` library, the system sends desktop notifications to inform users when to start working and when to take a break. This feature enhances user engagement and helps maintain focus during work sessions.

  - **Session Tracking**: The timer keeps track of the number of completed Pomodoro sessions. Users can set a specific number of sessions to complete before taking a longer break, promoting productivity and effective time management.

  - **User Feedback**: After each session, the program prints messages to the console indicating the completion of work or break sessions, providing real-time feedback on progress.

  - **Extensibility**: The structure of the code allows for easy modifications and enhancements. Future improvements could include features such as customizable notification messages, session statistics, or integration with task management tools.

  - **Simple Interface**: The program runs in a command-line interface, making it straightforward to use without any complex setup. Users can simply run the script to start their Pomodoro sessions.

  This project was an excellent opportunity to apply my programming skills in Python while creating a practical tool for improving productivity. I gained valuable experience in working with time management concepts and desktop notifications, all while enhancing my understanding of how to structure code effectively for usability and maintainability.
* Day 262: 📈 Video Game Stocks Analysis[Kaggle](https://www.kaggle.com/datasets/datadrivenx/video-game-stocks-financial-market-data/data) 

  Today, I focused on analyzing the financial market data of top video game stocks using Python. The analysis involved data cleaning, visualization, and modeling to understand trends and performance in the gaming industry. Below are the key highlights of the project:

  - **Data Import and Preparation**: I utilized Pandas to load the dataset from Kaggle, which includes stock prices for various video game companies. The dataset was cleaned to handle missing values and ensure proper formatting for analysis.

  - **Exploratory Data Analysis (EDA)**: I conducted a thorough EDA to visualize stock trends over time. This included:
    - **Time Series Plots**: Line graphs were created to display the stock price movements of different companies over time, allowing for a visual comparison of their performance.
    - **Statistical Summary**: A summary of key statistics (mean, median, standard deviation) was generated for each company's stock prices, providing insights into their volatility and average performance.

  - **Correlation Analysis**: I examined correlations between the stock prices of different companies. A heatmap was generated to visually represent these relationships, helping identify which companies' stocks move together.

  - **Modeling**: Implemented machine learning models such as Logistic Regression and Random Forest Classifier to predict stock price movements based on historical data. The models were evaluated using metrics like accuracy score and classification report.

  - **Visualization Techniques**: Leveraged Matplotlib and Seaborn for creating various plots:
    - **Bar Charts**: Used to compare average stock prices among different companies.
    - **Histograms**: Displayed the distribution of stock prices, aiding in understanding price ranges and frequencies.

  - **User-Friendly Functions**: Developed modular functions for data loading, preprocessing, and visualization. This enhances code reusability and makes it easier to run analyses with different datasets.

  This project provided valuable insights into the financial dynamics of the video game industry, reinforcing the importance of data analysis in making informed investment decisions. The experience highlighted how visualizations can effectively communicate complex financial trends and patterns.
* Day 263: Technical Test "inorderTraversal" and "generateTrees" [LeetCode](https://leetcode.com/problems/)

  - **inorderTraversal**: Implemented a solution for the "Binary Tree Inorder Traversal" problem, which requires returning the values of nodes in an inorder sequence (left, root, right). The approach uses recursion to traverse the tree and collect node values in the correct order. The time complexity is O(n), where n is the number of nodes in the tree.
    [Problem Description: inorderTraversal](https://leetcode.com/problems/binary-tree-inorder-traversal/description/)

  - **generateTrees**: Developed a solution for the "Unique Binary Search Trees II" problem, where the goal is to generate all structurally unique BSTs that can be formed using integers from 1 to n. The algorithm utilizes recursion with memoization to efficiently generate trees by considering each number as a potential root and recursively generating all possible left and right subtrees. The time complexity is O(n^n) due to the exponential number of unique trees that can be formed.
    [Problem Description: generateTrees](https://leetcode.com/problems/unique-binary-search-trees-ii/description/)
* Day 264: 🛒 E-Commerce Shopping Cart in Python 🛍️

  Today, I developed an E-Commerce Shopping Cart application using Python, focusing on Object-Oriented Programming (OOP) principles. This project enables users to manage their shopping cart effectively by adding, removing, and modifying products, while also calculating totals with applicable taxes and discounts. Here are the key highlights:

  - **Encapsulation**: The `Product` class encapsulates attributes such as `name`, `price`, and `stock`, ensuring that product details are protected and can only be modified through defined methods. This prevents unauthorized changes to the product's state.

  - **Shopping Cart Management**: The `ShoppingCart` class manages a collection of products, allowing users to add items while checking stock availability. It provides methods for removing products and modifying quantities, making it easy to manage the cart's contents.

  - **Total Calculation**: The application includes a method to calculate the total price of items in the cart, incorporating optional tax rates and discounts. This feature ensures that users can see the final amount they need to pay, enhancing the shopping experience.

  - **Testing Functionality**: A dedicated testing function simulates various operations on the shopping cart, such as adding products, modifying quantities, removing items, and calculating totals. This helps verify the correctness of the implementation and ensures robustness.

  - **User-Friendly Interface**: Although the application runs directly in Python without a graphical interface, it is designed to be intuitive. Users can easily understand how to interact with the cart through clear method calls and console output.

  - **Future Enhancements**: Potential improvements include implementing user authentication for personalized shopping experiences, adding support for multiple users managing their own carts concurrently, integrating a database for persistent storage, and creating a user-friendly graphical interface.

  This project was an excellent opportunity to apply OOP principles in a practical scenario. I refined my understanding of encapsulation and how it contributes to creating maintainable code while building a functional shopping cart system that could be expanded in future iterations.
* Day 265: 🏀 Basketball Injury Tracker in Python 🏥

  Today, I developed a Basketball Injury Tracker using Python, focusing on Object-Oriented Programming (OOP) principles to create a structured and maintainable system. The project allows coaches and medical staff to monitor player injuries, record recovery times, and maintain injury histories. Below are the key highlights:

  - **Encapsulation**: The `Player` class encapsulates player details and their injury records, ensuring that injury data is managed internally while providing methods for adding and retrieving injuries.

  - **Class Structure**: The system consists of multiple classes:
    - `Player`: Represents a basketball player and maintains their injury history.
    - `Injury`: Represents individual injuries with details such as type and recovery time.
    - `MedicalTeam`: Handles notifications to medical staff when a new injury is recorded.
    - `InjuryTracker`: Manages all players and their injuries, providing a central interface for interaction.

  - **Injury Management**: Coaches can record injuries for players, specifying the type of injury and estimated recovery time. The system automatically notifies the medical team about new injuries, ensuring prompt attention.

  - **Injury History**: Users can view the complete injury history for any player, allowing for better tracking of recurring issues and overall player health management.

  - **Menu-Driven Interface**: A user-friendly command-line interface allows users to interact with the system easily. Users can add players, record injuries, view injury histories, or exit the program through simple menu options.

  - **Future Enhancements**: The project is designed to be easily extendable. Future improvements could include data persistence (e.g., using a database), enhanced notification systems (e.g., email alerts), or a graphical user interface (GUI) for better usability.

  This project was an excellent opportunity to apply OOP principles in a practical context. I refined my understanding of how encapsulation and class design contribute to creating clean and efficient code while building a useful tool for managing basketball player injuries.
* Day 266: 📊 Collatz Conjecture Sequence Visualizer in Python 🌌

  Today, I developed a Collatz Conjecture Sequence Visualizer using Python. This project focuses on generating and plotting the Collatz sequence for a given positive integer, featuring a user-friendly graphical interface. Below are the key highlights:

  - **Collatz Sequence Generation**: The program generates the Collatz sequence for any positive integer input by the user, following the rules of the conjecture: if the number is even, divide it by two; if odd, multiply by three and add one. This process continues until reaching the number one.

  - **Data Visualization**: Utilizing `matplotlib`, the sequence is plotted in a visually appealing manner. The plot includes markers for each step in the sequence, providing a clear representation of how the values change over time.

  - **Dark Background Theme**: The plot features a dark background style, enhancing visibility and aesthetics. This design choice ensures that the plot elements (lines, markers, and grid) stand out clearly against the background.

  - **User Input via GUI**: A simple graphical user interface (GUI) is implemented using `tkinter`. Users can input a positive integer through a dialog box, making the application more interactive and accessible compared to command-line input.

  - **Error Handling**: The program includes error handling for invalid inputs. If a user enters a non-positive integer or cancels the input dialog, appropriate messages are displayed to guide them towards valid input.

  - **Customizable Plot Features**: The plot includes customizable features such as grid lines and tick colors, allowing for an enhanced viewing experience. Users can easily interpret the plotted data thanks to these thoughtful design choices.

  This project was an excellent exercise in data visualization and GUI development in Python. It allowed me to deepen my understanding of how to effectively use libraries like `matplotlib` and `tkinter` to create interactive applications that present mathematical concepts in an engaging way. I enjoyed refining my skills in both coding and design while building this practical tool for exploring the fascinating Collatz conjecture.
* Day 267: 🎯 Subset Sum to Target in Python 🧮

  Today, I worked on a project that focuses on solving the "Subset Sum to Target" problem using Python. The goal of this project is to find all combinations of numbers in a given array that sum up to a specified target value. The implementation leverages recursion to explore all possible subsets. Below are the key highlights:

  - **Recursive Backtracking**: The core of the solution is a recursive backtracking algorithm that explores all potential combinations of numbers. It builds subsets incrementally and checks their sums against the target.

  - **Base Cases**: The algorithm includes essential base cases:
    - If the current sum equals the target, the current subset is added to the results.
    - If the current sum exceeds the target, further exploration is halted for that path.

  - **Dynamic Path Management**: As subsets are built, they are stored in a temporary list (`path`). This allows for easy backtracking by removing the last added element when exploring new combinations.

  - **Exploration of Combinations**: The function iterates through the list of numbers, starting from a given index, ensuring that each number is only considered once per subset. This prevents duplicates and maintains unique combinations.

  - **Example Usage**: An example is provided in the code to demonstrate how to call the function with a sample list and target value. This makes it easy for users to test and modify inputs as needed.

  - **Output**: The program outputs all unique subsets that sum up to the specified target, providing a clear and practical solution to the problem.

  This project was an excellent exercise in understanding recursive algorithms and their applications in combinatorial problems. It enhanced my skills in problem-solving and algorithm design while providing insights into how recursion can be effectively utilized to explore complex scenarios.
* Day 268: 🛠️ Team Role Management System in Python 👥

  Today, I developed a Team Role Management System using Python, focusing on the Model-View-Controller (MVC) architecture and Object-Oriented Programming (OOP) principles. This project allows users to manage roles within a development team by adding, removing, viewing, and updating roles. Below are the key highlights:

  - **Model-View-Controller (MVC)**: The application is structured using the MVC pattern, which separates concerns into three components:
    - **Model**: Manages data and business logic related to roles.
    - **View**: Handles user interface and displays information.
    - **Controller**: Acts as an intermediary between the model and view, processing user input and updating the model accordingly.

  - **Role Management**: Users can perform various operations on roles:
    - **Add New Role**: Users can add new roles with titles and descriptions.
    - **Remove Role**: Users can remove existing roles by title.
    - **View All Roles**: The system displays all current roles in the team.
    - **View Specific Role**: Users can view details of a specific role by its title.
    - **Update Existing Role**: Users can update the title and description of an existing role.

  - **User-Friendly Interface**: The application features a menu-driven interface that allows users to easily navigate through different options. This enhances usability and provides a clear interaction model.

  - **Data Structure**: The roles are encapsulated in a `Role` class, which includes attributes like `title` and `description`. This promotes encapsulation by keeping role-related data organized and manageable.

  - **Extensibility**: The design allows for future enhancements, such as adding more attributes to roles (e.g., responsibilities or required skills) or integrating with a database for persistent storage.

  This project was an excellent exercise in applying OOP principles and the MVC architecture to create a structured and maintainable system. I refined my understanding of how these concepts work together to build clean, reusable code while developing a practical tool for managing team roles effectively.
* Day 269: 🏥 Medical Cost Personal Datasets Analysis 

  Today, I worked on analyzing the Medical Cost Personal Datasets from Kaggle using Python. The focus was on data exploration, feature engineering, and visualization using various libraries such as Pandas, NumPy, Seaborn, and Matplotlib. Below are the key highlights:

  - **Data Loading and Inspection**: 
    - The project begins with loading the dataset using Pandas. We perform an initial inspection to understand the structure and columns of the dataset. This involves checking for null values, data types, and basic statistics.
    - Sample rows from the dataset are displayed to get a quick view of the data.

  - **Statistical Summary**:
    - A function is created to generate a statistical summary of numerical variables, providing insights such as mean, median, standard deviation, minimum, and maximum values. This helps in understanding the central tendency and spread of the data.
    - Descriptive statistics for categorical variables (e.g., region, sex, and smoker status) are also included to gain insights into their distribution.

  - **Exploratory Data Analysis (EDA)**:
    - Visualization of numerical distributions using histograms to detect skewness, outliers, and normality.
    - Box plots are used to visualize distributions across different categories and to detect outliers in the data.
    - The dataset is further analyzed with Seaborn to visualize relationships between variables. Pair plots are used to see scatter plots for numerical variables and to quickly grasp the correlation between them.
    
  - **Categorical Analysis**:
    - Distribution of categorical variables is visualized using bar graphs. This approach allows us to see the frequency of different categories (e.g., smoker status, region) and provides insights into patterns such as healthcare costs across different demographics.

  - **Correlation Analysis**:
    - A correlation matrix is generated to understand relationships between numerical variables. This is visualized using a heatmap to enhance readability and clarity.
    - Insights from the correlation matrix guide further feature engineering and understanding of factors affecting medical costs.

  - **Feature Engineering**:
    - Based on the initial insights from EDA, new features are engineered. For example, BMI (Body Mass Index) is calculated and analyzed in relation to medical costs.
    - The impact of factors such as age, sex, smoking status, and region on healthcare costs is examined.

  - **Modular Analysis Functions**:
    - The project includes functions that allow for easy execution of the analysis. This includes functions to generate the full report, visualize distributions, and check for correlations.
    - The use of modular functions enhances code readability and maintainability.

  This project reinforced the importance of data visualization and feature engineering in understanding complex datasets. It also emphasized the value of modular code for easy maintenance and scalability in data science projects.
* Day 270: Pose Estimation Project with Python 🤖

  Today, I worked on a Pose Estimation project using Python, leveraging the power of MediaPipe and OpenCV. The project focuses on real-time human pose detection from video files, providing visual feedback in the form of landmarks and connections between key points. Below are the key highlights:

  - **Pose Detection**: The system utilizes MediaPipe's Pose module to detect human body landmarks in real-time. It processes each frame of the video to identify and visualize key points such as shoulders, elbows, wrists, hips, knees, and ankles.

  - **Modular Design**: The project is structured into multiple modules:
    - `Basics.py`: This module handles the main functionality of reading video input and displaying detected poses.
    - `PoseModule.py`: Contains the `PoseDetector` class, which encapsulates the logic for pose detection and landmark processing.
    - `Test.py`: Serves as the entry point for testing the pose detection functionality with a selected video file.

  - **User Interaction**: The application allows users to select video files via a graphical user interface (GUI) using `tkinter`. This enhances usability by providing an intuitive way to load videos for processing.

  - **Real-Time Visualization**: Detected landmarks are visualized on the input video frames with circles drawn around each landmark. Additionally, connections between landmarks can be displayed to illustrate the skeletal structure of the detected pose.

  - **FPS Calculation**: The system calculates and displays frames per second (FPS) in real-time, providing insights into the performance of the pose detection algorithm during video playback.

  - **Landmark Data Export**: Users have the option to save detected landmark positions to a CSV file for further analysis or record-keeping. This feature is useful for applications in sports science, physical therapy, and motion analysis.

  - **Documentation and Code Quality**: The code is well-documented with comments explaining each section and function. This ensures that future developers can easily understand and extend the functionality of the project.

  This project was an excellent opportunity to apply my knowledge of computer vision and machine learning in a practical context. I gained valuable experience working with MediaPipe for pose estimation and learned how to structure a Python application in a modular way. Overall, this project showcases my ability to integrate different technologies to create a functional tool for real-time human pose analysis.
* Day 271: Technical Test "numTrees" and "isInterleave" [LeetCode](https://leetcode.com/problems/)

  - **numTrees**: Implemented a solution for the "Unique Binary Search Trees" problem, which requires calculating the number of structurally unique BSTs that can be formed with `n` nodes, where each node has a unique value from 1 to `n`. The solution utilizes dynamic programming to build a table that counts the unique trees based on previously computed values. The time complexity of this approach is \(O(n^2)\), making it efficient for reasonable values of `n`.
    [Problem Description: numTrees](https://leetcode.com/problems/unique-binary-search-trees/description/)

  - **isInterleave**: Developed a solution for the "Interleaving String" problem, which checks if a string `s3` can be formed by interleaving two other strings `s1` and `s2`. The approach employs dynamic programming to create a table that tracks whether substrings of `s1` and `s2` can form substrings of `s3`. The time complexity is \(O(n \times m)\), where `n` and `m` are the lengths of `s1` and `s2`, respectively.
    [Problem Description: isInterleave](https://leetcode.com/problems/interleaving-string/description/)
* Day 272: 🔺 Pascal's Triangle Row Finder in Python 🔺

  Today, I developed a Pascal's Triangle Row Finder using Python, focusing on recursion to calculate specific rows of the triangle. This project not only computes the values of a given row but also visualizes the results using Matplotlib. Here are the key highlights:

  - **Recursion**: The project utilizes a recursive function to compute the binomial coefficients, which are essential for generating each element of Pascal's Triangle. The function `binomial_coefficient(n, k)` implements the mathematical definition of combinations recursively.

  - **Row Generation**: The function `pascal_triangle_row(n)` generates the nth row of Pascal's Triangle by iterating through all possible values of k (from 0 to n) and calculating each coefficient using the recursive function. This approach showcases how recursion can simplify complex calculations.

  - **Data Visualization**: To enhance understanding, I incorporated Matplotlib to plot the generated row of Pascal's Triangle. The `plot_pascal_triangle_row(row)` function creates a bar chart that visually represents the values in the specified row, making it easier to grasp the relationships between them.

  - **User Interaction**: The program allows users to specify which row of Pascal's Triangle they want to compute. By changing the value of `n`, users can explore different rows and see how the triangle expands.

  - **Educational Value**: This project serves as an excellent exercise in understanding combinatorial mathematics and recursion in programming. It reinforces concepts such as base cases and recursive cases, while also demonstrating how to visualize mathematical concepts through programming.

  This project was not only a fun challenge but also an opportunity to deepen my understanding of recursion and its applications in generating mathematical structures like Pascal's Triangle. I enjoyed integrating data visualization to make the results more accessible and engaging!
* Day 273: 🏺 Mythical Characters Management System in Python 🐉

  Today, I developed a Mythical Characters Management System using Python, focusing on the Model-View-Presenter (MVP) architecture and key Object-Oriented Programming (OOP) principles. This project allows users to manage characters from various mythologies such as Arthurian, Greek, and Japanese. Below are the key highlights:

  - **Model-View-Presenter (MVP)**: The application is structured using the MVP pattern, which separates concerns into three components:
    - **Model**: Manages data and business logic related to mythical characters.
    - **View**: Handles user interface and displays information.
    - **Presenter**: Acts as an intermediary between the model and view, processing user input and updating the model accordingly.

  - **Character Management**: Users can perform various operations on mythical characters:
    - **Add New Character**: Users can add new characters with names, mythological origins, and descriptions.
    - **Remove Character**: Users can remove existing characters by name.
    - **View All Characters**: The system displays all current mythical characters.
    - **View Specific Character**: Users can view details of a specific character by name.
    - **Update Existing Character**: Users can update both the name and description of an existing character.

  - **User-Friendly Interface**: The application features a menu-driven interface that allows users to easily navigate through different options. This enhances usability and provides a clear interaction model.

  - **Data Structure**: The characters are encapsulated in a `MythicalCharacter` class, which includes attributes like name, mythology, and description. This promotes encapsulation by keeping character-related data organized and manageable.

  - **Extensibility**: The design allows for future enhancements, such as adding more attributes to characters (e.g., powers or historical significance) or integrating with a database for persistent storage.

  This project was an excellent opportunity to apply OOP concepts and the MVP architecture to create a structured and maintainable system. I refined my understanding of how these concepts work together to build clean, reusable code while developing a practical tool for managing mythical characters effectively.
* Day 274: 🧪 Synthetic Data Generator in Python 🗃️

  Today, I developed a **Synthetic Data Generator** using Python and Tkinter. This tool allows users to create customizable synthetic datasets with adjustable parameters for various statistical distributions. The project emphasizes user experience, data visualization, and real-time input validation. Below are the key highlights:

  - **User Interface**: The application features a clean and intuitive Tkinter GUI that allows users to select different types of distributions (Normal, Uniform, Binomial, and Poisson) and input necessary parameters. The dark theme enhances usability and aesthetics.

  - **Data Generation**: Users can generate synthetic datasets based on their selected distribution. The application utilizes NumPy to efficiently create datasets with specified parameters like mean, standard deviation, range, etc.

  - **Real-Time Input Validation**: The application includes real-time validation of user inputs. The "Generate Data" button is enabled only when all inputs are valid, preventing errors and enhancing user experience.

  - **Data Visualization**: After generating the dataset, a histogram is displayed using Matplotlib. This visual representation helps users understand the distribution of generated data at a glance.

  - **Export Functionality**: Users can save the generated dataset in CSV format for further analysis or use in other applications. This feature makes the tool practical for data scientists and analysts.

  - **Error Handling**: Comprehensive error handling ensures that users receive informative messages when invalid inputs are provided or when no data has been generated yet.

  This project was an excellent opportunity to apply my knowledge of Python programming, GUI development with Tkinter, and data visualization using Matplotlib. It reinforced my understanding of how to create user-friendly applications that effectively meet user needs while providing valuable functionality. Overall, it was a rewarding experience in building a practical tool for synthetic data generation.
* Day 275: Technical Test "isValidBST" and "recoverTree" [LeetCode](https://leetcode.com/problems/)

  - **isValidBST**: Implemented a solution for the "Validate Binary Search Tree" problem, which checks if a given binary tree is a valid binary search tree (BST). A valid BST is defined such that for each node, all values in its left subtree are less than the node's value, and all values in its right subtree are greater. The solution uses an in-order traversal approach to ensure that the values are in sorted order. The time complexity is O(n), where n is the number of nodes in the tree.
    [Problem Description: isValidBST](https://leetcode.com/problems/validate-binary-search-tree/description/)

  - **recoverTree**: Developed a solution for the "Recover Binary Search Tree" problem, where two nodes of a BST have been swapped by mistake. The task is to recover the tree without changing its structure. The approach involves performing an in-order traversal to identify the two swapped nodes and then swapping their values back. This method also runs in O(n) time complexity, as it requires a single traversal of the tree.
    [Problem Description: recoverTree](https://leetcode.com/problems/recover-binary-search-tree/description/)
* Day 276: 📊 Custom Dashboard Generator in Python 🖥️

  Today, I developed a Custom Dashboard Generator using Python and Tkinter, allowing users to create personalized dashboards by selecting graphs, metrics, and visualizations from a loaded dataset. This project emphasizes user-friendly design and data visualization principles. Below are the key highlights:

  - **User Interface**: The application features a clean and intuitive interface built with Tkinter. Users can easily upload datasets in CSV or Excel formats, select columns for visualization, and choose the type of graph they want to create.

  - **Data Handling**: The application supports loading datasets from various file formats, including CSV and Excel (`.xls` and `.xlsx`). It uses the `pandas` library to read data efficiently and update the UI dynamically based on the dataset's columns.

  - **Graphical Visualization**: Users can create three types of visualizations: Bar graphs, Line graphs, and Pie charts. The application utilizes Matplotlib for rendering these graphs, providing clear and informative visual representations of the data.

  - **Customizability**: The dashboard allows users to select specific columns from their dataset for visualization, making it adaptable to different data structures. This flexibility is crucial for users who may work with diverse datasets.

  - **Enhanced User Experience**: The UI includes improved button styles for better accessibility and comfort. The background color is set to a light gray for a modern look, enhancing the overall aesthetic of the application.

  - **Label Rotation**: To improve readability, the x-axis labels on the graphs are rotated at 45 degrees. This adjustment ensures that longer labels do not overlap, making the visualizations clearer.

  This project was an excellent opportunity to combine data analysis with user interface design. I learned how to effectively use Tkinter for creating interactive applications and how to integrate data visualization libraries like Matplotlib with `pandas`. Overall, it was a rewarding experience that enhanced my skills in Python programming and application development.
* Day 277: 🌊 Koch Curve Visualization in Python 📈

  Today, I delved into fractal geometry by implementing the Koch curve using Python. This project focuses on recursive programming techniques to generate and visualize the iconic snowflake-like pattern of the Koch curve. Below are the key highlights of my work:

  - **Recursive Functionality**: The `koch_curve` function generates the points of the Koch curve through recursion. It divides each line segment into thirds, calculates the peak of an equilateral triangle, and recursively constructs smaller segments until the specified depth is reached.

  - **Matplotlib for Visualization**: I utilized the `matplotlib` library to plot the generated points. The `plot_koch_curve` function takes a recursion depth as input and creates a visual representation of the Koch curve, allowing for easy exploration of how increasing depth affects the curve's complexity.

  - **Dynamic Depth Adjustment**: The program allows users to modify the recursion depth, enabling them to observe how the detail and intricacy of the Koch curve evolve with deeper iterations. This feature enhances user engagement and understanding of fractals.

  - **Equilateral Triangle Calculation**: A crucial aspect of generating the Koch curve is calculating the coordinates for the peak of the triangle formed at each iteration. This involves basic trigonometry, ensuring that each segment maintains its geometric properties.

  - **Visual Aesthetics**: The resulting plot features a clean and visually appealing design, with an equal aspect ratio and grid lines for better readability. The title dynamically reflects the current recursion depth, providing context for viewers.

  - **Educational Insights**: This project serves as an excellent introduction to fractals and recursive algorithms. It deepened my understanding of how simple geometric rules can lead to complex and beautiful patterns, highlighting the intersection of mathematics and computer science.

  Overall, this exercise was not only fun but also enriching as it reinforced my programming skills while exploring fascinating mathematical concepts. I look forward to applying these techniques to more complex fractals and visualizations in future projects!
* Day 278: User Story Management System in Python 📖

  Today, I developed a User Story Management System using Python, focusing on the Model-View-Controller (MVC) architecture. This project allows users to create, view, edit, and delete user stories while maintaining data persistence through JSON files. Here are the key highlights:

  - **Model-View-Controller (MVC) Architecture**: The system is structured using the MVC pattern, separating concerns into three distinct components:
    - **Model**: Manages the data and business logic (user stories).
    - **View**: Handles user interface and display logic.
    - **Controller**: Acts as an intermediary between the model and view, processing user input and updating the view accordingly.

  - **User Story Management**: Users can add new user stories with attributes such as title, description, priority (High/Medium/Low), and status (Pending/In Progress/Completed). This allows for better organization and tracking of user stories.

  - **Data Persistence**: User stories are saved to a JSON file (`user_stories.json`) upon exiting the application and loaded when starting the application. This ensures that data is not lost between sessions.

  - **Edit Functionality**: Users can edit existing user stories by updating their description, priority, and status. This feature enhances flexibility and usability in managing user stories.

  - **User-Friendly Interface**: The command-line interface is designed to be intuitive, providing clear prompts for user input. Users can easily navigate through options to view all stories, add new ones, remove existing ones, or edit them.

  - **Error Handling**: The application includes basic error handling for scenarios such as attempting to remove a non-existent user story or loading data from a missing file. This improves robustness and user experience.

  This project was an excellent opportunity to apply the MVC design pattern in a practical context while enhancing my understanding of data management and user interaction in Python applications. I gained valuable experience in structuring code for maintainability and scalability, making it easier to extend features in future iterations of the project.
* Day 279: ETL Process with Python for SQL Server to PostgreSQL

  Today, I focused on building an ETL (Extract, Transform, Load) process using Python to transfer data from a SQL Server database to a PostgreSQL database. The project involved creating two scripts: `test.py` for testing the connection to SQL Server and `etl.py` for extracting data, transforming it if necessary, and loading it into PostgreSQL. Here are the key highlights:

  - **Database Connection**: The `test.py` script establishes a connection to the SQL Server using the `pyodbc` library. It verifies the connection by attempting to connect and handling any exceptions that may arise. Successful connections confirm that the database is accessible.

  - **Data Extraction**: The `etl.py` script utilizes `SQLAlchemy` and `pandas` to extract data from specific tables in the SQL Server database. A SQL query is executed to retrieve the names of tables of interest, including 'DimProduct', 'DimProductSubcategory', 'DimProductCategory', 'DimSalesTerritory', and 'FactInternetSales'.

  - **Data Loading**: After extracting the data, the script loads it into PostgreSQL using the `to_sql` method from `pandas`. Each table's data is prefixed with 'stg_' to indicate that it is staging data. The process includes handling potential errors during data loading and providing feedback on the number of rows imported.

  - **Environment Variables**: Although commented out in the code, there is a provision for retrieving sensitive information like passwords and user IDs from environment variables. This practice enhances security by avoiding hardcoded credentials.

  - **Error Handling**: Both scripts include robust error handling mechanisms. Any issues encountered during connection, extraction, or loading are caught and logged, ensuring that users are informed of any problems that occur during execution.

  - **Scalability**: The design allows for easy modifications and extensions. New tables can be added to the extraction process without significant changes to the existing code structure.

  This project served as an excellent introduction to ETL processes in Python, providing hands-on experience with database connections, data extraction techniques, and loading mechanisms. I gained valuable insights into managing data workflows and ensuring data integrity throughout the transfer process between different database systems.
* Day 280: Technical Test "isSameTree" and "isSymmetric" [LeetCode](https://leetcode.com/problems/)

  - **isSameTree**: Implemented a solution for the "Same Tree" problem, where the objective is to determine if two binary trees are structurally identical and have the same node values. The approach uses a recursive method to traverse both trees simultaneously, comparing corresponding nodes. If both nodes are `None`, they are considered equal; if one is `None` and the other is not, they are not equal. If both nodes exist, their values are compared, and the function recursively checks their left and right children. The time complexity of this solution is \(O(n)\), where \(n\) is the number of nodes in the trees.
    [Problem Description: isSameTree](https://leetcode.com/problems/same-tree/description/)

  - **isSymmetric**: Developed a solution for the "Symmetric Tree" problem, which checks whether a binary tree is a mirror of itself around its center. The solution employs a helper function that compares two nodes at a time, ensuring that the left subtree of one node matches the right subtree of another node and vice versa. If both nodes are `None`, they are symmetric; if one is `None`, they are not. If both exist, their values must be equal for symmetry to hold. This recursive method also has a time complexity of \(O(n)\), where \(n\) is the number of nodes in the tree.
    [Problem Description: isSymmetric](https://leetcode.com/problems/symmetric-tree/description/)
* Day 281: 📝 Note-taking Application in Python 📓

  Today, I developed a simple Note-taking Application using Python and the Flet library. The application allows users to create, view, and delete notes in a user-friendly interface. Below are the key highlights:

  - **User Interface**: The application features an intuitive interface built with Flet, allowing users to easily add and manage their notes. The layout includes an input field for new notes and a list displaying existing notes.

  - **Dynamic Note Management**: Users can add notes by typing in the input field and clicking the "Add Note" button. Each note is displayed with a delete button, enabling users to remove notes effortlessly.

  - **Event Handling**: The application utilizes event handling to respond to user actions. When the "Add Note" button is clicked, the application captures the input, validates it, and updates the display accordingly.

  - **Global State Management**: The application maintains a global state for the list of notes, ensuring that all user interactions update the displayed list in real-time without needing to refresh the page.

  - **Code Structure**: The project is organized into functions that handle specific tasks:
    - `add_note`: Adds a new note to the list and updates the display.
    - `remove_note`: Deletes a specified note from the list.
    - `main`: Initializes the application and sets up the user interface.

  - **Extensibility**: This simple application serves as a foundation for further enhancements. Potential features could include saving notes to a file, editing existing notes, or categorizing notes for better organization.

  This project was an excellent exercise in creating a functional application using Python and Flet. It helped me reinforce my understanding of event-driven programming and dynamic user interfaces while providing a practical tool for managing personal notes.
* Day 282: 💎 Diamonds [Kaggle](https://www.kaggle.com/datasets/shivam2503/diamonds/data)

  Today, I focused on analyzing the Diamonds dataset from Kaggle using Python. The primary objective was to perform exploratory data analysis (EDA) and model the data to predict diamond prices based on various features. Below are the key highlights of the project:

  - **Data Loading and Overview**: The dataset was loaded using Pandas, and an initial overview was conducted to understand its structure and contents. The dataset includes attributes such as price, carat, cut, color, clarity, dimensions (x, y, z), depth, and table width.

  - **Data Cleaning**: I addressed missing values and removed any records with zero values in critical dimensions (x, y, z). Outliers were also filtered out based on defined thresholds for depth, table, and dimensional features.

  - **Exploratory Data Analysis (EDA)**: 
    - **Categorical Features**: Count plots were generated for categorical variables like cut, color, and clarity to visualize their distributions.
    - **Numerical Features**: Histograms and KDE plots were created for numerical features to analyze their distributions. Boxplots illustrated the relationships between numerical variables (e.g., price vs. cut).
    - **Correlation Analysis**: A heatmap was produced to examine correlations between numerical features, providing insights into potential relationships.

  - **Encoding Categorical Variables**: Categorical variables were encoded using Label Encoding to prepare the dataset for modeling.

  - **Modeling**:
    - **Train-Test Split**: The dataset was split into training and testing sets.
    - **Model Selection**: Various regression models were implemented including Linear Regression, Decision Tree Regressor, Random Forest Regressor, and Support Vector Regression.
    - **Model Evaluation**: Each model's performance was evaluated using metrics such as Mean Absolute Error (MAE), Mean Squared Error (MSE), Root Mean Squared Error (RMSE), and R² score. A comparison of results was compiled in a DataFrame for clarity.

  - **Hyperparameter Tuning**: I utilized GridSearchCV for hyperparameter tuning of the Random Forest model to optimize its performance.

  This project provided a comprehensive understanding of data analysis and modeling techniques in Python while exploring the Diamonds dataset in depth. It underscored the importance of data visualization and model evaluation in deriving meaningful insights from data.
* Day 283: 🎄 Christmas Tree Generator in Python 🎅

  Today, I worked on a fun and festive project: a Christmas Tree Generator using Python and the Turtle graphics library. This project showcases how to create a visually appealing Christmas tree with decorations and a star on top. Below are the key highlights:

  - **Turtle Graphics**: The project utilizes the Turtle graphics library, which provides an easy way to draw shapes and patterns. It allows for creative visualizations with simple commands.

  - **Tree Structure**: The tree is drawn using a series of points that define its outline. The turtle fills in the shape with a dark green color, giving it a classic Christmas tree appearance.

  - **Decorations**: Colorful ornaments are added to the tree at various positions. The colors are randomly selected from a festive palette, making each run of the program unique and vibrant.

  - **Star on Top**: A gold star is drawn at the top of the tree, symbolizing the holiday spirit. The star is created using a simple function that defines its shape through angles and movements.

  - **Festive Messages**: After drawing the tree and decorations, the program displays cheerful messages like "Happy Holidays!" and encourages users to decorate their own trees. This adds an interactive element to the project.

  - **User Interaction**: While primarily a visual project, it invites users to think about how they might extend or modify it—such as adding more decorations or changing colors—encouraging creativity and engagement.

  This project was an enjoyable exercise in using Python for graphical applications. It allowed me to explore basic programming concepts while creating something festive and fun. I look forward to expanding this project further, perhaps by adding features like animated decorations or user input for customizing the tree!
* Day 284: ❄️ Snowfall Simulation in Python with Pygame ☃️

  Today, I created a captivating Snowfall Simulation using Python's Pygame library. This project showcases falling snowflakes on a borderless window, providing a serene winter atmosphere. Below are the key features and insights from the implementation:

  - **Pygame Initialization**: The project begins by initializing the Pygame library, which is essential for creating games and multimedia applications in Python.

  - **Dynamic Window Sizing**: The simulation automatically adjusts to the user's screen dimensions using the `ctypes` library to retrieve system metrics. This ensures that the snowfall effect fills the entire screen, enhancing the visual experience.

  - **Layered Window Attributes**: By setting the window to be layered, I achieved a transparent background effect, allowing for a more immersive snowfall experience without traditional window borders.

  - **Snowflake Generation**: The simulation generates 200 snowflakes with random initial positions and sizes. Each snowflake is represented as a dictionary containing its coordinates and size, allowing for easy manipulation.

  - **Animation Loop**: The main loop of the program handles events (such as quitting the application), updates the position of each snowflake, and redraws them on the screen. This creates a smooth animation effect as the snowflakes fall from the top to the bottom.

  - **Random Movement**: Each snowflake moves downwards at a random speed, giving a natural and varied appearance to the snowfall. When a snowflake reaches the bottom of the screen, it reappears at a random position at the top.

  - **Frame Rate Control**: The simulation runs at 30 frames per second, ensuring that the animation is fluid while maintaining performance.

  This project was an enjoyable exercise in using Pygame for graphical simulations. It deepened my understanding of game loops, event handling, and graphical rendering in Python. Overall, creating this snowfall effect was not only fun but also reinforced my skills in programming with Pygame.
* Day 285: 🎄 Christmas Gift Manager in Python 🎁

  Today, I developed a Christmas Gift Manager using Python, emphasizing Object-Oriented Programming (OOP) principles and the Model-View-Controller (MVC) architecture. This project allows users to manage a list of Christmas gifts, including adding, removing, updating, searching, sorting, and categorizing gifts. Below are the key highlights:

  - **Encapsulation**: The `Gift` class encapsulates attributes such as `name`, `description`, and `category`. By controlling access to these attributes through methods, I ensure that the integrity of gift data is maintained.

  - **Inheritance**: While this project does not heavily utilize inheritance, it lays the groundwork for future extensions where subclasses could be created for different types of gifts (e.g., toys, books) that may have additional attributes or methods.

  - **Abstraction**: The project uses abstraction to provide a clear interface for interacting with gifts through the `GiftModel`, which handles all data operations. Users interact with a simplified interface without needing to understand the underlying data management.

  - **Persistent Storage**: The application implements persistent storage using JSON to save and load gift data. This allows users to retain their gift list even after closing the application, enhancing user experience.

  - **Search Functionality**: Users can search for gifts by name or description. This feature improves usability by allowing quick access to specific gifts in a potentially large list.

  - **Gift Categories**: Gifts can be categorized (e.g., toys, books, electronics), helping users organize their gifts better. This added structure makes it easier to manage different types of gifts.

  - **Sorting Options**: The application allows users to sort their gift list by name, category, or date added. This feature enhances the user experience by providing flexibility in how gifts are displayed.

  - **Menu Options**: A user-friendly menu-driven interface enables interaction with the system. Users can view all gifts, add new ones, remove existing gifts, update details, search for specific gifts, and sort their list. This intuitive design makes the program accessible to all users.

  This project was an excellent opportunity to apply OOP principles and MVC architecture in creating a practical application. I refined my understanding of how encapsulation and abstraction contribute to building clean and maintainable code while enhancing user functionality through thoughtful design choices.
* Day 286: Technical Test "levelOrder" and "zigzagLevelOrder" [LeetCode](https://leetcode.com/problems/)

* Day 286: Technical Test "levelOrder" and "zigzagLevelOrder" [LeetCode](https://leetcode.com/problems/)

  - **levelOrder**: Implemented a solution for the "Binary Tree Level Order Traversal" problem, which requires returning the values of nodes in a binary tree level by level from left to right. The approach uses a breadth-first search (BFS) strategy with a queue to traverse each level of the tree. For each level, we collect node values and store them in a list. The time complexity of this solution is \(O(n)\), where \(n\) is the number of nodes in the tree.
    [Problem Description: levelOrder](https://leetcode.com/problems/binary-tree-level-order-traversal/description/)

  - **zigzagLevelOrder**: Developed a solution for the "Binary Tree Zigzag Level Order Traversal" problem, which returns the values of nodes in a binary tree in a zigzag pattern. This means that for each level, the traversal alternates between left-to-right and right-to-left. The implementation also uses BFS with a queue, but it toggles the order of insertion into the result list based on the current level's direction. The time complexity for this solution is also \(O(n)\), where \(n\) is the number of nodes in the tree.
    [Problem Description: zigzagLevelOrder](https://leetcode.com/problems/binary-tree-zigzag-level-order-traversal/description/)
Here’s a `README.md` for your math visualization project, formatted to match the style of your previous entry:
* Day 287: 📊 Simple Math Visualizations with Python 📈

  Today, I developed a project focused on visualizing basic mathematical concepts using Python and Matplotlib. The project includes functions to plot linear equations, quadratic functions, and sine waves. Below are the key highlights:

  - **Linear Functions**: The project features a function that plots linear equations of the form $$ y = mx + b $$. Users can specify the slope and intercept to visualize how these parameters affect the line's position and angle.

  - **Quadratic Functions**: A dedicated function allows for plotting quadratic equations of the form $$ y = ax^2 + bx + c $$. This demonstrates how changes in coefficients influence the shape and position of the parabola.

  - **Sine Waves**: The project also includes a function that generates and plots a sine wave, showcasing periodic functions. This helps illustrate concepts like amplitude and frequency in a visually engaging way.

  - **User-Friendly Interface**: The main function orchestrates the plotting of different mathematical functions, providing an easy-to-follow structure. Each plot is clearly labeled with titles and axes descriptions for better understanding.

  - **Matplotlib Integration**: By leveraging Matplotlib, the project provides high-quality visual representations of mathematical concepts. The use of grids, legends, and axis lines enhances readability and comprehension of the graphs.

  - **Extensibility**: The code structure allows for easy modifications and extensions. Users can add new functions to plot other mathematical concepts or customize existing ones to explore different parameters.

  This project served as an excellent exercise in applying Python programming skills while reinforcing fundamental mathematical principles. It was both enjoyable and educational to visualize these concepts through interactive plots, making math more accessible and engaging.
* Day 288: 🎄 Recursive Advent Calendar in Python 🎁

  Today, I developed a **Recursive Advent Calendar** using Python, which allows users to navigate through each day of December to discover surprises and activities. The project showcases the power of recursion and provides an engaging way to celebrate the holiday season. Below are the key highlights:

  - **Recursion**: The calendar uses a recursive function to navigate between days. Users can go forward to the next day, backtrack to previous days, or exit the calendar. This demonstrates how recursion can simplify navigation in structured data.

  - **Data Structure**: The calendar is implemented using a dictionary where each key represents a day of December and each value contains a surprise or activity. This allows for easy retrieval and management of content associated with each day.

  - **User Interaction**: A simple text-based interface prompts users for their choices, enhancing engagement. Users can choose to explore the next day, return to a previous day, or exit the program. This interactive element makes the experience enjoyable and user-friendly.

  - **Surprises and Activities**: Each day features unique content, such as quotes about Christmas, mini-games, recipes, and fun facts. This variety keeps users excited about what they will discover each day.

  - **Exit Functionality**: The program includes a clear exit option that thanks users for participating in the Advent Calendar experience. This ensures a smooth and friendly end to the interaction.

  - **Extensibility**: The structure of the project allows for easy expansion. New days and activities can be added without major changes to the existing codebase, making it adaptable for future enhancements.

  This project was a delightful exercise in applying programming concepts like recursion and data structures while creating a festive and interactive experience. It allowed me to explore how to engage users with simple yet effective programming techniques while celebrating the spirit of Christmas.
* Day 289:🏋️ Fitness Tracker in Python 📊

  Today, I developed a Fitness Tracker application using Python and the Flet library. The application allows users to plan and track their workout routines effectively. It provides functionalities to add exercises, log daily progress, and visualize statistics over time. Below are the key highlights:

  - **Exercise Management**: Users can add exercises along with their corresponding weight and repetitions. Each exercise is represented as an object, allowing for organized data handling.

  - **Data Logging**: The application enables users to log their daily workout progress by recording weight lifted and repetitions performed for each exercise. This helps users track their improvements over time.

  - **Statistics Calculation**: The app provides a feature to calculate total weights lifted and total repetitions for each exercise. This allows users to see their overall performance at a glance.

  - **User Interface**: The app features a user-friendly interface built using Flet, which allows for easy interaction. Users can input their exercises, view added exercises, and access statistics through simple button clicks.

  - **Error Handling**: Input validation is implemented to ensure that users enter valid data (e.g., numeric values for weight and repetitions). This enhances user experience by preventing incorrect entries.

  - **Extensibility**: The design of the application allows for future enhancements, such as adding graphs to visualize progress over time or integrating data persistence to save user data across sessions.

  This project was a valuable exercise in applying object-oriented programming principles while creating a practical tool for fitness enthusiasts. I gained insights into how to structure applications effectively using classes and methods, ensuring that the code remains clean and maintainable. Additionally, working with the Flet library provided me with experience in building interactive user interfaces in Python.
* Day 290: 🎄 Holiday Expense Tracker in Python 💰

  Today, I developed a Holiday Expense Tracker using Python, focusing on user-friendly expense management during the holiday season. The project allows users to input their holiday expenses and provides functionalities to calculate totals, averages, and the highest expense. Below are the key highlights:

  - **Expense Management**: The program allows users to add, edit, and delete expenses. Each expense includes an amount and a description, making it easy to track holiday spending.

  - **Calculations**: Users can calculate the total expenses, average expense per entry, and identify the highest expense recorded. This provides valuable insights into spending habits during the holidays.

  - **Data Persistence**: The tracker can save expenses to a CSV file and load them back into the program. This ensures that users can maintain their expense records across sessions without losing data.

  - **User Interaction**: A simple command-line interface guides users through various options, such as adding or removing expenses and viewing summaries. This makes the application intuitive and easy to navigate.

  - **Modular Design**: The program is structured around a `HolidayExpenseTracker` class that encapsulates all functionalities related to expense tracking. This modular approach enhances maintainability and allows for future feature expansions.

  - **CSV Handling**: The use of Python's built-in `csv` module allows for seamless reading from and writing to CSV files, ensuring compatibility with common data formats.

  This project was an excellent opportunity to practice Python programming skills while creating a practical tool for managing holiday expenses. It reinforced my understanding of object-oriented principles and provided insights into effective user interface design through command-line interactions. I look forward to expanding this project with additional features in the future!
* Day 291: 🎉 Countdown Timer to New Year in Python 🎆

  Today, I created a Countdown Timer that counts down to midnight on December 31st using Python and Tkinter. This project features a graphical user interface (GUI) and includes celebratory sounds and festive visuals. Here are the key highlights:

  - **Graphical Interface**: The application uses Tkinter to create an engaging user interface that displays the countdown in a visually appealing way. The background is set to dark, enhancing readability and adding to the festive atmosphere.

  - **Dynamic Countdown**: The timer calculates the remaining time until the New Year and updates every second. It formats the time into hours, minutes, and seconds, allowing users to see exactly how much time is left.

  - **Celebration Sound**: When the countdown reaches zero, a celebratory sound plays, adding excitement to the moment. This feature enhances user experience by providing an auditory cue for the New Year celebration.

  - **Customizable Aesthetics**: The timer's font has been changed to a more festive style (Comic Sans MS), and the text color is set to gold. This makes the countdown visually striking and suitable for a New Year's celebration.

  - **User-Friendly Design**: The application is straightforward to use, making it accessible for anyone wanting to countdown to the New Year. It serves as both a practical tool and a fun way to celebrate.

  This project was a fantastic opportunity to apply my knowledge of Python and GUI programming while creating something fun and interactive. It allowed me to explore how visual design can enhance user experience and how sound can be integrated into applications for added engagement. I look forward to further enhancing this project with more features in the future!
* Day 292: 🏦 Family Budget Planner Application in Python 💰

  Today, I developed a **Family Budget Planner** application using Python, focusing on creating a user-friendly interface with **Tkinter** and implementing data management features. This project is designed to help families track their expenses and manage their budget effectively. Below are the key highlights:

  - **User Interface**: The application features a clean and intuitive GUI built with Tkinter, allowing users to input various expense categories such as food, gifts, and entertainment. The layout is designed for ease of use, with clearly labeled input fields and buttons.

  - **Expense Management**: Users can add expenses for different categories, view their total expenses, and check against their monthly budget. The application alerts users if they exceed their budget, promoting better financial awareness.

  - **Data Storage**: Expenses are stored in a list, which allows for easy retrieval and manipulation. Users can view their expense history in a dedicated window, providing insights into their spending habits.

  - **CSV Export/Import**: The application includes functionality to export expenses to a CSV file for record-keeping and analysis. Additionally, it supports importing expenses from an existing CSV or Excel file, making it convenient for users to manage their data.

  - **Data Visualization**: To enhance understanding of spending patterns, the application utilizes Matplotlib to plot a pie chart representing the distribution of expenses across different categories. This visual representation aids users in identifying areas where they can cut back.

  - **Error Handling**: Robust error handling is implemented throughout the application to ensure that users receive appropriate feedback when inputs are invalid or when errors occur during data import/export processes.

  This project not only reinforced my skills in Python programming but also provided practical experience in developing applications that address real-world needs. I gained valuable insights into GUI design, data management, and user interaction, all while creating a tool that can assist families in achieving their financial goals.
* Day 293: Technical Test "maxDepth" and "BuildTree" [LeetCode](https://leetcode.com/problems/)

  - **maxDepth**: Implemented a solution for the "Maximum Depth of Binary Tree" problem, which requires finding the maximum depth of a binary tree. The maximum depth is defined as the number of nodes along the longest path from the root node down to the farthest leaf node. The solution employs a recursive approach, where we calculate the depth of the left and right subtrees and return the greater value plus one for the current node. The time complexity is $O(n)$, where $n$ is the number of nodes in the tree, and the space complexity is $O(h)$, where $h$ is the height of the tree.
    [Problem Description: maxDepth](https://leetcode.com/problems/maximum-depth-of-binary-tree/)

  - **BuildTree**: Developed a solution for the "Construct Binary Tree from Preorder and Inorder Traversal" problem. This problem involves reconstructing a binary tree given two integer arrays representing its preorder and inorder traversals. The algorithm uses recursion to identify the root from the preorder array and partitions the inorder array to build left and right subtrees accordingly. The time complexity is $O(n)$, as each node is processed once, and space complexity is also $O(n)$ due to storage for recursive calls and resulting tree nodes.
    [Problem Description: BuildTree](https://leetcode.com/problems/construct-binary-tree-from-preorder-and-inorder-traversal/description/)
* Day 294: 🌌 Zodiac Sign Calculator in Python ♈️🐉

  Today, I developed a Zodiac Sign Calculator using Python, which determines a person's zodiac sign based on their birth date and provides information for multiple zodiac systems, including Western and Chinese astrology. The project emphasizes recursion and modular design, making it both informative and engaging. Here are the key highlights:

  - **Zodiac Sign Calculation**: The program features a recursive function that determines the Western zodiac sign based on the day and month of birth. It uses predefined date ranges to classify signs accurately.

  - **Chinese Zodiac Determination**: A separate function calculates the Chinese zodiac sign based on the birth year. This function utilizes a simple modulo operation to map years to their corresponding zodiac animals in a 12-year cycle.

  - **User-Friendly Input**: The program prompts users to input their birth date in a clear format (DD-MM-YYYY). This ensures that users can easily interact with the application without confusion.

  - **Modular Design**: The code is structured into distinct functions for calculating zodiac signs, enhancing readability and maintainability. Each function has a specific purpose, making it easy to understand and modify if necessary.

  - **Detailed Output**: After processing the input, the program outputs both the Western and Chinese zodiac signs, providing users with a comprehensive understanding of their astrological profiles.

  - **Commented Code**: The entire codebase is well-commented, explaining the purpose of each function and the logic behind key calculations. This makes it an excellent resource for learning Python programming and understanding how to implement similar projects.

  This project was an enjoyable exploration of astrology through programming. It allowed me to practice my skills in Python while creating a tool that can be both fun and informative for users interested in their zodiac signs. I gained valuable experience in handling user input, implementing recursion, and structuring code effectively.
* Day 295: 📦 Mail/Package Service Application in Python 📬

  Today, I developed a Mail/Package Service application using Python, implementing the Model-View-Controller (MVC) architecture. The project allows users to manage packages, including adding, modifying, removing, searching, filtering, sorting, and saving/loading package data in both JSON and CSV formats. Below are the key highlights:

  - **MVC Architecture**: The application is structured using the MVC pattern, separating the logic into three main components:
    - **Model**: Manages the data and business logic related to packages.
    - **View**: Handles user interaction and displays information.
    - **Controller**: Acts as an intermediary between the Model and View, managing user input and updating the Model.

  - **Package Management**: Users can perform various operations on packages:
    - **Add Package**: Allows users to add new packages with details like ID, description, and weight.
    - **Remove Package**: Users can remove existing packages by specifying their ID.
    - **Modify Package**: Users can update details of existing packages.

  - **Search and Filter**: The application allows users to search for packages by ID or description and filter packages based on a specified weight limit.

  - **Sorting Functionality**: Users can sort packages by weight, making it easier to manage and review package information.

  - **Data Persistence**: The application supports saving and loading package data in both JSON and CSV formats:
    - **Save Packages**: Users can save all current packages to a file in their preferred format.
    - **Load Packages**: Users can load package data from a previously saved file.

  - **User-Friendly Interface**: A menu-driven interface guides users through various options, ensuring an intuitive experience while interacting with the application.

  This project was an excellent opportunity to apply my knowledge of Python programming and software design principles. It allowed me to explore data management techniques while creating a practical tool for managing mail and package services. I gained valuable insights into how to structure applications effectively using MVC architecture and how to implement file handling for data persistence.
* Day 296: 💰 Optimal Coin Change in Python 💵

  Today, I worked on an Optimal Coin Change project using Python, focusing on recursion and dynamic programming techniques. The project aims to find all possible combinations of coins that can make up a given amount, as well as the optimal combination that uses the least number of coins. Below are the key highlights:

  - **Recursion**: The project utilizes a recursive approach to explore all possible combinations of coin denominations that sum up to the target amount. This method allows for a thorough search of potential solutions.

  - **Dynamic Programming**: To find the optimal combination with the minimum number of coins, I implemented a dynamic programming solution. This approach efficiently calculates the least number of coins required for each amount up to the target, storing results in a `dp` array.

  - **Combination Generation**: The `combinations` function generates all valid combinations of coins recursively. When the remaining amount reaches zero, it adds the current combination to the results, ensuring comprehensive coverage of possibilities.

  - **Optimal Combination**: The `best_combination` function determines the combination that uses the fewest coins. It updates a list of coins used for each amount based on previously computed results, ensuring that we only consider optimal paths.

  - **User-Friendly Examples**: The code includes examples for both US and Colombian coin denominations, demonstrating how to use the functions effectively. This makes it easy to adapt the code for different currencies and amounts.

  - **Results Presentation**: The final output displays both all possible combinations and the optimal combination for a given amount. This dual functionality provides valuable insights into how change can be made efficiently.

  This project was an excellent opportunity to deepen my understanding of recursion and dynamic programming while solving a practical problem in finance. I gained valuable experience in structuring code for clarity and efficiency, making it easier to extend or modify in future iterations.
* Day 297: 🥭 Named Entity Recognition (NER) Model in Python 🧠

  Today, I focused on developing a Named Entity Recognition (NER) model using Python and the spaCy library. The project is designed to identify and classify entities such as quantities and products from text related to fruit pricing inquiries. Below are the key highlights:

  - **Training Data**: The model is trained on a dataset of questions about fruit prices. Each entry includes the text and annotated entities, such as quantities (e.g., "10 bananas") and products (e.g., "bananas"). This structured training data is crucial for teaching the model to recognize patterns.

  - **spaCy Integration**: I utilized the spaCy library, a powerful tool for natural language processing, to load a pre-trained English model. This allows for efficient training and entity recognition capabilities.

  - **Custom NER Component**: The project involves adding a custom Named Entity Recognition component to the spaCy pipeline. If the NER component does not already exist, it is created; otherwise, the existing one is updated with new entity labels.

  - **Training Process**: The model undergoes multiple epochs of training, where the training data is shuffled and processed in batches. This iterative process helps optimize the model's ability to recognize entities accurately.

  - **Loss Tracking**: During training, I implemented loss tracking to monitor the performance of the model across epochs. This provides insights into how well the model is learning and adjusting its parameters.

  - **Model Evaluation**: After training, I tested the model with sample texts to evaluate its performance in recognizing entities. The results include identified entities along with their respective labels, showcasing the effectiveness of the trained model.

  - **Model Persistence**: Finally, I saved the trained NER model to disk for future use. This allows for easy loading and testing without needing to retrain the model each time.

  This project was an excellent opportunity to deepen my understanding of Named Entity Recognition and how machine learning can be applied to natural language processing tasks. I gained valuable experience in preparing training data, configuring machine learning models with spaCy, and evaluating their performance in real-world scenarios.
* Day 298: 🪙 Coin Flip Simulation in Python 🎲

  Today, I developed a Coin Flip Simulation project using Python, which focuses on recursion to generate all possible sequences of results when flipping a coin \( n \) times. The project not only simulates the coin flips but also counts the combinations where there are more heads than tails and vice versa. Here are the key highlights:

  - **Recursion**: The core of the simulation relies on a recursive function that generates all possible outcomes of coin flips. By reducing the number of flips with each recursive call, the function builds sequences of 'H' (heads) and 'T' (tails) until all flips are accounted for.

  - **Combination Counting**: After generating all sequences, the program counts how many of those combinations have more heads than tails and how many have more tails than heads. This feature adds an analytical aspect to the simulation, providing insights into the results.

  - **Visualization**: To enhance user experience, the project includes a visualization component that displays the results in a bar chart. Using `matplotlib`, it presents a clear comparison between the counts of heads and tails for each sequence generated.

  - **User Interaction**: The program prompts users to input the number of coin flips they wish to simulate. This interactive element makes it easy to explore different scenarios and understand the distribution of outcomes.

  - **Output Clarity**: After executing the simulation, users receive a summary that includes the total number of sequences generated and counts of combinations with more heads or tails. This summary provides a quick overview of the results.

  This project was an engaging exercise in recursion and data visualization, allowing me to deepen my understanding of how to generate combinations programmatically. It also served as a practical application for using libraries like `matplotlib` for visual representation of data. Overall, it was a fun way to explore probability concepts through coding!
* Day 299: 💰 Expense Splitter in Python 📊

  Today, I developed an **Expense Splitter** application using Python and the Flet framework. This project is ideal for groups of friends or roommates who share expenses, allowing them to manage and track their shared costs effectively. Below are the key highlights:

  - **Expense Registration**: Users can easily register shared expenses by providing a description, amount, and the participants involved. This feature simplifies the process of tracking who owes what.

  - **Owed Calculation**: The application calculates how much each participant owes based on the expenses registered. This ensures transparency and helps avoid misunderstandings among friends or roommates.

  - **Transaction History**: Users can view a history of all transactions entered into the system. This feature allows users to keep track of past expenses and provides a clear overview of shared financial responsibilities.

  - **Report Generation**: The application includes functionality to export expense reports in both PDF and Excel formats. This makes it easy to share financial summaries with others or keep personal records.

  - **User-Friendly Interface**: Built with Flet, the application features a clean and intuitive user interface that allows users to interact with the system effortlessly. Users can add expenses, view summaries, and export reports with just a few clicks.

  - **Modular Design**: The code is organized into separate modules for managing expenses and generating reports. This modularity enhances maintainability and makes it easier to extend the application in the future.

  This project was an excellent opportunity to apply my knowledge of Python programming and UI development using Flet. I gained valuable experience in managing shared data, implementing calculations, and creating user-friendly interfaces. Overall, it was a rewarding exercise in building a practical tool for everyday financial management.
* Day 300: Technical Test "isBalanced" and "minDepth" [LeetCode](https://leetcode.com/problems/)

  - **isBalanced**: Implemented a solution for the "Balanced Binary Tree" problem, which checks whether a given binary tree is height-balanced. A binary tree is height-balanced if the depth of the two subtrees of any node never differs by more than one. The approach uses a recursive function to calculate the height of each subtree while checking for balance at each node. The time complexity is O(n), where n is the number of nodes in the tree.
    [Problem Description: isBalanced](https://leetcode.com/problems/balanced-binary-tree/description/)

  - **minDepth**: Developed a solution for the "Minimum Depth of Binary Tree" problem, which finds the minimum depth from the root node down to the nearest leaf node. A leaf node is defined as a node with no children. The solution employs a recursive method that calculates the depth by traversing the tree and considering cases where one or both child nodes may be absent. The time complexity is O(n), where n is the number of nodes in the tree.
    [Problem Description: minDepth](https://leetcode.com/problems/minimum-depth-of-binary-tree/)
* Day 301: 🍕 Pizza Drawing with Python Turtle 🎨

  Today, I created a fun project using Python's Turtle graphics library to draw a pizza. This project focuses on basic graphics programming concepts and random placement of toppings. Below are the key highlights:

  - **Turtle Graphics**: Utilized the Turtle module to create a visual representation of a pizza. The Turtle library makes it easy to draw shapes and designs using simple commands, providing an engaging way to learn programming.

  - **Drawing Shapes**: The pizza base is represented as a large circle filled with a golden color, simulating the crust. An inner red circle represents the sauce, showcasing how to use basic geometric shapes in graphics.

  - **Random Toppings**: Implemented random placement of toppings like pepperoni and mushrooms. Using the `random` module, I generated random coordinates within the pizza's area to ensure that toppings appear only on the pizza, demonstrating how randomness can enhance graphical projects.

  - **Color Customization**: Different colors were used for various components of the pizza (golden for crust, red for sauce, dark red for pepperoni, and gray for mushrooms). This aspect emphasizes how color can be applied in graphics to create visually appealing designs.

  - **Function Structure**: The drawing logic is encapsulated within a function (`draw_pizza`), promoting code reusability and organization. This structure allows for easy modifications and enhancements in the future.

  - **User Interaction**: Although this project does not include user input, it lays the groundwork for future enhancements where users could customize their pizza by choosing toppings or sizes.

  This project was an enjoyable way to explore graphics programming in Python while applying fundamental concepts in a creative manner. It provided a practical application of coding skills and sparked ideas for future projects involving more complex graphics and interactivity.
* Day 302: 🧑‍💻 Job Notification Script in Python 📬

  Today, I developed a Job Notification Script using Python that monitors job postings on the official Python website. The script checks for new job listings and sends desktop notifications whenever a new job is published. This project highlights my skills in web scraping, data handling, and user notifications. Below are the key highlights:

  - **Web Scraping**: The script utilizes the `requests` library to fetch the HTML content of the Python jobs page and `BeautifulSoup` to parse the HTML. This allows for easy extraction of job details such as title, company, location, posted date, and job types.

  - **CSV File Handling**: Job postings are saved into a CSV file (`python_jobs.csv`), which provides a structured format for storing job data. This allows for easy access and review of past job listings.

  - **Desktop Notifications**: Using the `plyer` library, the script sends desktop notifications for new job postings. This feature ensures that users are promptly informed about opportunities without needing to constantly check the website.

  - **Continuous Monitoring**: The script runs in an infinite loop, checking for new job postings every 60 seconds. This allows for real-time updates, making it a practical tool for job seekers.

  - **Data Management**: The script maintains a set of previously seen job titles to avoid duplicate notifications. This ensures that users receive alerts only for genuinely new postings.

  - **User-Friendly Interface**: While primarily a backend script, its functionality is designed to be straightforward and effective, providing value to users looking to stay updated on Python-related job opportunities.

  This project was an excellent exercise in combining web scraping with real-time notifications. It reinforced my understanding of how to interact with web data programmatically while also enhancing my skills in Python libraries such as `requests`, `BeautifulSoup`, and `plyer`. Overall, this script serves as a practical tool for anyone interested in Python jobs, making it easier to stay informed about new opportunities in the field.
* Day 303: 🪙 Coin Game with Minimax Algorithm in Python 🎮

  Today, I developed a Coin Game using Python, implementing the Minimax algorithm to create an AI opponent. The game allows two players to take turns removing coins from a pile, with the goal of taking the last coin to win. Here are the key highlights of the project:

  - **Game Mechanics**: Players can take between 1 to 3 coins per turn from a pile. The player who takes the last coin wins the game. This simple yet strategic gameplay encourages players to think ahead and plan their moves carefully.

  - **Minimax Algorithm**: The AI opponent uses the Minimax algorithm to determine its optimal move. This recursive strategy evaluates possible future game states and chooses the move that maximizes its chances of winning while minimizing the player's chances.

  - **Player Interaction**: The game features a user-friendly interface where players can input their choice of coins to take. Input validation ensures that players can only take a valid number of coins, enhancing the overall user experience.

  - **AI Decision Making**: The AI's decision-making process is transparent and logical, making it a challenging opponent for human players. The Minimax implementation allows the AI to anticipate player moves and respond effectively.

  - **Game Loop**: The main game loop alternates between player and AI turns until all coins are taken. This structure keeps the game engaging and dynamic, providing a clear flow from one turn to the next.

  - **Code Structure**: The project is organized into a single class, `CoinGame`, which encapsulates all game logic and methods. This design promotes clarity and maintainability, making it easy to extend or modify in the future.

  This project was an exciting challenge that allowed me to deepen my understanding of game theory and algorithmic thinking. Implementing the Minimax algorithm not only improved my coding skills but also enhanced my ability to design intelligent systems that can compete against human players. Overall, it was a rewarding experience that combined programming with strategic gameplay.
* Day 304: 🐦 Bird Study Service in Python 📚

  Today, I developed a Bird Study Service using Python, implementing the Model-View-Controller (MVC) architecture. This project focuses on managing bird data and provides a user-friendly interface for various operations related to bird studies. Below are the key highlights:

  - **MVC Architecture**: The project is structured using the MVC pattern, separating concerns into three components:
    - **Model**: Contains the data structure and logic for managing birds, including methods for adding, removing, searching, and updating bird information.
    - **View**: Handles user interaction and displays information through a simple menu-driven interface.
    - **Controller**: Manages the flow of data between the model and view, responding to user inputs and updating the display accordingly.

  - **Bird Management**: Users can perform various operations on birds:
    - **Add New Birds**: Users can add new birds to the study.
    - **Remove Birds**: The service allows users to remove birds from their records.
    - **Search for Birds**: Users can search for specific birds by name.
    - **Update Bird Information**: The application supports updating existing bird names, ensuring accurate records.

  - **Data Handling**: The model maintains a list of birds and provides methods for counting the total number of birds. This allows users to easily track their studies and manage their data effectively.

  - **User-Friendly Interface**: The view presents an intuitive menu that guides users through available options, making it easy to navigate the service. Users can view all birds, add or remove entries, search for specific birds, update names, and count total birds with just a few keystrokes.

  - **Extensibility**: The design allows for future enhancements such as integrating file storage for persistent data management, adding more detailed attributes for each bird (like species or habitat), or even connecting to an external database.

  This project was an excellent opportunity to apply MVC principles in Python while creating a practical tool for bird enthusiasts and researchers. It deepened my understanding of how to structure applications for maintainability and scalability while providing a solid foundation for future development in data management systems.
* Day 305: 🏀 Shooting Efficiency Tracker in Python 📊

  Today, I developed a Shooting Efficiency Tracker using Python, focusing on data management, visualization, and statistical analysis. The project allows users to track and visualize shooting efficiencies for different types of basketball shots, such as free throws, two-point shots, and three-point shots. Below are the key highlights:

  - **Data Persistence**: The application supports saving and loading shooting data using JSON files. Users can maintain their data across sessions, ensuring that their shooting statistics are always available.

  - **User-Friendly Interface**: A menu-driven interface allows users to view shooting efficiencies, add new data, modify existing entries, visualize statistics, and import data from external files (CSV or JSON). This design makes the application intuitive and accessible.

  - **Advanced Data Visualization**: Users can choose from multiple graph types (bar plots, line charts, pie charts) to visualize shooting efficiencies. This feature enhances data insights and helps users understand their performance trends over time.

  - **Statistical Analysis**: The application calculates important performance metrics such as average shooting efficiency, best/worst performances, and provides a comparative analysis of shooting types. This functionality aids users in identifying areas for improvement.

  - **Customization Options**: Users can customize shot types and their labels according to their preferences. This flexibility allows for a more personalized experience when tracking shooting efficiencies.

  - **Interactive Visualizations**: The project utilizes libraries like Matplotlib and Seaborn for static visualizations. Future enhancements could include interactive visualizations using Plotly or Bokeh for an even richer user experience.

  This project was a valuable exercise in applying data management and visualization techniques in Python. It allowed me to deepen my understanding of how to create user-friendly applications that provide meaningful insights into performance metrics. Overall, it was an enjoyable experience building a practical tool for basketball enthusiasts to track their shooting efficiency!
* Day 306: Technical Test "hasPathSum" and "pathSum" [LeetCode](https://leetcode.com/problems/)

  Today, I focused on solving two related problems from LeetCode: `hasPathSum` and `pathSum`. These problems involve traversing a binary tree to find specific paths that meet given criteria. Below are the key highlights of my work:

  - **Problem Overview**:
    - **hasPathSum**: This function checks if there exists a root-to-leaf path in a binary tree such that the sum of the node values along the path equals a specified `targetSum`.
    - **pathSum**: This function returns all root-to-leaf paths where the sum of the node values in each path equals `targetSum`. Each path is represented as a list of node values.

  - **Implementation Details**:
    - I created a `TreeNode` class to represent each node in the binary tree, encapsulating its value and pointers to its left and right children.
    
    - The `Solution` class contains both methods:
      - **hasPathSum** utilizes depth-first search (DFS) to traverse the tree while maintaining the current path and sum. It checks for leaf nodes and compares the accumulated sum with `targetSum`.
      
      - **pathSum** also employs DFS but collects all valid paths that match the target sum. It uses backtracking to explore different paths while maintaining the current path state.

  This exercise was an excellent opportunity to deepen my understanding of binary tree traversal techniques and recursion. It reinforced my skills in implementing algorithms that solve complex problems using clear and efficient code structures. The challenges presented by these problems were rewarding to tackle, enhancing my problem-solving capabilities in data structures and algorithms.
* Day 307: 🎓 Grade Converter in Python 📊

  Today, I developed a Grade Converter program using Python, designed to convert numerical grades into letter grades based on the Colombian grading system. The project emphasizes user customization of grade ranges and includes validation to handle invalid inputs. Here are the key highlights:

  - **Customizable Grade Ranges**: Users can define their own letter grades and corresponding numerical ranges. This feature allows for flexibility in grading systems, accommodating various educational institutions or personal preferences.

  - **Input Validation**: The program includes robust input validation to ensure that only valid numeric grades are accepted. Users are prompted to re-enter values if they provide invalid data, enhancing the overall user experience.

  - **Grade Conversion Logic**: The core functionality of the program involves converting numeric grades (0-100) into letter grades (A, B, C, D, F) based on the specified ranges. This logic is encapsulated in a dedicated function, making it easy to modify or extend in the future.

  - **User-Friendly Interface**: The program features a simple command-line interface that guides users through entering custom ranges and numeric grades. Clear prompts and feedback ensure that users understand what is required at each step.

  - **Error Handling**: The program gracefully handles errors such as out-of-range inputs or non-numeric entries. This ensures that users can interact with the application without encountering crashes or unexpected behavior.

  - **Extensibility**: The design of the program allows for easy enhancements, such as adding more features or integrating it into larger educational software systems. The modular structure promotes maintainability and scalability.

  This project was an excellent opportunity to apply programming concepts in a practical context while focusing on user interaction and data validation. I enjoyed creating a tool that can help students and educators easily convert grades, making it both functional and beneficial for academic settings.
* Day 308: [Data Colombia: Traffic Accidents](https://www.datos.gov.co/dataset/MUERTES-ACCIDENTES-DE-TRANSITO-2012-2022-MARZO/wwir-6riq/about_data)

  Today, I focused on analyzing the Traffic Accidents dataset from Colombia using Python. The primary objective was to perform exploratory data analysis (EDA) and model the data to classify types of accidents based on various features. Below are the key highlights of the project:

  - **Data Loading and Overview**: The dataset was loaded using Pandas from an Excel file, and an initial overview was conducted to understand its structure and contents. The dataset includes attributes such as date of incident, day of the week, time of incident, location, type of road, type of accident, gender, age of victims, and vehicle details.

  - **Data Cleaning**: I addressed missing values by standardizing text values to lowercase and replacing non-standard missing values with NaN. Columns with more than 50% missing values were dropped, and rows with critical missing values were also removed. Categorical columns were filled with the mode to handle remaining missing values.

  - **Exploratory Data Analysis (EDA)**:
    - **Categorical Features**: Count plots were generated for categorical variables like day, location, road type, accident type, gender, victim role, and victim vehicle to visualize their distributions.
    - **Numerical Features**: Kernel Density Estimation (KDE) plots were created for numerical features such as age and time to analyze their distributions. A heatmap illustrated correlations between numerical variables.

  - **Encoding Categorical Variables**: Categorical variables were encoded using Label Encoding to prepare the dataset for modeling.

  - **Modeling**:
    - **Train-Test Split**: The dataset was split into training and testing sets.
    - **Model Selection**: A Random Forest Classifier was implemented to classify the type of accident based on various features.
    - **Model Evaluation**: The model's performance was evaluated using a confusion matrix and classification report to assess metrics such as precision, recall, and F1-score.

  This project provided a comprehensive understanding of data analysis and modeling techniques in Python while exploring the Traffic Accidents dataset in depth. It highlighted the importance of data visualization and model evaluation in deriving meaningful insights from data.
* Day 309: 🍦 Ice Cream Combination Generator in Python 🍨

  Today, I developed an **Ice Cream Combination Generator** using Python, showcasing the power of recursion to generate all possible combinations of ice cream flavors and toppings. This project emphasizes the creativity and fun of customizing ice cream treats. Below are the key highlights:

  - **Recursion**: The core of the project is a recursive function, `generate_combinations`, which explores all possible combinations of toppings for each ice cream flavor. This function efficiently handles the inclusion and exclusion of each topping, ensuring that every combination is considered.

  - **Modular Design**: The code is structured into functions, with a clear separation between the combination generation logic and the user interface. This modularity enhances readability and maintainability, making it easier to extend or modify the program in the future.

  - **User Interaction**: The `main` function provides a welcoming interface for users, displaying available flavors and toppings before generating combinations. This user-friendly approach ensures that anyone can easily explore different ice cream options.

  - **Output Formatting**: Each combination is presented in a clear and human-readable format, allowing users to see exactly how their customized ice cream would look. The program also handles cases where no toppings are selected, providing a complete experience.

  - **Flavor Variety**: The project includes a diverse list of ice cream flavors (Vanilla, Chocolate, Strawberry, Mint) and toppings (Sprinkles, Cherries, Chocolate Syrup, Nuts), making it fun for users to experiment with different combinations.

  - **Exploration of Possibilities**: By generating all possible combinations, users can discover unique pairings they might not have considered otherwise. This aspect adds an element of surprise and delight to the ice cream selection process.

  This project was a delightful exercise in applying recursion and modular programming principles while creating an engaging tool for ice cream enthusiasts. It allowed me to explore how to generate combinations dynamically and present them in an appealing way, enhancing both my coding skills and my appreciation for creative programming solutions. Enjoy exploring all the delicious possibilities!
* Day 310: 🍳 NER for Recipe Extraction in Python 📜

  Today, I developed a Named Entity Recognition (NER) model using Python to extract ingredients, quantities, and methods of preparation from cooking recipes. This project leverages the powerful spaCy library for natural language processing and focuses on training a custom NER model tailored specifically for culinary texts. Here are the key highlights:

  - **NER Model**: The core of this project is a custom NER model built using spaCy. It identifies three main entity types:
    - **Ingredient**: Recognizes food items such as "flour" and "sugar".
    - **Quantity**: Captures measurements like "200g" and "1 cup".
    - **Method**: Identifies cooking methods such as "bake" and "fry".

  - **Training Data**: The model was trained on a small dataset of recipe instructions, where each instruction is paired with its corresponding entities. This data format allows the model to learn the context in which each entity type appears.

  - **Pipeline Configuration**: The spaCy pipeline was configured to include the NER component. Labels were added dynamically based on the training data, ensuring that all relevant entities are recognized during training.

  - **Training Process**: The model underwent training for 50 epochs, with data shuffled at each epoch to improve generalization. Losses were monitored throughout the training process to ensure effective learning.

  - **Model Evaluation**: After training, the model was tested with various recipe instructions to evaluate its performance. The output includes recognized entities along with their labels, demonstrating the model's ability to accurately identify components of recipes.

  - **User-Friendly Interface**: A simple testing loop was implemented to process sample recipe texts and display recognized entities. This makes it easy for users to interact with the model and see its outputs in real-time.

  This project was a fantastic opportunity to apply machine learning techniques in the context of natural language processing. It deepened my understanding of how NER works and provided hands-on experience with spaCy's capabilities. I am excited about the potential applications of this model in recipe management systems or culinary applications, where extracting structured information from unstructured text can enhance user experience and accessibility.
* Day 311: Technical Test "flatten" and "numDistinct" [LeetCode](https://leetcode.com/problems/)

  - **flatten**: Implemented a solution for the "Flatten Binary Tree to Linked List" problem, which transforms a binary tree into a linked list in-place. The linked list should follow the same order as a pre-order traversal of the binary tree. The approach utilizes a recursive method to rearrange the pointers of the tree nodes, ensuring that the left child pointers are set to null and the right child pointers point to the next node in the list. The time complexity is O(n), where n is the number of nodes in the tree.
    [Problem Description: flatten](https://leetcode.com/problems/flatten-binary-tree-to-linked-list/description/)

  - **numDistinct**: Developed a solution for the "Distinct Subsequences" problem, which counts the number of distinct subsequences of string `s` that equal string `t`. The solution employs dynamic programming to build a table that tracks the number of ways to form subsequences by iterating through both strings. The final result is found at the bottom-right cell of the table, representing all possible distinct subsequences. The time complexity is O(m * n), where m is the length of string `s` and n is the length of string `t`.
    [Problem Description: numDistinct](https://leetcode.com/problems/distinct-subsequences/description/)
* Day 312: 📊 Advanced Sales Dashboard with Flask and Plotly

  Today, I developed an **Advanced Sales Dashboard** using **Flask**, **Plotly**, and **Pandas**. The project focuses on building an interactive web application to analyze and visualize sales data. Below are the key highlights:

  - **Dynamic Dashboard**:  
    The dashboard provides interactive visualizations, including:  
    - A **bar chart** for sales by category, offering a clear breakdown of revenue by product types.  
    - A **line chart** for monthly sales trends, helping to identify seasonal patterns and growth trends.  

  - **Data Preprocessing**:  
    Implemented a robust data preprocessing pipeline that:  
    - Removes duplicates to ensure data integrity.  
    - Handles missing values by replacing them with appropriate defaults (e.g., mean for numerical values, "Unknown" for categories).  
    - Converts date columns to datetime format and extracts additional features like month and year for detailed time-based analysis.  

  - **Advanced Insights**:  
    The dashboard calculates and displays key metrics such as:  
    - **Total Sales**: Aggregated revenue over the dataset.  
    - **Average Sale**: Mean revenue per transaction.  
    - **Top Categories**: The top three categories generating the highest revenue.  
    - **Sales Growth**: Month-over-month growth percentage, providing a high-level performance indicator.  

  - **Dummy Data Generator**:  
    Created a script to generate **realistic dummy sales data**, ensuring the dashboard has a functional dataset for testing and demonstration purposes. Key features include:  
    - Randomized transactions across five categories (`Electronics`, `Clothing`, `Furniture`, `Groceries`, `Toys`) and corresponding products.  
    - Transaction amounts ranging between $10 and $2,000.  
    - Date ranges spanning from January 2024 to January 2025.  

  - **API for Insights**:  
    Added an API endpoint (`/insights`) to deliver sales insights in JSON format, facilitating easy integration with other systems or frontends.

  This project was a rewarding experience in combining **data analysis** and **web development**. I enhanced my skills in creating clean, maintainable Flask applications, integrating Plotly for interactive visualizations, and implementing advanced data preprocessing techniques. The modular structure ensures scalability, making it adaptable for future enhancements like predictive analytics or more granular visualizations.
* Day 313:🌍 Tourist Location NER (Named Entity Recognition) Project 🏛️

  Today, I worked on a Named Entity Recognition (NER) system for tourist locations using Python, with a focus on Object-Oriented Programming (OOP) principles such as inheritance, encapsulation, and abstraction. The project allows automatic identification of cities, monuments, and tourist activities from travel-related text. Below are the key highlights:

  - **Encapsulation**: The `NERModel` class encapsulates attributes like `train_data` and `nlp_model`, ensuring that machine learning model details are protected by making them private. Controlled access is provided through specialized methods.

  - **Inheritance**: The system uses inheritance for different NER components, derived from a base `BaseNERModel` abstract class. This allows reusability of common attributes while providing specialized functionality for each entity recognition subclass.

  - **Abstraction**: The `BaseNERModel` class contains an abstract method `train_model`, which is implemented by different NER model classes. This ensures that each type of entity recognition has a tailored training approach, maintaining a consistent interface.

  - **Entity Management**: The system can identify and classify entities such as cities, monuments, and tourist activities. The `NERTrainer` class captures details like entity labels, training epochs, and model configuration, making the system easy to extend with new features in the future.

  - **Machine Learning Training**: The system uses SpaCy's advanced NLP capabilities to train a custom NER model, with configurable parameters like training epochs, dropout rates, and entity labels. The final model's performance is clearly demonstrated through test cases.

  - **Interaction Interface**: A modular approach allows for easy testing and evaluation of the NER model, where users can input text and receive automatically detected entities. This makes the program user-friendly and practical for real-world natural language processing scenarios.

  This project was an excellent exercise in applying OOP principles to create a well-structured and maintainable machine learning system. I had the opportunity to refine my understanding of how abstraction, encapsulation, and inheritance work together to create clean and reusable code, all while building a practical Named Entity Recognition tool for tourist locations.
* Day 314: 📦 Box Management System in Python 🗃️

  Today, I worked on a Box Management System using Python, with a focus on Object-Oriented Programming (OOP) principles such as inheritance, encapsulation, and abstraction. The project allows users to manage box inventories, track box details, perform complex operations, and maintain a comprehensive inventory system. Below are the key highlights:

  - **Encapsulation**: The `Box` class encapsulates attributes like `id`, `name`, and `price`, ensuring that box information is protected by making them private. Controlled access is provided through specific methods in the `BoxInventory` class.

  - **Inheritance**: The system uses a flexible class design for different box types, allowing easy extension and specialization of box characteristics while maintaining a consistent base structure.

  - **Abstraction**: The `BoxInventory` class provides an abstract layer for managing box collections, offering methods like `add_box()`, `remove_box()`, and `find_box_by_id()` that simplify complex inventory operations.

  - **Inventory Management**: Users can add, remove, update, and search for boxes with comprehensive details including material, dimensions, weight, and price. This makes the system flexible and adaptable to various inventory tracking scenarios.

  - **Advanced Operations**: The system includes sophisticated features like calculating total inventory value, filtering boxes by material, sorting boxes by price, and generating detailed inventory reports.

  - **Menu Options**: A menu-driven interface allows for interaction with the system, where users can perform various inventory management tasks. This makes the program user-friendly and practical for real-world box tracking.

  This project was an excellent exercise in applying OOP principles to create a well-structured and maintainable system. I had the opportunity to refine my understanding of how abstraction, encapsulation, and inheritance work together to create clean and reusable code, all while building a practical box management tool.
* Day 315: 🎲 Coin Toss Sequences with Recursion

  Today, I worked on a Python project focused on generating and analyzing all possible coin toss sequences for a given number of tosses using recursion. The project explores the mathematical and combinatorial aspects of coin tosses, with an emphasis on understanding balanced and unbalanced sequences. Below are the key highlights:

  - **Recursive Sequence Generation**: 
    - A recursive function was implemented to generate all possible sequences of coin tosses (`H` for Heads and `T` for Tails).
    - This approach efficiently handles the combinatorial explosion of sequences as the number of tosses increases.

  - **Analysis of Unbalanced Sequences**:
    - A function was developed to count sequences with more `H` (Heads) or `T` (Tails), categorizing them as unbalanced.
    - This analysis provides insights into the distribution of sequences that deviate from perfect balance.

  - **Detailed Sequence Output**:
    - The project includes functionality to display all generated sequences in a user-friendly format, enabling easy inspection of individual outcomes.
    - The total number of sequences for a given number of tosses is calculated and printed.

  - **Key Functions**:
    - `generate_coin_toss_sequences(n)`: Generates all possible sequences for `n` coin tosses using recursion.
    - `count_unbalanced_sequences(sequences)`: Analyzes sequences to count cases with more Heads or Tails.

  - **Insights and Results**:
    - The recursive approach highlights the elegance of solving combinatorial problems programmatically.
    - Results demonstrate the balance and unbalance distribution trends, offering a deeper understanding of probabilistic outcomes.

  This project was an excellent opportunity to deepen my understanding of recursion and combinatorics in Python. It reinforced the importance of leveraging recursion for generating complex patterns while showcasing how analytical functions can extract meaningful insights from data.
* Day 316: 🩺 Diabetes Analysis and Prediction in Python 📊   [Diabetes Dataset on Kaggle](https://www.kaggle.com/datasets/akshaydattatraykhare/diabetes-dataset/data)  

  Today, I worked on analyzing the Diabetes dataset from Kaggle using Python. The main objective was to perform exploratory data analysis (EDA) and build predictive models to classify whether a person has diabetes based on various health metrics. Below are the key highlights of the project:

  - **Data Loading and Overview**: The dataset was loaded using Pandas to explore its structure and contents. It includes features such as pregnancies, glucose levels, blood pressure, skin thickness, insulin levels, BMI, diabetes pedigree function, and age, with the target variable being `Outcome` (1 = diabetic, 0 = non-diabetic).  

  - **Data Cleaning**:  
    - Addressed missing or zero values in critical features like glucose, blood pressure, and BMI.  
    - Outliers were identified and treated to improve data quality.  

  - **Exploratory Data Analysis (EDA)**:  
    - **Feature Distributions**: Histograms and KDE plots were used to visualize the distributions of numerical features.  
    - **Outcome Analysis**: Boxplots and violin plots helped examine how features like glucose and BMI vary between diabetic and non-diabetic groups.  
    - **Correlation Analysis**: A heatmap was generated to identify relationships between features, highlighting significant correlations with diabetes outcome.  

  - **Modeling**:  
    - **Train-Test Split**: The data was divided into training and testing sets for model evaluation.  
    - **Model Selection**: Various classification models were implemented, including Logistic Regression, Decision Tree Classifier, Random Forest Classifier, and Support Vector Machine (SVM).  
    - **Model Evaluation**: Each model's performance was assessed using accuracy, precision, recall, F1-score, and ROC-AUC metrics.  

  - **Hyperparameter Tuning**: GridSearchCV was used to optimize the Random Forest and SVM models, leading to improved performance.  

  - **Visualization**: Confusion matrices and ROC curves were plotted to better understand model performance and compare results.  

  This project provided valuable insights into the role of data preprocessing, feature engineering, and model evaluation in building robust classification systems. It also underscored the importance of leveraging domain-specific datasets for impactful data science solutions.  
* Day 317: Technical Test "generate" and "getRow" [LeetCode](https://leetcode.com/problems/)

  - **generate**: Implemented a solution for the "Pascal's Triangle" problem, where the task is to generate the first `numRows` of Pascal's triangle. The approach uses a dynamic programming method to construct each row by calculating elements based on the previous row. The solution efficiently builds the triangle by starting with the first row and iteratively adding subsequent rows, with each element computed by summing the two numbers directly above it. The time complexity is O(numRows²), and the space complexity matches the number of elements in the generated triangle.
    [Problem Description: generate](https://leetcode.com/problems/pascals-triangle/description/)

  - **getRow**: Solved the "Pascal's Triangle II" problem, which requires returning the specific row of Pascal's triangle for a given row index. The solution uses an optimized dynamic programming approach that generates the row in-place with a single pass. By leveraging the mathematical relationship between combinations, the algorithm calculates each element using the previous element and the row index. This method is more space-efficient than generating the entire triangle, with a time complexity of O(rowIndex) and space complexity of O(rowIndex).
    [Problem Description: getRow](https://leetcode.com/problems/pascals-triangle-ii/description/)
  
* Day 318: Basketball Warm-Up Routine Generator in Python

  Today, I worked on a Basketball Warm-Up Routine Generator using Python, with a focus on creating a flexible and customizable system for generating personalized warm-up routines for basketball players. The project leverages Object-Oriented Programming (OOP) principles to create a modular and extensible solution for sports training preparation.

  - **Position-Based Routines**: The system generates customized warm-up routines based on specific basketball player positions, ensuring targeted and effective preparation.

  - **Exercise Variety**: Implements a comprehensive database of exercises with varying intensity levels and durations, allowing for dynamic routine generation.

  - **Randomization**: Utilizes random selection of exercises to provide unique warm-up experiences while maintaining core training principles.

  - **Modular Design**: The project is structured with separate modules for routine generation, position-specific exercises, and utility functions, promoting code reusability and maintainability.
* Day 319: Car Price [Car Price Dataset on Kaggle](https://www.kaggle.com/datasets/asinow/car-price-dataset)

  Today, I worked on analyzing the Car Price Dataset from Kaggle using Python. The focus was on data preprocessing, exploratory data analysis (EDA), and implementing multiple machine learning models to predict car prices. Below are the key highlights of the project:

  - **Data Exploration and Cleaning**: 
    - Inspected the dataset for missing values, outliers, and unique values in each column.
    - Replaced infinite values and handled missing data using imputation techniques.
    - Explored categorical variables such as `Fuel_Type`, `Transmission`, and numerical features like `Price`, `Mileage`, and `Engine_Size`.

  - **Exploratory Data Analysis (EDA)**:
    - Created detailed visualizations, including count plots, box plots, and distribution histograms for both categorical and numerical features.
    - Generated a heatmap for analyzing correlations between numerical variables like `Mileage` and `Price`.
    - Highlighted key relationships, such as the impact of `Fuel_Type` and `Transmission` on car prices.

  - **Feature Encoding**:
    - Encoded categorical variables using `LabelEncoder` to ensure compatibility with machine learning models.

  - **Machine Learning Models**:
    - Implemented and evaluated multiple models, including:
      - **Gradient Boosting**: GradientBoostingClassifier.
      - **LightGBM**: A gradient-boosting framework optimized for speed and performance.
      - **CatBoost**: A gradient-boosting algorithm that handles categorical features efficiently.
      - **Neural Networks**: Multi-layer perceptron (MLPClassifier) for non-linear relationships.

  - **Model Evaluation**:
    - Compared models using metrics such as accuracy, confusion matrices, and ROC curves.
    - Employed cross-validation to assess the stability and generalizability of each model.
    - Plotted detailed ROC curves to evaluate the classification performance across different thresholds.

  - **Results and Insights**:
    - Identified key features influencing car prices, including `Year`, `Mileage`, and `Engine_Size`.
    - Demonstrated the importance of selecting appropriate models for different datasets and problems.

  This project provided hands-on experience in applying machine learning techniques to real-world datasets, as well as the importance of preprocessing and feature engineering. It reinforced my skills in model evaluation and selecting the right tools for effective predictions.
* Day 320: 🤖 Generative AI with DeepSeek and GPT-2 in Python 🧠

  * Today, I worked on a Generative AI project using Python, leveraging the power of DeepSeek and the GPT-2 model from Hugging Face's Transformers library. The project focuses on generating human-like text based on a given prompt, showcasing the capabilities of modern language models. Below are the key highlights:

      * Model and Tokenizer: The project uses the GPT-2 model, a state-of-the-art generative language model, along with its tokenizer to convert text into token IDs and vice versa. This ensures seamless interaction with the model for text generation.

      * Device Optimization: The code automatically detects and utilizes a GPU if available, significantly speeding up the text generation process. If a GPU is not available, it falls back to the CPU, ensuring compatibility across different systems.

      * Text Generation Function: The generate_text function allows for customizable text generation. Parameters like max_length, temperature, and top_k provide control over the length, creativity, and diversity of the generated text.

      * Temperature and Top-K Sampling: By adjusting the temperature and top_k parameters, the system can generate more deterministic or creative outputs. This flexibility makes the model suitable for various applications, from creative writing to technical content generation.

      * Prompt-Based Generation: The system takes a user-defined prompt as input and generates a continuation of the text. This makes it highly adaptable for different use cases, such as storytelling, content creation, or even code generation.

      * User-Friendly Output: The generated text is decoded and cleaned to remove special tokens, ensuring a clean and readable output. This makes the system practical for real-world applications where readability is crucial.

    This project was an excellent opportunity to explore the capabilities of Generative AI and understand how models like GPT-2 can be integrated into Python applications. I gained valuable insights into text generation techniques, model optimization, and the importance of parameter tuning for achieving desired results.
* Day 321: 🏀 Basketball Win-Loss Tracker in Python 🏆

  Today, I worked on a **Basketball Win-Loss Tracker** using Python, with a focus on data analysis and visualization. The project allows users to track the performance of NBA teams during the 2024-25 season, including wins, losses, winning percentages, and other key statistics. Below are the key highlights:

  - **Data Scraping**: The project uses `pandas` to scrape NBA standings data directly from Wikipedia. This ensures that the data is always up-to-date and reflects the latest season statistics.

  - **Data Cleaning**: The scraped data is cleaned to remove unnecessary prefixes (like "x –" or "y –") from team names and to handle missing or inconsistent values. This ensures that the data is ready for analysis and visualization.

  - **Team Selection**: Users can select a team by its corresponding number from a list of all NBA teams. The system then displays detailed statistics for the selected team, including wins, losses, winning percentage, home and road records, and more.

  - **Data Visualization**: The project uses `matplotlib` and `seaborn` to create insightful visualizations, including:
    - A **bar chart** showing wins and losses for the selected team.
    - A **stacked bar chart** comparing wins and losses across all teams, with the selected team highlighted.
    - A **histogram** displaying the distribution of winning percentages across the league.
    - A **box plot** showing the distribution of wins among all teams.

  - **Interactive Analysis**: The system provides an interactive experience, allowing users to explore team statistics and compare performance across the league. This makes it a valuable tool for basketball enthusiasts and data analysts alike.

  - **Extensibility**: The project is designed to be easily extended with additional features, such as comparing multiple teams, analyzing trends over multiple seasons, or integrating data from other sources like APIs.

  This project was an excellent exercise in working with real-world data, cleaning and preparing it for analysis, and creating meaningful visualizations. It reinforced my understanding of data manipulation with `pandas` and data visualization with `matplotlib` and `seaborn`, while also providing a practical tool for tracking NBA team performance.
* Day 322: 🎯 Intent Recognition System with BERT 🤖  

  Today, I worked on an Intent Recognition System using Python and a pre-trained BERT model for zero-shot classification. This project allows the system to determine the intent of user input dynamically without requiring a pre-trained classifier for each specific category. Below are the key highlights:  

  - **Zero-Shot Classification**: The system uses the `facebook/bart-large-mnli` model from Hugging Face’s Transformers library, enabling intent classification without labeled training data.  

  - **Predefined Intents**: A set of possible intents is provided, including `book_flight`, `check_weather`, `play_music`, `set_alarm`, and many others, making the system versatile for various applications.  

  - **Real-Time Interaction**: The program runs an interactive loop where users can input phrases, and the system predicts the most relevant intent in real time. This makes it user-friendly and practical.  

  - **Transformer Model**: By leveraging a powerful transformer-based model, the system can understand natural language queries effectively, providing accurate intent predictions.  

  - **Scalability**: New intents can be easily added to the list without modifying the model, making the system highly adaptable for different use cases.  

  This project was an excellent exercise in applying NLP techniques to build a dynamic and scalable intent recognition system. I had the opportunity to work with Hugging Face’s Transformers library, reinforcing my understanding of zero-shot learning and BERT-based classification. 🚀  
* Day 323: 🎬 Emotion Classifier in Text using Python 🧠

  Today, I worked on an **Emotion Classifier** using Python, leveraging Natural Language Processing (NLP) techniques and Machine Learning (ML) to classify the sentiment of text as either Positive or Negative. The project uses the Rotten Tomatoes movie reviews dataset and focuses on preprocessing text data, feature extraction, and training a Logistic Regression model. Below are the key highlights:

  - **Dataset**: The Rotten Tomatoes dataset was used, which contains movie reviews and their corresponding sentiment labels (`Positive` or `Negative`). The dataset was balanced by undersampling the majority class to ensure fair model training.

  - **Text Preprocessing**: The text data was cleaned and preprocessed using techniques like:
    - **Lowercasing**: Converting all text to lowercase to ensure uniformity.
    - **Stopword Removal**: Removing common stopwords (e.g., "the", "and") while retaining important sentiment-bearing words like "not", "great", and "amazing".
    - **Lemmatization**: Reducing words to their base forms using SpaCy to improve feature consistency.

  - **Feature Extraction**: The preprocessed text was converted into numerical features using **TF-IDF (Term Frequency-Inverse Document Frequency)**. The vectorizer was configured to capture unigrams, bigrams, and trigrams, ensuring that the model could understand context and phrases.

  - **Model Training**: A **Logistic Regression** classifier was trained on the TF-IDF features. The model was chosen for its simplicity and effectiveness in text classification tasks. Class weights were used to handle the balanced dataset and ensure fair treatment of both Positive and Negative samples.

  - **Evaluation**: The model achieved an accuracy of **87%** on the test set, with balanced precision and recall for both Positive and Negative classes. The classification report provided detailed insights into the model's performance.

  - **Prediction**: The trained model can classify new text inputs into Positive or Negative sentiment. For example:
    - `"This movie is great! I loved every moment of it."` → **Positive**
    - `"The film was terrible and boring. I hated it."` → **Negative**

  - **Sample Testing**: The model was tested with a variety of sample texts, including strong positive, strong negative, and mixed sentiment sentences. The results demonstrated the model's ability to generalize well to unseen data.

  - **Scalability**: The project is designed to be easily extendable. Future improvements could include:
    - Adding a **Neutral** sentiment class for more nuanced classification.
    - Using more advanced models like **BERT** or **Transformers** for better accuracy.
    - Deploying the model as a web application using **Flask** or **Streamlit**.

  This project was a great opportunity to dive deeper into NLP and ML techniques, particularly in the context of sentiment analysis. I gained hands-on experience with text preprocessing, feature extraction, and model evaluation, all while building a practical tool for classifying emotions in text.
* Day 324: ⚽ Football Match Outcome Predictor using Machine Learning 🤖

  Today, I worked on a **Football Match Outcome Predictor** using Python and Machine Learning. The project leverages historical match data from the UEFA Champions League to train a model that predicts the outcome of future matches (win, draw, or loss). Below are the key highlights:

  - **Data Fetching**: The system fetches match data from the [Football Data API](https://www.football-data.org/) for the UEFA Champions League. It retrieves details such as home team, away team, and match scores for the specified season.

  - **Data Preprocessing**: The raw match data is preprocessed to extract relevant features like team names and goals scored. The match outcome is determined as either a home win, draw, or away win. Team names are encoded using `LabelEncoder` to prepare the data for machine learning.

  - **Machine Learning Model**: A **Random Forest Classifier** is trained on the preprocessed data to predict match outcomes. The model is evaluated using accuracy and a classification report, ensuring it performs well on unseen data.

  - **Future Season Prediction**: The system allows users to predict outcomes for the **2025 season** (or any future season). If the data for the future season is not available, it uses the current season's teams as a placeholder.

  - **User Interaction**: Users can select two teams from a list of participating teams and get the predicted probabilities for the match outcome (home win, draw, or away win). The system validates user input to ensure only valid team names or numbers are accepted.

  - **Key Features**:
    - **Team Selection**: Users can choose teams by entering their names or corresponding numbers from the displayed list.
    - **Outcome Probabilities**: The model provides probabilities for each possible outcome, helping users understand the likelihood of a win, draw, or loss.
    - **Error Handling**: The system handles invalid inputs gracefully and prompts the user to try again.

  - **Practical Applications**:
    - **Football Fans**: Fans can use the tool to predict outcomes for upcoming matches and engage in discussions or friendly bets.
    - **Sports Analysts**: Analysts can extend the model by adding more features (e.g., team rankings, player stats) to improve prediction accuracy.
    - **Learning Tool**: The project serves as a great introduction to machine learning, data preprocessing, and API integration.

  This project was an exciting opportunity to combine my passion for football with my interest in machine learning. I gained hands-on experience in data preprocessing, model training, and user interaction design, all while building a practical tool for football enthusiasts.
* Day 325: ✨ Simple Spell Checker with Dark Theme in Python 🖤

  Today, I built a **Simple Spell Checker** using Python, with a focus on creating a user-friendly interface and implementing a dark theme for a modern look. The project leverages the `pyspellchecker` library for spell-checking functionality and `tkinter` for the graphical user interface. Below are the key highlights:

  - **Dark Theme**: The application features a sleek dark theme with carefully chosen colors for the background, text, and buttons. This makes it visually appealing and easy on the eyes, especially for extended use.

  - **Spell Checking**: The program uses the `pyspellchecker` library to check the spelling of words entered by the user. It provides instant feedback on whether a word is spelled correctly or suggests corrections if it’s misspelled.

  - **Suggestions**: If a word is misspelled, the application suggests the most likely correct spelling and provides a list of possible corrections. This helps users quickly identify and fix errors.

  - **History Feature**: A history section keeps track of all the words checked during the session. This feature is displayed in a scrollable text area, making it easy to review past inputs and corrections.

  - **Clear Functionality**: A "Clear" button allows users to reset the input field, result label, and history section with a single click. This improves usability and ensures a clean interface for new inputs.

  - **Error Handling**: The application includes robust error handling to ensure a smooth user experience. For example, it displays a warning if the user tries to check an empty input.

  - **User-Friendly Interface**: The interface is designed to be intuitive and easy to use. Labels, buttons, and input fields are well-organized, and the application provides clear feedback at every step.

  This project was a great opportunity to explore GUI development with `tkinter` and enhance my understanding of integrating external libraries like `pyspellchecker`. The dark theme and additional features make this spell checker a polished and practical tool, perfect for a portfolio piece.
* Day 326: 🧩 Maze Solver with Deep Learning in Python 🧠

  Today, I worked on a Maze Solver using Python that integrates Deep Learning principles to navigate through a randomly generated maze. The project employs a neural network to predict the best moves based on the current state of the maze. Below are the key highlights:

  - **Maze Generation**: The maze is generated randomly, with walls and paths created using a simple probabilistic method. The start and destination points are clearly defined, allowing for dynamic exploration.

  - **Data Representation**: The maze is converted into a numerical format suitable for input into the neural network. Each cell in the maze is represented by specific numerical values: `0` for the start, `1` for the destination, `2` for walls, and `3` for paths.

  - **Neural Network Architecture**: A Sequential model from Keras is used to build a neural network with two hidden layers. The model is designed to predict four possible moves (up, down, left, right) based on the current state of the maze.

  - **Training Process**: The model is trained using randomly generated mazes and dummy labels representing potential moves. Although the labels are not optimal paths in this demonstration, they serve as placeholders for future enhancements where actual pathfinding data can be integrated.

  - **Recursive Pathfinding Algorithm**: A recursive function is implemented to explore the maze using predictions from the trained neural network. It marks visited cells and attempts to find a path to the destination by considering the most probable moves suggested by the model.

  - **Visualization of Results**: Upon successfully finding a path, the maze is updated to reflect the visited cells, providing a clear visual representation of the route taken from start to destination. If no path is found, an appropriate message is displayed.

  This project was an engaging exercise in combining traditional algorithmic approaches with modern machine learning techniques. It allowed me to explore how deep learning can enhance decision-making processes in dynamic environments like mazes. I gained valuable insights into neural network training and pathfinding algorithms while creating an interactive tool that showcases these concepts effectively.
* Day 327: 👗 Fashion Image Classifier with TensorFlow 🖼️

  Today, I worked on building a **Fashion Image Classifier** using TensorFlow and Keras. The goal of this project was to create a machine learning model capable of classifying images of clothing items from the **Fashion MNIST dataset**. Below are the key highlights:

  - **Dataset**: The Fashion MNIST dataset consists of 70,000 grayscale images (28x28 pixels) across 10 categories, such as T-shirts, trousers, dresses, and sneakers. It’s a popular dataset for benchmarking image classification models.

  - **Model Architecture**: I built a simple yet effective neural network using Keras' `Sequential` API. The model includes:
    - A `Flatten` layer to convert the 28x28 image into a 1D array.
    - A `Dense` layer with 128 units and ReLU activation for feature extraction.
    - A `Dropout` layer to prevent overfitting.
    - An output `Dense` layer with 10 units (one for each class) and softmax activation for classification.

  - **Training**: The model was trained for 10 epochs using the Adam optimizer and sparse categorical cross-entropy loss. The training process achieved high accuracy on both the training and validation sets.

  - **Evaluation**: After training, the model was evaluated on the test dataset, achieving an accuracy of over **88%**. This demonstrates the model's ability to generalize well to unseen data.

  - **Visualization**: To better understand the model's performance, I created visualizations of:
    - Training and validation accuracy over epochs.
    - Predictions for the first few test images, showing the predicted class, confidence score, and true label.

  - **Practical Use**: This classifier can be used in real-world applications such as e-commerce platforms to automatically categorize clothing items, improving user experience and search functionality.

  This project was a great opportunity to dive deeper into **deep learning** and **image classification**. I gained hands-on experience with TensorFlow and Keras, and I learned how to build, train, and evaluate a neural network from scratch. I also explored techniques like dropout to improve model performance and prevent overfitting.
* Day 328: Technical Test "minimumTotal" and "maxProfit" [LeetCode](https://leetcode.com/problems/)

  - **minimumTotal**: Implemented a solution for the "Triangle" problem, where the goal is to find the minimum path sum from top to bottom in a triangle array. The approach uses dynamic programming by iteratively updating each element with the minimum sum it can achieve by moving down or diagonally. This method ensures that we consider all possible paths efficiently.
    [Problem Description: minimumTotal](https://leetcode.com/problems/triangle/description/)


  - **maxProfit**: Solved the "Best Time to Buy and Sell Stock" problem, aiming to maximize profit by choosing optimal days for buying and selling a stock. The solution iterates through daily prices, maintaining a running minimum price seen so far and calculating potential profits based on this minimum. It updates maximum profit whenever it finds a better opportunity.
    [Problem Description: maxProfit](https://leetcode.com/problems/best-time-to-buy-and-sell-stock/description/)
* Day 329: 🏀 Basketball Play Generator with TensorFlow 🧠

  Today, I worked on a **Basketball Play Generator** using **TensorFlow**, a deep learning framework, to create a model that generates basketball plays based on player positions and common actions. The project focuses on simulating realistic basketball plays by combining positions (e.g., Point Guard, Center) with actions (e.g., Pick and Roll, Pass, Shoot a Three-pointer). Below are the key highlights:

  - **Dataset Simulation**: I created a simulated dataset of 30,000 basketball plays, where each play is a sequence of 3-5 actions linked to specific player positions. The dataset ensures a balanced distribution of actions to avoid overfitting to common plays like "Pick and Roll" or "Pass."

  - **Neural Network Model**: The project uses a **LSTM-based neural network** with **Embedding layers** to process both player positions and actions. The model is trained to predict the next action in a sequence, making it capable of generating new plays dynamically.

  - **Temperature-Based Sampling**: To increase the diversity of generated plays, I implemented **temperature-based sampling** during play generation. Higher temperature values introduce more randomness, ensuring that the model doesn't always repeat the same actions.

  - **Visualizations**: I added several visualizations to analyze the dataset and model performance:
    - **Action Distribution**: A bar chart showing the frequency of each action in the dataset.
    - **Training History**: Line plots displaying the model's accuracy and loss over training epochs.
    - **Confusion Matrix**: A heatmap to evaluate the model's performance in predicting actions.

  - **Play Generation**: The model generates basketball plays step by step, starting from a seed play (e.g., `[("Point Guard (PG)", "Pick and Roll"), ("Shooting Guard (SG)", "Pass")]`). Each generated play includes a sequence of actions assigned to specific positions, ensuring realistic and diverse plays.

  - **Practical Application**: This project can be used by basketball coaches and players to simulate offensive strategies, explore new play combinations, and improve team coordination. It also serves as a great example of how deep learning can be applied to sports analytics.

  This project was an excellent opportunity to explore **sequence generation** with **LSTM networks** and apply **TensorFlow** to a real-world problem. I gained valuable experience in data preprocessing, model training, and visualization, all while building a tool that could have practical applications in basketball strategy.
* Day 330: 📰 Topic Classifier with Scikit-learn and NLP 📊

  Today, I worked on a **Topic Classifier** using Python, focusing on Natural Language Processing (NLP) and Machine Learning. The project classifies news articles into predefined categories (e.g., sports, technology, politics) using the `scikit-learn` library. Below are the key highlights:

  - **Dataset**: I used the **20 Newsgroups dataset**, a collection of newsgroup documents labeled into 20 categories. For simplicity, I focused on 5 categories: `sci.space`, `comp.graphics`, `talk.politics.guns`, `rec.sport.baseball`, and `sci.med`.

  - **Text Preprocessing**: The raw text data was cleaned and preprocessed using techniques like:
    - **Tokenization**: Splitting text into individual words.
    - **Lemmatization**: Reducing words to their base or root form.
    - **Stopword Removal**: Eliminating common words (e.g., "the", "and") that add little meaning.
    - **TF-IDF Vectorization**: Converting text into numerical features to make it suitable for machine learning models.

  - **Model Training**: I trained and compared multiple machine learning models, including:
    - **Multinomial Naive Bayes**: A probabilistic classifier commonly used for text classification.
    - **Support Vector Machine (SVM)**: A powerful model for high-dimensional data like text.
    - **Random Forest**: An ensemble method that combines multiple decision trees.
    - **Logistic Regression**: A linear model for binary and multiclass classification.

  - **Model Evaluation**: The models were evaluated using:
    - **Accuracy**: The percentage of correctly classified documents.
    - **Confusion Matrix**: A detailed breakdown of true vs. predicted labels.
    - **Classification Report**: Precision, recall, and F1-score for each category.

  - **Visualizations**: I created several visualizations to better understand the dataset and model performance:
    - **Topic Distribution**: A bar plot showing the number of documents in each category.
    - **Document Length Distribution**: A histogram displaying the distribution of document lengths (in words).
    - **Most Common Words**: A bar plot highlighting the most frequent words in the dataset.
    - **Confusion Matrix**: A heatmap showing how well the model classified documents into the correct categories.

  - **Hyperparameter Tuning**: I used **Grid Search** to optimize the hyperparameters of the SVM model, ensuring the best possible performance.

  - **Cross-Validation**: To ensure the model's robustness, I performed **5-fold cross-validation**, which provided a more reliable estimate of the model's accuracy.

  - **Practical Application**: This project demonstrates how machine learning can be used to automatically categorize large volumes of text data, a task that is highly relevant in fields like news aggregation, content moderation, and customer feedback analysis.
* Day 331: 🐱 Pet Database Management in Python 🐾

  Today, I worked on a **Pet Database Management System** using Python. The project focuses on handling pet-related information, including names, breeds, and ages. The system is designed to store and manage pet records efficiently. Below are the key highlights:

  - **Data Storage**: The pet records are structured as a list of dictionaries, where each pet has attributes such as `name`, `breed`, and `age`. This makes it easy to manipulate and query the data.

  - **Dummy Data Generation**: I generated a dataset of 20 pets with various breeds and ages. This dataset is useful for testing and simulating real-world scenarios where pet databases are needed.

  - **Data Manipulation**: The system supports operations such as adding new pets, retrieving pet information, and filtering pets by breed or age. This provides flexibility for users who want to manage pet data dynamically.

  - **Scalability**: The structure allows easy extension by integrating a database backend in the future. The current implementation can be expanded with features like owner tracking, vaccination records, and adoption history.

  - **Usability**: The project is designed to be straightforward and user-friendly, making it an excellent foundation for pet-related applications such as veterinary management or pet adoption platforms.

  This project was a great opportunity to practice data organization and management using Python. It reinforced my understanding of handling structured data while keeping the system flexible and scalable. 🐶🐾
* Day 332: 🎭 Shakespeare Text Generator in Python 🖋️

  Today, I worked on a **Shakespeare Text Generator** using Python, with a focus on deep learning techniques such as Recurrent Neural Networks (RNNs) and Long Short-Term Memory (LSTM) networks. The project generates text that mimics the writing style of William Shakespeare, trained on his works. Below are the key highlights:

  - **LSTM Model**: The core of the project is an LSTM model, which is well-suited for sequence prediction tasks like text generation. The model learns the patterns and structure of Shakespeare's writing, allowing it to generate coherent and stylistically similar text.

  - **Preprocessing**: The text data is preprocessed by converting characters into numerical indices, creating sequences of fixed length, and one-hot encoding the labels. This prepares the data for training the LSTM model.

  - **Training**: The model is trained on sequences of characters from Shakespeare's works. By predicting the next character in a sequence, the model learns the relationships between characters and the overall structure of the text.

  - **Text Generation**: After training, the model can generate new text by starting with a seed sequence and predicting the next character iteratively. The generated text maintains the stylistic elements of Shakespeare's writing, such as poetic language and dramatic phrasing.

  - **Customizable Seed Text**: The generator allows users to input a custom seed text, which serves as the starting point for text generation. This makes the tool interactive and adaptable to different creative needs.

  - **Efficient Training**: The model is designed to train efficiently with reduced epochs and optimized hyperparameters, making it faster while still producing high-quality results.

  This project was an exciting dive into natural language processing and deep learning. It provided a hands-on opportunity to explore how LSTMs can capture the nuances of human language and generate creative, stylistically consistent text. The generator can be used for creative writing, educational purposes, or simply for fun!
* Day 333: 🏋️ Muscle Fatigue Simulation in Python 💪

  Today, I worked on a Muscle Fatigue Simulation System using Python, with a focus on Object-Oriented Programming (OOP) principles such as inheritance, encapsulation, and abstraction. The project simulates muscle fatigue based on user inputs and records data for analysis. Below are the key highlights:

  - **Encapsulation**: The `Muscle` class encapsulates attributes like `name`, `max_force`, and `fatigue_rate`, ensuring that these values are controlled and accessed through defined methods.

  - **Inheritance**: The system uses inheritance to model different muscle groups. The `Muscle` base class is extended by specific muscle types, allowing for reusability and specialization in fatigue behavior.

  - **Abstraction**: The `Muscle` class contains an abstract method `apply_fatigue`, which is implemented by its subclasses. This ensures that each muscle type has a tailored fatigue simulation, maintaining a structured and scalable design.

  - **Fatigue Simulation**: Users can input muscle exertion levels, and the system calculates fatigue dynamically. The simulation models real-world muscle endurance and recovery principles.

  - **Data Recording**: The system stores fatigue progression in an SQLite database, enabling users to track and analyze muscle fatigue over time.

  - **Graphical Analysis**: Using Matplotlib, the project visualizes fatigue levels over time, helping users understand the impact of exertion on different muscle groups.

  - **Interactive Interface**: A Tkinter-based GUI allows users to select muscles, enter exertion data, and visualize results, making the system practical and user-friendly.

  This project was an excellent exercise in applying OOP principles to create a structured and maintainable simulation tool. I refined my understanding of abstraction, encapsulation, and inheritance while building a system that effectively models and tracks muscle fatigue dynamics.
* Day 334: 🤖 Intent Classifier for Messages using Python 🧠

  Today, I worked on an **Intent Classifier for Messages** using Python, with a focus on Natural Language Processing (NLP) techniques and machine learning. The project aims to classify the intent behind a message, such as "purchase," "help," or "question," which can be integrated into chatbots or customer support systems. Below are the key highlights:

  - **Text Preprocessing**: The system uses NLTK to preprocess text by converting it to lowercase, removing punctuation, and eliminating stopwords. This ensures that the input data is clean and ready for analysis.

  - **TF-IDF Vectorization**: The `TfidfVectorizer` from Scikit-learn is used to convert text into numerical features, capturing the importance of words in the context of the dataset.

  - **Naive Bayes Classifier**: A `MultinomialNB` model is trained to classify messages into intents. The model is simple yet effective for text classification tasks.

  - **Hyperparameter Tuning**: Using `GridSearchCV`, the system automatically finds the best hyperparameters for the TF-IDF vectorizer and the Naive Bayes classifier, optimizing the model's performance.

  - **Model Evaluation**: The classifier is evaluated using accuracy, a classification report, and a confusion matrix. Visualizations like the confusion matrix provide insights into the model's performance.

  - **Model Persistence**: The trained model is saved to a file using `joblib`, allowing it to be reused without retraining. This makes the system efficient and ready for deployment.

  - **Testing with New Messages**: The system is tested with new, unseen messages to demonstrate its ability to generalize and classify intents accurately.

  This project was an excellent exercise in applying NLP and machine learning techniques to build a practical and scalable intent classification system. I had the opportunity to refine my understanding of text preprocessing, model training, and deployment, all while creating a tool that can be used in real-world scenarios.
* Day 335: 🐦 Twitter US Airline Sentiment Analysis [Twitter US Airline Sentiment Dataset on Kaggle](https://www.kaggle.com/datasets/crowdflower/twitter-airline-sentiment/)

  Today, I worked on an **Unsupervised Sentiment Analysis** project using the **Twitter US Airline Sentiment Dataset**. The goal was to analyze tweets related to US airlines and group them into positive, negative, and neutral sentiments without relying on labeled data. Below are the key highlights:

  - **Exploratory Data Analysis (EDA)**: I performed a comprehensive EDA to understand the dataset, including sentiment distribution, word cloud visualization, and correlation analysis. This helped me identify patterns and trends in the data, such as the most common words and the distribution of tweets across different airlines.

  - **Text Preprocessing**: I cleaned and preprocessed the text data by removing stopwords, punctuation, and lemmatizing the words using **SpaCy**. This step was crucial to prepare the data for clustering and topic modeling.

  - **Clustering with K-Means**: I used **K-Means clustering** to group the tweets into three clusters (positive, negative, and neutral). The clustering was performed on TF-IDF vectorized text, and the results were evaluated using the **silhouette score**.

  - **Topic Modeling with LDA**: To uncover the main themes within the tweets, I applied **Latent Dirichlet Allocation (LDA)**. This helped identify the top words associated with each topic, providing insights into the common issues or praises mentioned in the tweets.

  - **Visualizations**: I created several visualizations, including sentiment distribution, word clouds, and correlation heatmaps, to make the analysis more intuitive and accessible.

  - **Unsupervised Approach**: Unlike traditional sentiment analysis, this project did not rely on labeled data. Instead, it used unsupervised techniques to group tweets based on their content, making it a flexible and scalable solution for analyzing large volumes of text data.

  This project was a great opportunity to explore unsupervised learning techniques and apply them to real-world text data. I gained valuable experience in text preprocessing, clustering, and topic modeling, all while building a practical tool for sentiment analysis.
* Day 336: 🎯 Josephus Problem Solver in Python 🧮

  Today, I worked on solving the **Josephus Problem** using Python, with a focus on **recursion**, **user interface design**, and **input validation**. The project provides a graphical interface for users to input the number of people and the step size, and it displays the elimination steps along with the final survivor. Below are the key highlights:

  - **Recursion**: The Josephus problem is solved using a recursive approach. The function `josephus(n, k)` calculates the position of the last remaining person in a circle of `n` people, where every `k-th` person is eliminated. This demonstrates the power of recursion in solving mathematical problems.

  - **User Interface**: The project features a **Tkinter-based GUI** with a modern dark theme. Users can input values for `n` (number of people) and `k` (step size) and click the "Solve" button to see the results. The interface is intuitive and visually appealing, with dark backgrounds and light text for better readability.

  - **Input Validation**: The program ensures that users enter valid positive integers for `n` and `k`. If invalid inputs are provided, an error message is displayed, guiding the user to correct their input.

  - **Process Visualization**: The `josephus_with_steps(n, k)` function not only calculates the final survivor but also displays the elimination steps in real-time. This helps users understand how the problem is solved step by step.

  - **Unit Testing**: The project includes unit tests to verify the correctness of the Josephus problem solver. The `TestJosephus` class tests both the recursive solution and the step-by-step elimination process, ensuring the program works as expected.

  - **Modern Design**: The GUI uses a dark theme with custom fonts and colors. Buttons are designed to be visually appealing and responsive, providing a comfortable user experience. The text box displays the elimination steps in a clear and organized manner.

  This project was a great opportunity to combine mathematical problem-solving with practical software development skills. I gained experience in creating user-friendly interfaces, validating user inputs, and writing unit tests, all while solving an interesting historical problem.
* Day 337: 🎳 Bowling Score Calculator in Python 🏆

  Today, I worked on a **Bowling Score Calculator** using Python, with a focus on implementing the rules of bowling and creating a user-friendly interface to calculate and display scores. The project allows users to input rolls (strikes, spares, or pin counts) and calculates the total score based on the official rules of bowling. Below are the key highlights:

  - **Input Validation**: The program validates user input to ensure that rolls follow bowling rules. For example, strikes are represented by `'X'`, spares by `'/'`, and pin counts by numbers. Invalid inputs are rejected to maintain data integrity.

  - **Score Calculation**: The calculator accurately computes the total score, taking into account strikes and spares. Strikes add 10 points plus the next two rolls, while spares add 10 points plus the next roll. Regular rolls add their face value.

  - **Scorecard Visualization**: The program generates a scorecard in ASCII format, displaying the rolls for each frame and the cumulative score. This makes it easy for users to track their progress throughout the game.

  - **User Interaction**: A simple and intuitive interface allows users to input rolls one by one. They can type `'done'` to finish entering rolls and view the final scorecard.

  - **Extensibility**: The code is modular and easy to extend. For example, additional features like saving score history or simulating multiple games could be added in the future.

  This project was a great exercise in applying logic and problem-solving skills to implement the rules of bowling in code. It also reinforced my understanding of data validation, string manipulation, and user interface design in Python. The result is a practical tool that can be used to calculate and visualize bowling scores with ease.
* Day 338: Technical Test "maxProfitll" and "maxProfitlll" [LeetCode](https://leetcode.com/problems/)

  - **maxProfitll**: Solved the "Best Time to Buy and Sell Stock II" problem, where the goal is to maximize profit by buying and selling stocks multiple times. The solution iterates through the prices array, capturing all possible profits from upward price movements. This approach ensures that we accumulate the maximum profit by buying low and selling high whenever possible.
    [Problem Description: maxProfitll](https://leetcode.com/problems/best-time-to-buy-and-sell-stock-ii/description/)

  - **maxProfitlll**: Solved the "Best Time to Buy and Sell Stock III" problem, aiming to maximize profit with at most two transactions. The solution uses dynamic programming to track the maximum profit after the first buy, first sell, second buy, and second sell. By iterating through the prices array, it ensures that all possible combinations of two transactions are considered to achieve the highest profit.
    [Problem Description: maxProfitlll](https://leetcode.com/problems/best-time-to-buy-and-sell-stock-iii/description/)
* Day 339: 👨‍💼 Employee Management System in Python 🏢

  Today, I worked on an **Employee Management System** using Python, following the **Model-View-Controller (MVC)** architecture. The project focuses on managing employee data efficiently, with features to add, remove, update, and search employees, as well as display statistics and save/load data. Below are the key highlights:

  - **MVC Architecture**: The system is structured using the MVC pattern, separating concerns into **Model**, **View**, and **Controller** components. This ensures clean, maintainable, and scalable code.

  - **Model**: The `Employee` class represents an employee with attributes like `id`, `name`, `position`, `salary`, and `department`. The `EmployeeModel` class handles data management, including adding, removing, and updating employees, as well as searching and calculating statistics.

  - **View**: The `EmployeeView` class manages the user interface, displaying a menu and employee data. It also collects user input for adding, updating, and searching employees, making the system intuitive and user-friendly.

  - **Controller**: The `EmployeeController` class acts as the intermediary between the Model and View. It processes user input, calls the appropriate methods in the Model, and updates the View accordingly.

  - **Employee Management**: The system allows users to:
    - View all employees.
    - Add new employees.
    - Remove employees by ID.
    - Search employees by department.
    - Update employee salaries.
    - Display statistics (total employees, total salary, average salary).

  - **Data Persistence**: Employees can be saved to and loaded from a file (`employees.txt`), ensuring data is retained between sessions.

  - **Menu-Driven Interface**: A simple and intuitive menu guides users through the system, making it easy to perform operations like adding, removing, and updating employee data.

  This project was a great opportunity to practice **MVC architecture** and **file handling** in Python. It reinforced my understanding of how to structure applications for clarity and scalability, while also providing a practical tool for managing employee data.
* Day 340: [Mall Customer Segmentation Data on Kaggle](https://www.kaggle.com/datasets/vjchoudhary7/customer-segmentation-tutorial-in-python/data)

    Today, I worked on analyzing the Mall Customer Segmentation Dataset from Kaggle using Python. The focus was on customer segmentation using clustering techniques, specifically K-Means, and exploring the dataset through data visualization and statistical analysis. Below are the key highlights:

    - **Statistical Summary**: The project includes generating a statistical summary of numerical variables such as Age, Annual Income, and Spending Score. This provides insights into the central tendency, spread, and distribution of the data.

    - **Categorical Distribution**: I created visualizations to display the distribution of categorical variables, such as Gender. This helps in understanding the demographic composition of the customers.

    - **Numerical Distributions**: The code generates histograms for numerical variables, allowing for a visual inspection of their distributions. This helps identify patterns, skewness, or outliers in the data.

    - **Correlation Analysis**: A correlation matrix is generated to analyze relationships between numerical variables. This provides insights into potential relationships, such as whether higher income correlates with higher spending scores.

    - **Clustering with K-Means**: The project includes implementing the K-Means clustering algorithm to segment customers into distinct groups based on their Age, Annual Income, and Spending Score. The optimal number of clusters is determined using the Elbow Method.

    - **Cluster Visualization**: The clusters are visualized using scatter plots, showing how customers are grouped based on their Annual Income and Spending Score. This helps in understanding the characteristics of each cluster.

    - **Silhouette Analysis**: The quality of the clustering is evaluated using the Silhouette Score, which measures how well each customer fits into their assigned cluster.

    - **Gender Distribution by Cluster**: I analyzed how gender is distributed across the clusters, providing insights into whether certain clusters are dominated by a specific gender.

    - **Age vs Spending Score by Cluster**: Visualizations are created to explore the relationship between Age and Spending Score within each cluster, helping to identify trends or patterns.

    - **Annual Income vs Spending Score by Cluster**: Scatter plots are used to analyze the relationship between Annual Income and Spending Score for each cluster, providing insights into customer behavior.

    This project was an excellent opportunity to apply clustering techniques to real-world data and gain insights into customer behavior. The experience reinforced the importance of data visualization and statistical analysis in understanding and interpreting complex datasets.
* Day 341:🏥 MedNER: Medical Named Entity Recognition (NER) Project 💊

  Today, I worked on a Named Entity Recognition (NER) system for medical-related entities using Python, with a focus on Object-Oriented Programming (OOP) principles such as encapsulation, modularity, and user interaction. The project is designed to extract medical entities such as diseases, medications, symptoms, and medical procedures from clinical reports or scientific articles. Below are the key highlights:

  - **Encapsulation**: The `MedNER` class encapsulates attributes like `patterns` and `database connection`, ensuring that the entity extraction logic and data storage details are protected. Controlled access is provided through specialized methods like `extract_entities` and `store_entities`.

  - **Modularity**: The system is divided into modular components, such as entity extraction, database storage, and visualization. This makes the codebase easy to maintain and extend with new features in the future.

  - **Entity Management**: The system can identify and classify medical entities such as diseases, medications, symptoms, and procedures. The `extract_entities` method uses regular expressions to match predefined patterns, ensuring accurate extraction of relevant entities.

  - **Database Integration**: Extracted entities are stored in a SQLite database for persistent storage and further analysis. The `store_entities` method handles the insertion of entities into the database, making the system scalable for large datasets.

  - **Visualization**: The system includes a visualization feature using `matplotlib` to display the frequency of extracted entities. This provides a clear and intuitive way to analyze the results.

  - **User Interaction**: A user-friendly graphical interface (GUI) built with `tkinter` allows users to input text or upload files for analysis. The interface is designed with a dark theme and intuitive buttons, ensuring a comfortable and modern user experience.

  - **Practical Use Cases**: The system is designed for real-world applications, such as analyzing medical histories, classifying symptoms, and extracting relevant information from clinical reports. It can be easily integrated into larger healthcare systems or used as a standalone tool.

  This project was an excellent exercise in applying OOP principles to create a well-structured and maintainable system for medical entity recognition. I had the opportunity to refine my understanding of how encapsulation and modularity work together to create clean and reusable code, all while building a practical tool for medical text analysis.
* Day 342: 🌍 Travel Planner App in Python 🗺️

  Today, I worked on a **Travel Planner App** using Python and Streamlit, with a focus on creating an interactive and user-friendly tool for planning trips. The app allows users to create itineraries, track budgets, and get recommendations for places to visit. Below are the key highlights:

  - **Itinerary Management**: Users can add activities to their itinerary, including details like activity name, date, cost, category (e.g., transport, accommodation, food), and priority (low, medium, high). The app stores this information in a session state, ensuring persistence across interactions.

  - **Budget Tracking**: The app calculates the total cost of all activities and compares it to the user's estimated budget. It provides real-time feedback on whether the user is within budget or overspending, along with a visual representation of budget vs. expenses.

  - **Expense Analysis**: The app categorizes expenses (e.g., transport, accommodation, food) and provides a pie chart to visualize the distribution of costs. This helps users understand where their money is being spent.

  - **Cumulative Expenses**: A line chart shows how expenses accumulate over time, giving users insight into their spending patterns throughout the trip.

  - **Priority Filtering**: Users can filter activities by priority (low, medium, high), making it easier to focus on the most important tasks.

  - **Travel Recommendations**: Based on the destination entered by the user, the app provides a list of popular places to visit. While the current version uses a static dictionary for recommendations, this feature can be extended with dynamic data sources in the future.

  - **Export Functionality**: The app allows users to export their itinerary as a CSV file, making it easy to share or print their travel plans.

  - **Interactive Visualizations**: The app uses **Plotly** to create interactive charts, including bar charts for budget vs. expenses, pie charts for expense distribution, and line charts for cumulative expenses.

  This project was an excellent exercise in building a practical and interactive web application using Streamlit. I gained experience in managing session states, creating dynamic visualizations, and designing a user-friendly interface. The app is well-suited for travelers who want to organize their trips efficiently and stay on top of their budgets.
* Day 343: 🔒 Metadata Analysis Tool in Python 📂

  Today, I worked on a **Metadata Analysis Tool** using Python, with a focus on file processing, metadata extraction, and user-friendly interface design. The tool allows users to analyze and manage metadata from various file types, including images, PDFs, and Word documents. Below are the key highlights:

  - **Metadata Extraction**: The tool extracts metadata from images (JPEG, PNG), PDFs, and Word documents (DOCX). For images, it uses the `Pillow` library to read EXIF data. For PDFs, it uses `pdfplumber`, and for Word documents, it uses `python-docx`.

  - **User-Friendly Interface**: The tool features a modern and intuitive graphical user interface (GUI) built with `Tkinter`. The dark theme and well-designed buttons make it comfortable for users to interact with the application.

  - **Batch Processing**: Users can select multiple files at once for analysis or metadata removal. This feature is particularly useful for handling large numbers of files efficiently.

  - **Metadata Removal**: For image files, the tool provides an option to remove metadata, ensuring privacy and security. This is done by saving the image without EXIF data using the `Pillow` library.

  - **Export Functionality**: Users can export the metadata analysis results to a `.csv` or `.txt` file. This makes it easy to save and share the results for further analysis or reporting.

  - **Logging**: All actions, such as file analysis and metadata removal, are logged to a file (`metadata_tool_log.txt`). This provides an audit trail for tracking user activities.

  - **Error Handling**: The tool includes robust error handling to manage unsupported file types or corrupted files gracefully. Users are notified of any issues through clear error messages.

  This project was an excellent exercise in combining file processing, metadata management, and GUI development. I gained valuable experience in working with different file formats, designing user-friendly interfaces, and implementing practical features like batch processing and logging. The tool is not only functional but also visually appealing, making it a great addition to my portfolio.
* Day 344: 🎮 Nim Game Solver in Python 🧠

  Today, I worked on a **Nim Game Solver** using Python, with a focus on recursion, game theory, and optimal strategy. The project allows users to play the classic Nim game against a computer opponent that always makes optimal moves. Below are the key highlights:

  - **Recursion**: The core of the project is a recursive function `nim_game_solver` that determines the optimal move for any given state of the game. This function explores all possible moves and uses backtracking to find the best strategy.

  - **Memoization**: To optimize performance, I implemented memoization using a dictionary to store previously computed results. This significantly reduces the computation time for larger piles by avoiding redundant calculations.

  - **Game Theory**: The project leverages the mathematical principles of the Nim game, particularly the XOR operation, to determine winning and losing positions. This ensures that the computer always makes the best possible move to force a win.

  - **Player vs. Computer**: The game supports two modes: the player can make moves manually, while the computer uses the `nim_game_solver` to make optimal moves. This creates a challenging and interactive experience.

  - **Input Validation**: The program includes robust input validation to ensure that the user enters valid pile sizes and move choices. This makes the game more user-friendly and prevents errors during gameplay.

  - **Game State Visualization**: After each move, the current state of the piles is displayed, allowing the player to track the progress of the game. This enhances the user experience and makes the game more engaging.

  - **Winning Strategy**: The computer is programmed to always force a win if it starts in a winning position. If the player starts in a winning position and plays optimally, they can also force a win, demonstrating the power of strategic thinking.

  This project was an excellent exercise in applying recursion, game theory, and optimization techniques to create a functional and interactive game. I had the opportunity to deepen my understanding of how algorithms can be used to solve strategic problems, all while building a fun and challenging game.
* Day 345: Technical Test "maxPathSum" and "isPalindrome" [LeetCode](https://leetcode.com/problems/)

  - **maxPathSum**: Implemented a solution for the "Maximum Path Sum" problem, where the task is to find the maximum path sum in a binary tree. A path is defined as a sequence of nodes where each pair of adjacent nodes has an edge connecting them, and no node appears more than once in the sequence. The path does not need to pass through the root. The approach uses a recursive helper function to compute the maximum gain from each node while updating the global maximum sum. The time complexity is O(n), where n is the number of nodes in the tree.
    [Problem Description: maxPathSum](https://leetcode.com/problems/binary-tree-maximum-path-sum/description/)

  - **isPalindrome**: Solved the "Valid Palindrome" problem, which determines if a given string is a palindrome after converting all uppercase letters to lowercase and removing all non-alphanumeric characters. The solution uses a two-pointer approach to compare characters from the start and end of the string, skipping non-alphanumeric characters. The time complexity is O(n), where n is the length of the string.
    [Problem Description: isPalindrome](https://leetcode.com/problems/valid-palindrome/description/)
* Day 346: 🌳 Tree Mirror in Python 🪞

  Today, I worked on a **Tree Mirror** project using Python, focusing on recursion and tree manipulation. The project involves creating a mirror image of a binary tree and visualizing both the original and mirrored trees using `matplotlib` and `networkx`. Below are the key highlights:

  - **Recursion**: The `mirror_tree` function uses recursion to swap the left and right children of each node in the binary tree, effectively creating a mirror image of the tree. This demonstrates the power of recursion in solving tree-based problems efficiently.

  - **Tree Visualization**: The `visualize_tree` function uses `networkx` to create a graph representation of the binary tree, and `matplotlib` is used to plot the tree. This allows for a clear visual comparison between the original and mirrored trees.

  - **TreeNode Class**: The `TreeNode` class represents a node in the binary tree, with attributes for `value`, `left`, and `right` children. This simple structure is the foundation for building and manipulating the tree.

  - **Example Usage**: The program includes an example binary tree with nodes `1` through `7`. The original tree is visualized first, followed by the mirrored tree, showcasing the transformation.

  - **User-Friendly Output**: The program generates two plots: one for the original binary tree and one for the mirrored tree. This makes it easy to understand the effect of the mirroring operation.

  This project was a great exercise in understanding tree structures, recursion, and visualization techniques. It reinforced my knowledge of how to manipulate binary trees and provided a practical way to visualize the results using Python libraries.
* Day 347: 📊 Data Visualization and Report Generation in Python 📈

  Today, I worked on a Data Visualization and Report Generation project using Python, focusing on creating a comprehensive report with tables and visualizations for a Data Scientist's portfolio. The project leverages the Model-View-Controller (MVC) architecture to ensure clean, maintainable, and scalable code. Below are the key highlights:

  - **MVC Architecture**: The project is structured using the MVC pattern, separating data handling (`Model`), visualization and document generation (`View`), and logic (`Controller`). This ensures a clear separation of concerns and makes the codebase easy to extend.

  - **Data Visualization**: The project includes multiple visualizations to provide insights into the data:
    - **Line Chart**: Shows hours worked over time.
    - **Bar Chart**: Displays total hours worked by each employee.
    - **Pie Chart**: Illustrates the distribution of hours worked across clients.
    - **Histogram**: Visualizes the distribution of hours worked.
    - **Scatter Plot**: Highlights the relationship between dates and hours worked.

  - **Document Automation**: The `DocumentView` class automates the creation of a Word document, incorporating tables and visualizations seamlessly. This makes it easy to generate professional reports with minimal effort.

  - **Data Handling**: The `DataModel` class handles data loading from an Excel file, ensuring that the data is easily accessible for analysis and visualization.

  - **Customizable Visualizations**: The `GraphView` class provides static methods for generating various visualizations, making it easy to add or modify charts as needed.

  - **Practical Application**: This project is highly practical for a Data Scientist's portfolio, showcasing skills in data analysis, visualization, and report generation. It can be adapted to various datasets and use cases, making it a versatile tool.

  This project was an excellent opportunity to refine my skills in data visualization, document automation, and software design patterns. By applying the MVC architecture, I was able to create a well-structured and maintainable system that can be easily extended with new features in the future.
* Day 348: Sales Data Analysis [Kaggle](https://www.kaggle.com/datasets/beekiran/sales-data-analysis/data)

    Today, I worked on analyzing the Sales Data Analysis dataset from Kaggle using Python. The focus was on data exploration, visualization, and predictive modeling using libraries such as Pandas, Seaborn, Matplotlib, and Scikit-learn. The project includes generating statistical summaries, visualizing distributions of numerical and categorical variables, and building regression models to predict sales. Below are the key highlights:

    - **Statistical Summary**: The project includes a function that generates a statistical summary of numerical variables, such as `quantity_ordered`, `price_each`, and `sales`. This helps in understanding the central tendency, spread, and overall distribution of the data.

    - **Categorical Distribution**: I created visualizations to display the distribution of categorical variables, such as `product` and `city`. This provides insights into the most popular products and cities with the highest sales.

    - **Numerical Distributions**: The code generates histograms and boxplots for numerical variables, allowing for visual inspection of their distributions. This helps identify trends, outliers, and patterns in the data.

    - **Correlation Analysis**: A correlation matrix is generated to analyze relationships between numerical variables. This provides insights into potential relationships that can be explored further, and is visualized with a heatmap for clarity.

    - **Predictive Modeling**: I built and evaluated multiple regression models, including Gradient Boosting, LightGBM, and Neural Networks, to predict sales based on features such as `quantity_ordered`, `price_each`, `city`, and `month`. The models were evaluated using metrics such as Mean Squared Error (MSE) and R-squared (R2).

    - **Model Comparison**: The project includes a comparison of different models using cross-validation, providing insights into their performance and robustness. This helps in selecting the best model for the task.

    - **User-Friendly Functions**: The project includes functions for generating the full report, making it easy to run all analyses in one go. This modular approach enhances code readability and maintainability.

    This project was an excellent opportunity to deepen my understanding of data analysis and predictive modeling techniques in Python, as well as to explore the Sales Data Analysis dataset thoroughly. The experience reinforced the importance of visualizing data and building robust models to extract meaningful insights and make data-driven decisions.
* Day 349: 🎳 Bowling League Manager in Python 🏆

  Today, I worked on a **Bowling League Manager** using Python, with a focus on the **Model-View-Controller (MVC)** architecture. This project allows users to manage a bowling league by registering players and teams, entering match results, and displaying league rankings. Below are the key highlights:

  - **MVC Architecture**: The project is structured using the **Model-View-Controller** pattern, which separates the application into three interconnected components. This ensures a clean and maintainable codebase.
    - **Model**: Handles the data logic, including players, teams, and league rankings.
    - **View**: Manages the user interface, displaying menus and receiving input.
    - **Controller**: Acts as the intermediary between the model and the view, handling the application logic.

  - **Player and Team Management**: The system allows users to register players and assign them to teams. Each player's scores are tracked, and teams are ranked based on their average scores.

  - **Match Results**: Users can enter match results for individual players, updating their scores and contributing to their team's overall performance.

  - **League Rankings**: The system calculates and displays the league rankings based on the average scores of each team. This provides a clear overview of team performance throughout the league.

  - **User-Friendly Interface**: A menu-driven interface makes it easy for users to navigate the system, register players and teams, enter results, and view rankings. This ensures a smooth and intuitive user experience.

  This project was a great opportunity to practice implementing the **MVC architecture** in Python, as well as reinforcing concepts like data management, user interaction, and modular design. It also provided a practical application for managing sports leagues, making it both a learning experience and a useful tool.
* Day 350: 🔢 Recursive Number to Words Converter in Python 🧮

  Today, I worked on a **Recursive Number to Words Converter** in Python. This project focuses on converting a given number (e.g., `123`) into its word representation (e.g., "one hundred twenty-three") using recursion. The implementation is designed to handle numbers up to the billions range, making it a versatile tool for number-to-text conversion. Below are the key highlights:

  - **Recursive Logic**: The core of the project is a recursive function that breaks down the number into smaller parts (units, tens, hundreds, thousands, etc.) and combines their word representations. This approach ensures clean and modular code.

  - **Base Cases**: The function handles base cases for numbers less than 20, numbers between 20 and 99, and numbers in the hundreds, thousands, millions, and billions ranges. Each case is processed recursively to build the final word representation.

  - **Word Representations**: The project uses predefined lists (`units` and `tens`) to store word representations for numbers 0-19 and multiples of 10 (20, 30, ..., 90). These lists are used to construct the final output efficiently.

  - **Scalability**: The function is designed to handle large numbers (up to billions) by recursively processing higher ranges (thousands, millions, billions) and appending the appropriate scale words.

  - **Example Usage**: The project includes an example that converts the number `123456789` into its word representation: "one hundred twenty-three million four hundred fifty-six thousand seven hundred eighty-nine."

  This project was a great exercise in understanding recursion and how it can be applied to solve real-world problems like number-to-text conversion. It also reinforced my understanding of string manipulation and modular programming in Python.
* Day 351: Technical Test "findLadders" and "findLaddersI" [LeetCode](https://leetcode.com/problems/)

  - **findLadders**: Implemented a solution for the "Word Ladder II" problem, where the task is to find all the shortest transformation sequences from a `beginWord` to an `endWord` using a dictionary `wordList`. Each transformation must change exactly one letter at a time, and every intermediate word must exist in the `wordList`. The solution uses Breadth-First Search (BFS) to explore all possible paths and returns the shortest ones. The time complexity is O(M^2 * N), where M is the length of each word and N is the number of words in the `wordList`.
    [Problem Description: findLadders](https://leetcode.com/problems/word-ladder-ii/description/)

  - **findLaddersI**: Solved the "Word Ladder" problem, which involves finding the length of the shortest transformation sequence from `beginWord` to `endWord` using a dictionary `wordList`. Each transformation must change exactly one letter at a time, and every intermediate word must exist in the `wordList`. The solution uses Breadth-First Search (BFS) to efficiently find the shortest path. The time complexity is O(M^2 * N), where M is the length of each word and N is the number of words in the `wordList`.
    [Problem Description: findLaddersI](https://leetcode.com/problems/word-ladder/description/)
* Day 352: 🔒 SSL Certificate Checker in Python 🌐

  Today, I worked on an SSL Certificate Checker tool using Python, which allows users to verify the validity and expiration dates of SSL certificates for any given website. The project combines Python's `ssl` and `socket` libraries with a modern graphical user interface (GUI) built using `tkinter`. Below are the key highlights:

  - **SSL Certificate Retrieval**: The tool retrieves SSL certificate information, including the issuer, subject, and expiration date, by establishing a secure connection to the specified domain. This is done using Python's `ssl` and `socket` libraries, ensuring accurate and reliable results.

  - **Error Handling**: Robust error handling ensures that the tool gracefully handles invalid domains, connection issues, or missing certificates, providing clear and user-friendly error messages.

  - **Expiration Check**: The tool calculates the remaining days until the certificate's expiration and displays whether the certificate is still valid or has already expired. This feature is particularly useful for system administrators and developers who need to monitor SSL certificates.

  - **Modern Dark Theme UI**: The graphical interface is designed with a dark theme (`#2E3440` background) for better readability and a sleek appearance. Buttons and text fields are styled with contrasting colors (`#5E81AC` for buttons and `#D8DEE9` for text) to enhance user experience.

  - **User-Friendly Interaction**: The interface includes an input field for the domain, a "Check SSL Certificate" button, and a text area to display the results. This makes the tool intuitive and easy to use, even for non-technical users.

  - **Practical Application**: This tool is ideal for monitoring SSL certificates, ensuring websites are secure, and avoiding potential security risks caused by expired certificates. It demonstrates the practical use of Python for network security tasks.

  This project was a great opportunity to explore Python's capabilities in network programming and GUI development. It also reinforced my understanding of SSL/TLS protocols and how certificates work in securing web communications. The combination of functionality and a polished user interface makes this tool a valuable addition to my portfolio.
* Day 353: 🌐 WHOIS Lookup Tool in Python 🔍

    Today, I worked on a WHOIS Lookup Tool using Python, which retrieves domain registration information and checks the legitimacy of websites. The project focuses on integrating APIs, validating user input, and creating a user-friendly graphical interface. Below are the key highlights:

    - **WHOIS Lookup**: The tool uses the `python-whois` library to retrieve domain registration details such as the registrar, creation date, expiration date, and name servers. This provides valuable insights into the ownership and history of a domain.

    - **Website Legitimacy Check**: The tool sends an HTTP request to the website to verify if it is live and accessible. This helps users determine if the website is operational or potentially fraudulent.

    - **Input Validation**: A domain validation function ensures that the user-provided domain follows the correct format using regular expressions. This prevents errors and ensures accurate results.

    - **Graphical User Interface (GUI)**: The tool features a modern and user-friendly interface built with `tkinter`. The dark-themed design (`#2E3440` background) and colorful buttons (`#81A1C1` for lookup, `#A3BE8C` for export) enhance the user experience.

    - **Export Functionality**: Users can export the WHOIS information to a text file for offline reference. This feature is implemented using `filedialog`, making it easy to save and share results.

    - **Error Handling**: The tool gracefully handles errors, such as invalid domains or failed WHOIS lookups, and displays user-friendly error messages using `messagebox`.

    - **Practical Use Cases**: This tool is ideal for verifying domain ownership, checking expiration dates, and ensuring the legitimacy of websites. It’s a valuable addition to any developer’s toolkit for cybersecurity and domain management tasks.

    This project was a great opportunity to explore domain-related APIs, improve my skills in GUI development, and create a practical tool that can be used in real-world scenarios. I also gained a deeper understanding of input validation and error handling, ensuring the tool is robust and reliable.
* Day 354: 🔥 Simple Firewall Application in Python 🛡️

  Today, I worked on a **Simple Firewall Application** using Python, designed to filter incoming and outgoing network traffic based on predefined rules. This project focuses on creating a basic yet functional firewall that can be extended for more advanced use cases. Below are the key highlights:

  - **Rule-Based Filtering**: The firewall filters traffic based on predefined rules, which include direction (`incoming` or `outgoing`), protocol (`TCP` or `UDP`), and port number. Each rule specifies whether to `allow` or `block` the traffic.

  - **Dynamic Rule Management**: The system allows for dynamic addition and removal of rules during runtime. Rules can also be saved to and loaded from a JSON file, making it easy to persist configurations across sessions.

  - **Logging**: All firewall actions (e.g., allowed or blocked traffic) are logged to a file (`firewall.log`) for auditing and monitoring purposes. This ensures transparency and helps in troubleshooting.

  - **IP-Based Filtering**: The firewall supports filtering traffic based on IP addresses, allowing for more granular control over network traffic.

  - **Simulated Traffic**: A traffic simulation function demonstrates how the firewall processes different types of network traffic, including HTTP, HTTPS, SSH, and custom ports like 8080.

  - **Extensibility**: The project is designed to be easily extended. For example, support for additional protocols (e.g., UDP) or integration with real network interfaces can be added in the future.

  This project was a great opportunity to explore network traffic filtering and rule-based systems. It reinforced my understanding of how firewalls operate and how to implement basic security mechanisms in Python. The modular design ensures that the system is maintainable and scalable for future enhancements.
* Day 355: 🏀 Basketball Player Stats Analyzer in Python 🏀

  Today, I worked on a **Basketball Player Stats Analyzer** using Python, with a focus on leveraging less commonly used but powerful Python functions like `enumerate()`, `itertools.groupby`, `collections.Counter`, and `functools.reduce`. The project analyzes player statistics such as points, rebounds, and assists, providing insights into player performance. Below are the key highlights:

  - **`enumerate()`**: Used to display player stats with their rank, making it easy to see how players compare to one another. This function adds a ranking system to the output, enhancing readability.

  - **`itertools.groupby`**: Groups players by their points range (e.g., 25-30, 30-35), allowing for a quick overview of how players are distributed across different performance levels.

  - **`collections.Counter`**: Counts the frequency of rebounds among players, providing a clear picture of how often specific rebound numbers occur in the dataset.

  - **`functools.reduce`**: Calculates the total points scored by all players, demonstrating how to aggregate data efficiently using functional programming techniques.

  - **`collections.defaultdict`**: Creates a dictionary of player stats for easy lookup, showcasing how to organize and access data in a structured way.

  - **Data Visualization**: The project includes a function to plot player stats using `matplotlib`, providing a visual comparison of points, rebounds, and assists for each player.

  - **Persistent Data**: The program can save and load player stats from a JSON file, ensuring data persistence and making it easy to update and reuse the dataset.

  - **Advanced Filtering**: Players are filtered based on their performance (e.g., high scorers with more than 25 points per game), allowing for targeted analysis of top performers.

  This project was an excellent exercise in exploring Python’s less commonly used functions and libraries. I gained a deeper understanding of how tools like `itertools`, `collections`, and `functools` can simplify complex tasks and make code more efficient. Additionally, the integration of data visualization and persistent storage makes this a practical tool for analyzing basketball player stats.
* Day 356: 🚗 Car Maintenance Tracker in Python 🛠️

  Today, I worked on a **Car Maintenance Tracker** using Python, with a focus on Object-Oriented Programming (OOP) principles such as encapsulation, abstraction, and the Model-View-Controller (MVC) design pattern. The project allows users to track vehicle maintenance records, add new vehicles, and visualize maintenance data using **Matplotlib**. Below are the key highlights:

  - **Encapsulation**: The `CarMaintenanceModel` class encapsulates attributes like `vehicles` and `maintenance_records`, ensuring that data is protected and accessed only through controlled methods. This ensures data integrity and security.

  - **Abstraction**: The `CarMaintenanceView` class abstracts the user interface, providing a clear separation between the user interaction and the underlying logic. This makes the system easy to extend and maintain.

  - **MVC Design Pattern**: The project follows the **Model-View-Controller** pattern, where:
    - **Model**: Manages the data and business logic (`CarMaintenanceModel`).
    - **View**: Handles the user interface and data visualization (`CarMaintenanceView`).
    - **Controller**: Acts as the intermediary between the Model and View (`CarMaintenanceController`).

  - **Vehicle Management**: Users can add new vehicles to the system, including details like `make`, `model`, and `year`. This ensures that all vehicles are properly registered and tracked.

  - **Maintenance Records**: The system allows users to add maintenance records for each vehicle, including details like `service_type`, `date`, and `description`. This makes it easy to keep track of all maintenance activities.

  - **Data Visualization**: Using **Matplotlib**, the system provides a visual representation of maintenance data, showing the distribution of service types across all vehicles. This feature enhances the usability of the system by providing insights at a glance.

  - **Menu-Driven Interface**: A user-friendly menu allows for easy interaction with the system. Users can add vehicles, add maintenance records, view records, and visualize data with just a few simple steps.

  This project was an excellent exercise in applying OOP principles and the MVC design pattern to create a well-structured and maintainable system. I had the opportunity to refine my understanding of how encapsulation, abstraction, and separation of concerns work together to create clean and reusable code, all while building a practical car maintenance tracking tool.
* Day 357: 🏗️ Pyramid Block Counter and Visualizer in Python 🧱

  Today, I worked on a **Pyramid Block Counter and Visualizer** in Python. This project calculates how many complete levels of a pyramid can be built with a given number of blocks and also visualizes the pyramid structure using ASCII art. Below are the key highlights:

  - **Block Calculation**: The program calculates the number of complete levels that can be formed in a pyramid given a specific number of blocks. Each level of the pyramid is a square, and the number of blocks required for a level is the square of its level number (e.g., Level 1: 1 block, Level 2: 4 blocks, Level 3: 9 blocks, etc.).

  - **Efficient Logic**: The program uses a `while` loop to iteratively determine the maximum number of levels. It subtracts the blocks used for each level from the total until there are no longer enough blocks to form the next level.

  - **Visualization**: The program includes a function to draw the pyramid using ASCII art. Each level is represented by `[]` symbols, and the pyramid is centered by adding spaces before the blocks. This provides a clear and intuitive representation of the pyramid structure.

  - **User Interaction**: The program prompts the user to input the number of blocks and then displays both the number of complete levels and the pyramid visualization. If there are not enough blocks to build even a single level, it informs the user accordingly.

  - **Practical Application**: This project is a fun and practical way to explore mathematical concepts (like squares and iterative calculations) while also practicing Python programming skills, such as loops, conditionals, and string manipulation.

  This project was a great exercise in combining mathematical logic with creative visualization. It reinforced my understanding of iterative problem-solving and provided an opportunity to create a visually appealing output using simple ASCII art.
* Day 358: 🌹 International Women's Day Tribute with Python Turtle 🐢

  Today, I created a beautiful tribute for International Women's Day using Python's `turtle` module. The project features a rose, a stem with leaves, and an inspirational message: "The best curve of a woman is her smile." Below are the key highlights:

  - **Rose Drawing**: Using the `turtle` module, I drew a six-petaled rose with vibrant red petals. The `draw_petal` function creates each petal, and the `draw_rose` function assembles them into a complete flower.

  - **Stem and Leaves**: The `draw_stem` function adds a green stem and two leaves to the rose, making it more realistic and visually appealing. The leaves are filled with green color using `begin_fill` and `end_fill`.

  - **Inspirational Message**: The `draw_message` function displays the message "The best curve of a woman is her smile" at the top of the screen in bold black text. This adds a meaningful touch to the project.

  - **Modular Design**: The code is organized into separate functions (`draw_petal`, `draw_rose`, `draw_stem`, and `draw_message`), making it easy to understand, maintain, and extend in the future.

  - **User-Friendly**: The program runs smoothly, displaying the rose, stem, leaves, and message in a single window with a light pink background. It’s a simple yet powerful way to celebrate women and their contributions.

  This project was a wonderful opportunity to combine creativity with programming. Using Python's `turtle` module, I was able to create a visual tribute that not only looks beautiful but also carries a meaningful message. It’s a reminder of the importance of celebrating and appreciating women every day.
* Day 359: Technical Test "longestConsecutive" and "sumNumbers" [LeetCode](https://leetcode.com/problems/)

  - **longestConsecutive**: Implemented a solution for the "Longest Consecutive Sequence" problem, where the task is to find the length of the longest sequence of consecutive elements in an unsorted array of integers. The solution uses a hash set to achieve O(n) time complexity by checking for the start of sequences and then calculating their lengths. The approach ensures efficient traversal and avoids unnecessary computations.
    [Problem Description: longestConsecutive](https://leetcode.com/problems/longest-consecutive-sequence/description/)

  - **sumNumbers**: Solved the "Sum Root to Leaf Numbers" problem, which involves calculating the total sum of all root-to-leaf numbers in a binary tree. Each root-to-leaf path represents a number, and the solution uses a depth-first search (DFS) approach to traverse the tree, construct the numbers, and sum them up. The time complexity is O(N), where N is the number of nodes in the tree.
    [Problem Description: sumNumbers](https://leetcode.com/problems/sum-root-to-leaf-numbers/description/)
* Day 360: 🔒 Web Application Security Scanner in Python 🛡️

  Today, I worked on a **Web Application Security Scanner** using Python, designed to identify common vulnerabilities in web applications, such as Cross-Site Scripting (XSS), Cross-Site Request Forgery (CSRF), SQL Injection (SQLi), and exposed files or directories. The project combines web scraping, vulnerability testing, and a user-friendly graphical interface to provide a comprehensive security assessment tool. Below are the key highlights:

  - **XSS Scanning**: The scanner injects a simple JavaScript payload (`<script>alert('XSS')</script>`) into all text input fields of forms on the target page. If the payload is reflected in the response, it indicates a potential XSS vulnerability.

  - **CSRF Scanning**: The scanner checks if forms on the target page contain a CSRF token. If no CSRF token is found, it indicates a potential CSRF vulnerability.

  - **SQL Injection Scanning**: The scanner tests for SQL Injection vulnerabilities by injecting a common SQL payload (`' OR '1'='1`) into input fields. If the response contains SQL-related errors, it indicates a potential SQLi vulnerability.

  - **Exposed Files and Directories**: The scanner checks for common exposed files and directories, such as `robots.txt`, `sitemap.xml`, `.env`, and `config.php`. If these files are accessible, they may reveal sensitive information about the application.

  - **Graphical User Interface (GUI)**: The project includes a modern and user-friendly GUI built with `tkinter`. The interface features a dark theme, colorful buttons, and a scrollable text area to display scan results in real-time.

  - **Error Handling**: The scanner includes robust error handling to ensure that unexpected issues (e.g., network errors or invalid URLs) do not crash the program. Errors are logged and displayed to the user.

  - **Report Generation**: After the scan, the tool generates a detailed report of all vulnerabilities found and saves it to a file (`vulnerability_report.txt`). This makes it easy to share and review the results.

  - **Practical Use Case**: This tool is designed to be a practical and educational resource for identifying vulnerabilities in web applications. It demonstrates how to combine web scraping, vulnerability testing, and GUI development into a single project.

  This project was an excellent exercise in web security, GUI development, and Python programming. It allowed me to explore the importance of securing web applications and provided hands-on experience with vulnerability testing techniques. The integration of a graphical interface makes the tool accessible and user-friendly, while the underlying functionality ensures it remains a powerful security assessment tool.
* Day 361: 🛒 Price Notifier System in Python 💰

  Today, I worked on a **Price Notifier System** using Python, designed to monitor product prices from various online stores. The system allows users to track products, set desired prices, and receive notifications when prices drop below a specified threshold. Below are the key highlights:

  - **Web Scraping**: The system uses the `requests` and `BeautifulSoup` libraries to scrape product prices from URLs provided by the user. It supports custom CSS selectors for extracting prices from different websites, ensuring flexibility across various e-commerce platforms.

  - **Price Tracking**: Users can add products to a monitored list, specifying the product name, URL, desired price, and optional CSS selectors. The system periodically checks the current price of each product and updates its history.

  - **Price History**: Each product maintains a history of price changes, allowing users to track price trends over time. The history is limited to the last 30 entries to keep the data manageable.

  - **User-Friendly CLI**: The system features a command-line interface (CLI) that allows users to:
    - Add new products to monitor.
    - View the list of monitored products and their current prices.
    - Update product prices in real-time.
    - Remove products from the monitoring list.

  - **Customizable Decimal Separator**: The system supports both `.` and `,` as decimal separators, making it adaptable to different regional price formats.

  - **JSON Storage**: All monitored products and their data are stored in a JSON file (`monitored_products.json`), ensuring persistence between program runs. This makes it easy to manage and extend the system.

  This project was a great opportunity to practice web scraping, file handling, and building a user-friendly CLI. I also deepened my understanding of how to structure Python projects for maintainability and scalability. The Price Notifier System is a practical tool for anyone looking to save money by tracking online product prices effectively.
* Day 362: 📅 Recursive Calendar Generator in Python 🗓️

  Today, I worked on a **Recursive Calendar Generator** using Python, with a focus on handling leap years, recursive functions, and user-friendly interactions. The project allows users to generate calendars for specific months or entire years, and it supports recursive prompts for continuous use. Below are the key highlights:

  - **Leap Year Handling**: The program includes a function to check if a given year is a leap year, ensuring accurate calendar generation for both leap and non-leap years.

  - **Recursive Functionality**: The `display_calendar` function is implemented recursively, allowing users to generate multiple calendars without restarting the program. This makes the system interactive and user-friendly.

  - **Monthly and Yearly Calendars**: Users can choose to generate a calendar for a specific month or an entire year. The program uses Python's built-in `calendar` module to format and display the calendars neatly.

  - **Input Validation**: The program validates user inputs, such as ensuring the month is within the valid range (1-12). If invalid input is provided, the program prompts the user again, ensuring robustness.

  - **Flexible Formatting**: The calendar is displayed in a clean and readable format, making it easy for users to view and understand.

  - **User Interaction**: The program prompts users to decide whether they want to generate another calendar or exit, providing a seamless and intuitive experience.

  This project was a great opportunity to explore recursive programming and calendar manipulation in Python. I deepened my understanding of how to handle edge cases (like leap years) and create interactive, reusable code. The Recursive Calendar Generator is a practical tool that can be extended with additional features, such as custom formatting or integration with other applications.
* Day 363: 🔐 Caesar Cipher GUI in Python 🖥️

  Today, I worked on a **Caesar Cipher GUI** application using Python and the `tkinter` library. This project allows users to encrypt and decrypt text using the Caesar Cipher algorithm, providing an intuitive and visually appealing interface. Below are the key highlights:

  - **Graphical User Interface (GUI)**: The application features a clean and modern dark-themed interface, built with `tkinter`. It includes input fields for plaintext, ciphertext, and the encryption key, as well as buttons for encryption, decryption, and clearing fields.

  - **Caesar Cipher Algorithm**: The core functionality of the application is the implementation of the Caesar Cipher algorithm. It supports both uppercase and lowercase letters while preserving special characters and spaces. The algorithm shifts each letter by a specified key value, making it a classic example of substitution-based encryption.

  - **Input Validation**: The application includes robust input validation to ensure the key is a valid integer between 1 and 25. If the user enters an invalid key or leaves a required field empty, the program displays user-friendly error messages.

  - **File Handling**: Users can open text files to load plaintext or ciphertext directly into the application. They can also save the encrypted or decrypted results to a file, making it easy to work with external data.

  - **Brute Force Decryption**: For cases where the key is unknown, the application includes a **Brute Force** feature. It attempts to decrypt the ciphertext using all possible keys (1–25) and displays the results in a new window. This is particularly useful for cracking simple Caesar Cipher codes.

  - **Menu Bar**: The application includes a menu bar with **File** and **Help** options. Users can open and save files, as well as access an **About** dialog for information about the program.

  - **User-Friendly Design**: The interface is designed with user experience in mind. Buttons are color-coded for clarity, and the dark theme reduces eye strain during prolonged use. Tooltips and clear labels guide users through the process.

  This project was a great opportunity to combine my knowledge of encryption algorithms with GUI development. I gained experience in creating interactive applications with `tkinter`, handling file I/O, and implementing input validation. The Caesar Cipher GUI is a practical tool for learning about encryption and can be easily extended with additional features in the future.
* Day 364: 🏀 Basketball Shot Clock in Python ⏱️

  Today, I worked on a **Basketball Shot Clock** application using Python, with a focus on creating an interactive and user-friendly interface for basketball training sessions. The project allows users to simulate a shot clock, track player scores, and manage a multiplayer competition. Below are the key highlights:

  - **Interactive Shot Clock**: The application features a countdown timer that starts at 24 seconds, simulating a real basketball shot clock. Users can start, pause, and reset the timer with ease.

  - **Multiplayer Mode**: Players can be added dynamically, and their scores are tracked in real-time. The system allows users to increment scores for each player, making it ideal for competitive training sessions.

  - **Winner Announcement**: When the shot clock reaches zero, the application announces the winner based on the highest score. If a player reaches 10 points, they are declared the champion.

  - **Score Management**: The system provides a clear and intuitive interface for tracking player scores. Each player has a dedicated button to increment their score, ensuring smooth and efficient scorekeeping.

  - **Save Statistics**: The application allows users to save player statistics to a CSV file, making it easy to review and analyze performance over time.

  - **User-Friendly Interface**: The interface is designed with a dark theme for a modern look, featuring green buttons with black text for clear visibility and ease of use. The shot clock animation provides a visual representation of the remaining time.

  This project was an excellent exercise in creating a practical and interactive tool for basketball training. I had the opportunity to refine my skills in GUI development using `tkinter`, as well as implementing features like threading for the countdown timer and file handling for saving statistics. The result is a versatile and user-friendly application that can be used in real-world training scenarios.
* Day 365: Comprehensive Data Analysis Portfolio 📊

  Today, I completed my final project for the year: a **Comprehensive Data Analysis Portfolio** built using Python, Streamlit, and various data visualization libraries. This project serves as a culmination of everything I've learned over the past 365 days, showcasing my skills in data analysis, visualization, and interactive dashboard development. Below are the key highlights:

  - **Interactive Dashboard**: The portfolio is powered by Streamlit, providing an interactive web-based dashboard. Users can filter activities by date range and categories, view detailed statistics, and explore visualizations such as bar charts, word clouds, and Gantt charts.

  - **Data Visualization**: I used Plotly and Seaborn to create dynamic and insightful visualizations, including:
    - **Activity Distribution by Category**: A bar chart showing the frequency of activities in each category.
    - **Monthly Productivity Trends**: A line chart with a regression line to analyze productivity trends over the year.
    - **Activity Timeline (Gantt Chart)**: A Gantt chart visualizing the distribution of activities over time.

  - **Advanced Analytics**:
    - **Trend Analysis**: I applied linear regression to analyze monthly productivity trends, identifying patterns and forecasting future activity levels.
    - **Weekday Distribution**: A bar chart showing the distribution of activities by day of the week, helping to identify the most productive days.

  - **Export Functionality**:
    - **PDF Reports**: Users can generate a PDF report summarizing key statistics and visualizations, making it easy to share insights.
    - **Data Export**: The portfolio allows downloading filtered data as a CSV file and visualizations as PNG images for further analysis.

  - **Object-Oriented Design**:
    - **Encapsulation**: The `Activity` class encapsulates attributes like `date`, `category`, and `description`, ensuring data integrity and controlled access.
    - **Modular Code**: The project is structured into reusable functions and classes, making it easy to extend and maintain.

  - **User-Friendly Interface**:
    - The dashboard features a clean and intuitive design, with filters for date range and categories, making it easy for users to explore the data.
    - A word cloud provides a quick overview of the most frequent keywords in activity descriptions.

  This project represents a significant milestone in my journey, combining technical skills, creativity, and practical application. It not only demonstrates my ability to analyze and visualize data but also highlights my proficiency in building interactive and user-friendly tools. I'm proud of how far I've come and excited to continue growing as a data professional.
* Day 366: 🌌 Wave Function Collapse Simulator in Python 🌀

  Today, I worked on a **Wave Function Collapse Simulator** inspired by quantum mechanics, using Python and recursion. This project models the collapse of a wave function into one of its possible states, demonstrating how quantum systems transition from superposition to a definite state. Below are the key highlights:

  - **Quantum System Representation**: The `QuantumSystem` class represents a quantum system with a set of possible states and their probabilities. Each state is defined as a tuple containing the state name and its probability.

  - **Probability Normalization**: The system ensures that the probabilities of all states sum to 1 using the `normalize_probabilities` method. This is crucial for accurately simulating the collapse process.

  - **Wave Function Collapse**: The `collapse_wave_function` method simulates the collapse of the wave function into one of the possible states. It uses recursion to explore the probability distribution and determine the final state based on a random value.

  - **Recursive State Selection**: The `_recursive_collapse` method recursively checks the cumulative probabilities of the states to determine which state is selected. This approach elegantly handles the probability-based selection process.

  - **User-Friendly Output**: The system provides a clear string representation of the quantum system, showing both the uncollapsed states with their probabilities and the final collapsed state.

  - **Example Usage**: The program includes an example of a quantum system with three states ("State A", "State B", "State C") and their respective probabilities. It demonstrates the collapse process and outputs the result.

  This project was a fascinating exploration of quantum mechanics concepts and recursion in Python. It allowed me to deepen my understanding of probability-based simulations and recursive algorithms while creating a simple yet powerful quantum system simulator.
* Day 367: 🏦 Banking System in Python 💰

  Today, I worked on a **Banking System** using Python, with a focus on Object-Oriented Programming (OOP) principles such as inheritance, encapsulation, and abstraction. The project allows users to create accounts, perform transactions, manage balances, and visualize financial data. Below are the key highlights:

  - **Encapsulation**: The `Account` class encapsulates attributes like `account_number`, `balance`, and `customer_name`, ensuring that sensitive information is protected. Controlled access is provided through methods like `deposit`, `withdraw`, and `get_balance`.

  - **Inheritance**: The system uses inheritance to differentiate between `SavingsAccount` and `CheckingAccount`, both derived from the `Account` class. This allows reusability of common attributes (like `account_number` and `balance`) while providing specialized functionality for each account type, such as interest calculation for savings accounts.

  - **Abstraction**: The `Account` class provides a consistent interface for operations like deposits and withdrawals, while the `Bank` class abstracts the management of multiple accounts, making the system easy to extend with new features in the future.

  - **Transaction Management**: The system tracks all transactions (deposits and withdrawals) for each account, allowing users to view their transaction history. This ensures transparency and helps users keep track of their financial activities.

  - **Visualization**: Using `matplotlib`, the system provides visual representations of account balances and transaction histories. Users can view pie charts for balance distribution, bar charts for transaction types, and line charts for balance trends over time.

  - **User-Friendly Interface**: A menu-driven interface allows users to interact with the system easily. Features include creating accounts, depositing funds, withdrawing funds, transferring money between accounts, applying interest, and deleting accounts.

  - **Error Handling**: The system includes robust error handling to ensure smooth operation. Clear error messages are displayed for invalid inputs or failed operations, improving the user experience.

  This project was an excellent exercise in applying OOP principles to create a well-structured and maintainable system. I had the opportunity to refine my understanding of how abstraction, encapsulation, and inheritance work together to create clean and reusable code, all while building a practical banking tool.
* Day 368: 📈 Time Series Forecasting with LSTM in Python 🕒

  Today, I worked on a Time Series Forecasting project using Python, focusing on building an LSTM (Long Short-Term Memory) model to predict future values based on historical data. The project involves loading, preprocessing, and modeling time series data to forecast a full week of values in 2-hour intervals. Below are the key highlights:

  - **Data Loading and Preprocessing**: The dataset was loaded from a CSV file, and the `date` column was converted to a datetime format for proper time series handling. The data was normalized using `MinMaxScaler` to ensure all features are on the same scale, which is crucial for LSTM models.

  - **Sequence Creation**: Historical data for a full day (24 hours) was used as input, and the model was trained to predict a full week of data in 2-hour intervals (84 data points). This was achieved by creating sequences of input-output pairs using a sliding window approach.

  - **Model Architecture**: An LSTM-based model was built using TensorFlow/Keras. The model consists of an LSTM layer with 50 units, followed by a Dense layer to produce the output. A `Reshape` layer was added to ensure the output matches the required shape for the forecast horizon.

  - **Training and Evaluation**: The model was trained for 20 epochs using the Adam optimizer and Mean Squared Error (MSE) as the loss function. The training process included validation on a test set to monitor performance. After training, the model was evaluated using metrics such as MAE (Mean Absolute Error), MSE, and RMSE (Root Mean Squared Error).

  - **Results Visualization**: The actual vs. predicted values were plotted to visually assess the model's performance. This step is crucial for understanding how well the model captures the underlying patterns in the data.

  - **Modular Code Structure**: The project was implemented using a modular approach, with each step (data loading, preprocessing, model building, training, evaluation, and visualization) encapsulated in separate functions. This makes the code reusable, maintainable, and easy to extend for future improvements.

  This project was an excellent opportunity to dive deep into time series forecasting and understand the power of LSTM models for sequential data. I gained hands-on experience in data preprocessing, model building, and evaluation, all while creating a practical tool for forecasting future values in a time series dataset.
* Day 369: 🎤 Speech-to-Text Transcription with Wav2Vec2 🎧

  Today, I worked on a Speech-to-Text Transcription system using the Wav2Vec2 model from Hugging Face's Transformers library. The project focuses on loading audio data, transcribing it into text, and saving the transcriptions to a file. Below are the key highlights:

  - **Dataset Loading**: The project starts by loading an audio dataset from Hugging Face's dataset hub. Specifically, the dataset used is `charris/hubert_process_filter_spotify`, which contains audio files that are processed and filtered for transcription tasks.

  - **Audio Selection**: A function is provided to select a specified number of audio files from the dataset. This allows for flexibility in choosing how many files to transcribe, making the system adaptable to different use cases.

  - **Model and Processor Loading**: The Wav2Vec2 model and its corresponding processor are loaded using the `transformers` library. The model used is `facebook/wav2vec2-large-960h`, which is pre-trained on a large corpus of speech data and is well-suited for speech-to-text tasks.

  - **Audio Transcription**: The core functionality of the project is the transcription of audio files into text. The `transcribe_audio` function preprocesses the audio, passes it through the Wav2Vec2 model to obtain logits, and then decodes these logits into human-readable text.

  - **Transcription Saving**: Once the audio files are transcribed, the results are saved to a text file named `transcriptions.txt`. This file contains the transcriptions of each audio file, making it easy to review and analyze the results.

  - **Automated Workflow**: The entire process is automated in the `if __name__ == "__main__":` block, which sequentially loads the dataset, selects audio files, loads the model and processor, transcribes the audio, and saves the transcriptions. This makes the system easy to run with minimal user intervention.

  This project was a great opportunity to explore the capabilities of the Wav2Vec2 model for speech-to-text tasks. It also reinforced my understanding of working with Hugging Face's datasets and transformers libraries, as well as handling audio data in Python. The system is practical and can be extended to handle larger datasets or different models in the future.
* Day 370: Technical Test "Surrounded Regions" and "Palindrome Partitioning" [LeetCode](https://leetcode.com/problems/)

  - **Surrounded Regions**: Implemented a solution for the "Surrounded Regions" problem, where the task is to capture all regions surrounded by 'X' in an `m x n` matrix. A region is captured by flipping all 'O's into 'X's in that region. The solution uses a Depth-First Search (DFS) approach to mark all 'O's connected to the border as safe (using a temporary marker 'T'). After processing, it replaces all remaining 'O's with 'X's and restores the safe 'O's. The time complexity is O(m * n), where `m` is the number of rows and `n` is the number of columns in the matrix.
    [Problem Description: Surrounded Regions](https://leetcode.com/problems/surrounded-regions/description/)

  - **Palindrome Partitioning**: Solved the "Palindrome Partitioning" problem, which involves partitioning a string such that every substring in the partition is a palindrome. The solution uses a backtracking approach with Depth-First Search (DFS) to explore all possible partitions. For each substring, it checks if it is a palindrome and recursively partitions the remaining string. The time complexity is O(N * 2^N), where `N` is the length of the string, as there are 2^N possible partitions in the worst case, and each partition requires O(N) time to check for palindromes.
    [Problem Description: Palindrome Partitioning](https://leetcode.com/problems/palindrome-partitioning/description/)
* Day 371: 🌐 Recursive Voronoi Diagram Generator in Python 🖼️

  Today, I worked on a **Recursive Voronoi Diagram Generator** using Python. This project focuses on generating Voronoi diagrams recursively by dividing the space into regions based on randomly generated points. The implementation leverages libraries like `numpy`, `matplotlib`, and `scipy.spatial` to create visually appealing diagrams. Below are the key highlights:

  - **Random Point Generation**: The `generate_random_points` function creates a set of random points within specified x and y limits. These points serve as the generators for the Voronoi regions.

  - **Recursive Voronoi Generation**: The `recursive_voronoi` function recursively generates Voronoi diagrams. It starts with an initial set of points, computes the Voronoi diagram, and then generates new points within each region to continue the recursion. This process continues until the specified recursion depth is reached.

  - **Region Handling**: The algorithm ensures that only valid regions are processed. It skips empty or degenerate regions (those with zero width or height) to avoid errors and maintain smooth execution.

  - **Visualization**: Each step of the recursion is visualized using `matplotlib`. The Voronoi diagram is plotted with clear boundaries, and the title indicates the current recursion depth, making it easy to follow the recursive process.

  - **Flexibility**: The program allows customization of parameters such as the number of initial points, recursion depth, and the x and y limits of the space. This makes it adaptable to different scenarios and use cases.

  - **Practical Applications**: Voronoi diagrams have applications in various fields, including computer graphics, geographic information systems (GIS), and even biology. This project serves as a foundation for exploring these applications further.

  This project was a great opportunity to deepen my understanding of computational geometry and recursive algorithms. It also allowed me to practice working with visualization libraries like `matplotlib` and `scipy.spatial` to create dynamic and interactive outputs.
* Day 372: 👵 ElderlyCare – Health and Medication Monitoring System in Python 🩺

  Today, I worked on **ElderlyCare**, a system designed to monitor the health and medication history of elderly individuals. This project was built using the **Model-View-Controller (MVC)** architectural pattern, ensuring a clean separation of concerns and making the system modular, scalable, and easy to maintain. Below are the key highlights:

  - **MVC Architecture**: The system is divided into three main components:
    - **Model**: Handles the data logic, including the management of elderly persons and their medication records.
    - **View**: Manages the user interface, displaying menus and information to the user in an intuitive way.
    - **Controller**: Acts as the intermediary between the Model and the View, processing user inputs and updating the system state.

  - **Elderly Person Management**: The system allows users to add elderly individuals with details such as name, age, and health condition. Each person is stored as an instance of the `ElderlyPerson` class, ensuring data encapsulation and organization.

  - **Medication History Tracking**: For each elderly person, the system supports adding and viewing medication records, including details like medication name, dosage, and date. This feature is crucial for caregivers to monitor and manage the health of elderly individuals effectively.

  - **User-Friendly Menu**: The system features an intuitive menu-driven interface, making it easy for users to navigate and perform actions such as adding elderly persons, viewing their details, and managing medication records.

  - **Scalability**: The use of MVC and object-oriented principles makes the system highly scalable. New features, such as reminders for medication or integration with health devices, can be added without disrupting the existing codebase.

  - **Practical Application**: This project is not just a coding exercise but a practical tool that could be used in real-world scenarios, such as nursing homes or by family members caring for elderly relatives.

  This project was an excellent opportunity to deepen my understanding of the MVC pattern and how it can be applied to create structured and maintainable systems. I also gained valuable experience in designing user-friendly interfaces and managing complex data relationships in Python.
* Day 373: 🌿 3D L-System Algorithm in Python 🐢

  Today, I worked on a 3D L-System algorithm in Python, which generates complex 3D graphics using recursive rules. L-Systems (Lindenmayer Systems) are a type of formal grammar used to model the growth processes of plants and other natural structures. This project focuses on expanding L-Systems into three dimensions, creating visually stunning fractal-like structures. Below are the key highlights:

  - **L-System Rules**: The system starts with an initial string (axiom) and applies replacement rules iteratively to generate a final string. These rules define how the structure grows and branches, simulating natural patterns.

  - **Recursive Expansion**: The `apply_rules` function handles the recursive expansion of the axiom based on the provided rules. This allows for the creation of intricate and detailed structures with just a few iterations.

  - **3D Graphics Rendering**: Using the `turtle` library, the program interprets the generated string to draw a 3D-like structure. The turtle moves forward, turns left or right, and handles branching using a stack-based approach to save and restore its state.

  - **Branching and Stack Management**: The system supports branching through the use of square brackets (`[` and `]`). When encountering `[`, the turtle's current state (position and heading) is saved to a stack. When encountering `]`, the state is restored, allowing the turtle to return to a previous position and continue drawing.

  - **Customizable Parameters**: The program allows customization of the axiom, rules, number of iterations, turning angle, and distance. This flexibility makes it easy to experiment with different shapes and structures.

  - **Fractal-Like Structures**: The example rule provided (`F -> FF+[+F-F-F]-[-F+F+F]`) generates a fractal-like 3D structure, showcasing the power of L-Systems in creating complex and organic patterns.

  This project was a fascinating exploration of how mathematical rules can be used to simulate natural growth processes and generate beautiful 3D graphics. It reinforced my understanding of recursion, string manipulation, and the use of stacks for managing state in graphical rendering.
* Day 374: 🌳 Lowest Common Ancestor in BST with Visualization 📊

  Today, I enhanced my Binary Search Tree (BST) project with a professional visualization system and improved architecture. The project now efficiently finds the Lowest Common Ancestor (LCA) between any two nodes in a BST while providing clear visual feedback. Here are the key highlights:

  - **BST Visualization**: Implemented a dynamic tree visualization using NetworkX and Matplotlib that automatically adjusts node positions based on tree depth. The visualization highlights searched nodes and their LCA in red for immediate understanding.

  - **Interactive Demo**: Created an interactive command-line interface where users can input any two node values to find their LCA. The system provides both textual results and visual confirmation with highlighted nodes.

  - **Modular Architecture**: Organized the code into specialized classes (BSTVisualizer, BSTOperations, LCADemo) following the Single Responsibility Principle. This makes the system more maintainable and easier to extend.

  - **Error Handling**: Added robust input validation to handle non-existent nodes and invalid inputs gracefully, improving user experience.

  - **Sample BST**: Pre-built a comprehensive BST structure with nodes [6, 2, 8, 0, 4, 7, 9, 3, 5] for demonstration purposes, showing all possible LCA scenarios.

  - **Clear Documentation**: Enhanced all classes and methods with detailed docstrings explaining their purpose and usage, making the codebase more accessible.

  This project significantly improved my understanding of tree algorithms and data visualization in Python. The interactive visualization component particularly helped solidify my comprehension of how LCAs work in BST structures by providing immediate visual feedback. The modular architecture also served as excellent practice in designing clean, maintainable systems.
* Day 375: 🌳 Mirror Binary Tree in Python 🔄  

  Today, I worked on a Mirror Binary Tree project in Python, focusing on recursive algorithms and tree visualization. The project takes a binary tree and inverts its structure to create a mirror image. Below are the key highlights:  

  - **Recursive Algorithm**: The `mirror_tree` function uses recursion to swap the left and right children of each node, effectively inverting the entire tree structure. This demonstrates the power of recursion in tree manipulation.  

  - **Tree Construction**: The `build_tree_from_list` function allows for easy tree creation from a level-order (BFS) list representation, making it simple to test different tree structures.  

  - **Visualization**: Using `networkx` and `matplotlib`, the project includes a visualization feature that clearly displays the original and mirrored trees, helping to verify the correctness of the algorithm.  

  - **Interactive Demo**: The script includes an interactive mode where users can input their own trees and see the mirroring effect in real-time, along with traversal outputs (inorder, preorder, postorder).  

  - **Clear Documentation**: Each function is well-documented with docstrings, and example usage is provided for better understanding.  

  This project was a great exercise in understanding tree structures, recursion, and visualization techniques. It reinforced my knowledge of binary tree operations and provided a practical way to see the mirroring effect visually.  
* Day 376: 🌳 Prefix Tree (Trie) for Name Search System 🔍

  Today, I developed an advanced Prefix Tree (Trie) implementation in Python for efficient name storage and retrieval, with special visualization capabilities. This system excels at finding partial matches in large name datasets while demonstrating core computer science concepts. Here are the key highlights:

  - **Trie Data Structure**: Implemented a classic trie structure with nodes containing character mappings and end-of-word markers, providing O(m) search time complexity (where m is prefix length).

  - **Visualization**: Added innovative graph visualization using `networkx` and `matplotlib` that:
    - Color-codes nodes (root in green, end nodes in red, others in blue)
    - Shows character labels on each node
    - Allows depth and children limits for large datasets

  - **Case-Insensitive Search**: Designed the system to store and search names in lowercase automatically, ensuring case-insensitive matching.

  - **Interactive Interface**: Created a comprehensive menu-driven demo with options to:
    - Load sample names or import from files
    - Search by prefix with sorted results
    - View all stored names
    - Visualize the trie structure
    - Display trie statistics

  - **Performance Metrics**: Implemented statistics tracking including:
    - Total names and nodes count
    - Average name length
    - Compression ratio showing space efficiency

  - **Practical Applications**: Demonstrated how tries excel at:
    - Autocomplete systems
    - Spell checkers
    - Contact name searches
    - Any scenario requiring prefix-based search

  This project deepened my understanding of tree data structures and graph visualization techniques. The interactive visualization particularly helped in comprehending how the trie grows and shares common prefixes among names, making it an excellent educational tool.
* Day 377: 🌳 Fenwick Tree (Binary Indexed Tree) Implementation in Python 

  Today I implemented a Fenwick Tree (also known as Binary Indexed Tree) in Python, a specialized data structure that efficiently maintains prefix sums and supports point updates in logarithmic time. The implementation includes visualization capabilities using matplotlib to better understand the tree structure. Here are the key highlights:

  - **Efficient Operations**: The Fenwick Tree supports O(log n) time complexity for both point updates and prefix sum queries, making it ideal for dynamic array problems where values change frequently.

  - **Visualization**: Added matplotlib visualization showing both the original data values and the tree structure with clear annotations indicating which indices each tree node covers. This makes the internal workings of the data structure much more intuitive.

  - **Range Queries**: Implemented efficient range sum queries that can calculate the sum between any two indices in O(log n) time by combining two prefix sum queries.

  - **Initialization Options**: The tree can be initialized either with a size (all zeros) or with initial values, with an optimized O(n) construction time when values are provided.

  - **Type Hints**: Used Python type hints throughout the implementation for better code clarity and maintainability.

  - **Error Handling**: Added bounds checking for all operations to prevent index out of range errors.

  This project was an excellent exercise in understanding advanced data structures and their practical implementation. The visualization component was particularly valuable for grasping how the tree structure differs from the original array and how each node covers specific ranges of indices.

  The Fenwick Tree has important applications in problems involving frequent updates and prefix sum calculations, such as:
  - Maintaining changing frequency tables
  - Dynamic ranking systems
  - Computational geometry problems
  - Range sum queries in mutable arrays

  By implementing this structure with visualization capabilities, I've gained deeper insights into its efficient operation and potential use cases in algorithm optimization.
* Day 378: 🎮 Word Raider - A Word Guessing Game in Python 🔠  

  Today, I built **Word Raider**, a fun and interactive word-guessing game in Python. The game challenges players to guess a hidden word within a limited number of attempts, providing feedback on correct, misplaced, and incorrect letters. Below are the key highlights:  

  - **Word Bank**: The game reads words from an external file (`words.txt`), making it easy to customize and expand the vocabulary. Each word is randomly selected for replayability.  

  - **User Feedback**: The game provides real-time feedback by displaying:  
    - Correct letters in their exact positions.  
    - Misplaced letters (correct letter, wrong position).  
    - Incorrect letters not present in the target word.  

  - **Turn Management**: Players have a limited number of turns (default: 5) to guess the word, adding strategic depth to each attempt. The game tracks used turns and displays progress.  

  - **Input Validation**: The game ensures guesses are valid—checking for correct length and alphabetic characters—to prevent errors and guide the player.  

  - **Win/Lose Conditions**: Clear messages indicate whether the player guessed the word correctly or ran out of turns, revealing the target word if lost.  

  - **Early Exit**: Players can type `exit` at any time to quit the game gracefully.  

  This project was a great way to practice file handling, string manipulation, and loop control in Python. It also reinforced the importance of user feedback in game design, making the experience intuitive and engaging.  
* Day 379: Technical Test "minCut" and "cloneGraph" [LeetCode](https://leetcode.com/problems/)

  - **minCut**: Implemented a solution for the "Palindrome Partitioning II" problem, where the task is to find the minimum number of cuts needed to partition a string such that every substring is a palindrome. The solution uses dynamic programming to first check for palindrome substrings and then calculates the minimum cuts required. This approach ensures efficient computation with a time complexity of O(n²), where n is the length of the string.
    [Problem Description: minCut](https://leetcode.com/problems/palindrome-partitioning-ii/description/)

  - **cloneGraph**: Solved the "Clone Graph" problem, which involves creating a deep copy of a connected undirected graph. Each node in the graph contains a value and a list of its neighbors. The solution uses a depth-first search (DFS) approach along with a hash map to keep track of visited nodes, ensuring that each node is cloned exactly once and all connections are properly replicated. The time complexity is O(N + E), where N is the number of nodes and E is the number of edges in the graph.
    [Problem Description: cloneGraph](https://leetcode.com/problems/clone-graph/description/)
* Day 380: 🏀 Basketball Position Recommender in Python 

  Today, I developed a Basketball Position Recommender system using Python that analyzes a player's physical attributes and skills to suggest the most suitable position (Point Guard, Shooting Guard, Small Forward, Power Forward, or Center). The project focuses on data processing and weighted scoring algorithms. Below are the key highlights:

  - **Input Validation**: The system collects and validates player height (in cm) and weight (in kg), ensuring realistic ranges (150-250cm for height, 40-150kg for weight) through robust error handling.

  - **Skill Assessment**: Players rate their abilities (1-10 scale) across 7 key basketball skills: ball handling, shooting, passing, rebounding, defense, post play, and athleticism. This comprehensive evaluation captures all aspects needed for position analysis.

  - **Weighted Scoring Algorithm**: The program uses position-specific weightings to calculate suitability scores. Each position (PG, SG, SF, PF, C) has different emphasis on physical attributes and skills, reflecting real basketball requirements.

  - **Normalization**: Height and weight values are normalized to a 1-10 scale for fair comparison with skill ratings, ensuring balanced consideration of physical and technical attributes.

  - **Detailed Output**: The system provides both a clear recommendation and detailed scores for all positions, allowing players to understand their strengths across different roles on the court.

  - **User-Friendly Interface**: With clear prompts and formatted results, the program offers an intuitive experience from data entry to final recommendation.

  This project was an excellent exercise in data processing and decision algorithms. I gained valuable experience in designing weighted scoring systems and creating practical tools that combine quantitative analysis with sports knowledge. The recommender demonstrates how data-driven approaches can provide meaningful insights in athletic contexts.
* Day 381: 📈 Catalan Numbers Visualization in Python 🔢

  Today I worked on visualizing and comparing different methods to calculate Catalan numbers in Python. Catalan numbers are a sequence of natural numbers that have applications in various combinatorial problems, such as counting valid parentheses expressions, binary trees, and lattice paths.

  Below are the key highlights of this project:

  - **Recursive Calculation**: Implemented a recursive approach with memoization using Python's `lru_cache` decorator to efficiently compute Catalan numbers while avoiding redundant calculations.

  - **Binomial Coefficient Method**: Created a more efficient calculation using binomial coefficients (`comb(2n, n)/(n+1)`), which provides a direct mathematical formula for Catalan numbers.

  - **Growth Visualization**: Generated a log-scale plot showing the exponential growth of Catalan numbers, including a polynomial trend line to demonstrate their asymptotic behavior.

  - **Method Comparison**: Built a comparative visualization (bar chart) showing the results from both calculation methods side by side, confirming they produce identical results.

  - **Mathematical Libraries**: Utilized `math.factorial`, `math.comb`, and NumPy for numerical operations, along with Matplotlib and Seaborn for professional-quality visualizations.

  This project was an excellent opportunity to explore both the mathematical properties of Catalan numbers and different computational approaches to calculate them. The visualizations help intuitively understand their rapid growth rate, while the method comparison demonstrates how algorithmic choices can impact performance.

  The implementation showcases Python's capabilities for mathematical computing and data visualization, combining pure mathematics with practical programming techniques.
* Day 382: 💤 SleepAnalyzer - Python Sleep Tracking System 📊

  Today, I developed a comprehensive Sleep Tracking System using Python with MVC (Model-View-Controller) architecture. This application helps users track and analyze their sleep patterns with detailed statistics and insights. Below are the key highlights:

  - **MVC Architecture**: Implemented a clean separation of concerns with Model handling data operations, View managing user interface, and Controller coordinating between them. This makes the code maintainable and scalable.

  - **Data Persistence**: The system stores sleep records in JSON format with automatic file creation, ensuring data persists between sessions without manual setup.

  - **Sleep Metrics**: Tracks multiple sleep metrics including duration (automatically calculated), quality (1-5 scale), dream recall, and custom notes for each night.

  - **Advanced Analytics**: Provides detailed statistics like average sleep duration, quality trends, dream frequency, and even calculates a sleep consistency score and recommended bedtime.

  - **Data Management**: Full CRUD functionality (Create, Read, Update, Delete) with intuitive search capabilities by date range, sleep duration, quality, and dream recall.

  - **Export Options**: Supports exporting data to multiple formats (CSV, JSON, and human-readable text) for further analysis or sharing with healthcare professionals.

  - **User-Friendly Interface**: Features a clean menu-driven interface with clear data visualization, including star ratings for sleep quality and comprehensive error handling.

  This project was an excellent opportunity to build a complete application from scratch while following software architecture best practices. I particularly focused on creating robust data validation, meaningful statistics, and an intuitive user experience. The MVC pattern implementation helped me better understand how to structure medium-sized applications for maintainability and future expansion.
* Day 383: 🗃️ LRU Cache Implementation in Python 🏗️

  Today, I implemented a Least Recently Used (LRU) Cache in Python, focusing on efficient data structure design and algorithm optimization. The project demonstrates how to manage limited cache space by automatically evicting the least recently used items when capacity is reached. Below are the key highlights:

  - **Doubly Linked List**: The cache uses a doubly linked list to maintain the order of item usage, with the most recently used items at the head and least recently used at the tail. This allows O(1) time complexity for both insertions and deletions.

  - **Hash Map**: A dictionary (hash map) provides O(1) access to cache items by key, while the linked list maintains the usage order. This combination of data structures ensures optimal performance for both get and put operations.

  - **Cache Operations**: The implementation supports two main operations: `get(key)` to retrieve a value while updating its usage status, and `put(key, value)` to add or update an item in the cache.

  - **Automatic Eviction**: When the cache reaches capacity, the system automatically removes the least recently used item before adding new entries, maintaining efficient memory usage.

  - **Visualization**: The implementation includes a visualization component using matplotlib that shows the evolution of the cache state after each operation, making it easy to understand the LRU eviction policy in action.

  - **Practical Application**: This LRU Cache implementation mirrors how real-world systems (like databases and web servers) manage memory, providing hands-on experience with a fundamental computer science concept used in system design.

  This project was an excellent exercise in combining different data structures to solve a common system design problem. I gained deeper understanding of how to achieve O(1) time complexity for cache operations and how visualization can help debug and demonstrate algorithm behavior. The implementation serves as a practical foundation that could be extended for more complex caching scenarios.
* 💻 Day 384: Chess Piece Classification [Kaggle](https://www.kaggle.com/datasets/anshulmehtakaggl/chess-pieces-detection-images-dataset) 

  Today, I worked on building a Chess Piece Classification project using a dataset from Kaggle. The goal was to classify images of chess pieces using image processing and machine learning techniques with libraries such as OpenCV, NumPy, Scikit-learn, and Matplotlib. The project covers the full pipeline from data download and preprocessing to model training and evaluation. Below are the key highlights:

  - **Image Preprocessing**: The project includes a function that reads grayscale images of chess pieces, resizes them to a fixed dimension (64x64), and flattens them for classification. This step standardizes the input for the model and ensures consistency in training and testing.

  - **Data Normalization**: The image pixel values are normalized to a [0, 1] range to enhance model performance and reduce training time. This is a crucial preprocessing step when working with image data in machine learning.

  - **Train-Test Split**: The data is split into training and testing sets using a standard 80-20 ratio. This ensures that the model is evaluated on unseen data and provides a reliable measure of generalization.

  - **KNN Classification**: A K-Nearest Neighbors (KNN) classifier is trained to distinguish between different types of chess pieces. The classifier is simple, effective, and well-suited for small-scale image classification problems.

  - **Model Evaluation**: The model’s performance is evaluated using classification metrics such as precision, recall, F1-score, and the confusion matrix. These metrics help understand the strengths and weaknesses of the classifier across different classes.

  - **Visualization of Predictions**: The project includes a utility to visualize a few sample predictions alongside the true labels. This offers an intuitive sense of how well the model is performing and helps in spotting misclassifications.

  - **User-Friendly Functions**: The project includes reusable and modular functions for loading images, training models, and plotting results. This makes the code clean, maintainable, and easy to extend.

  This project was an excellent opportunity to apply machine learning techniques to visual data and explore image classification using Python. It also reinforced the importance of preprocessing and evaluation when working with image-based datasets.
* 🗓️ Day 385: Lambda Function Plotter [Python + Tkinter + Matplotlib] 

  Today, I worked on developing a Lambda Function Plotter using Python. The project consists of a GUI that allows users to input lambda expressions and visualize them interactively. The interface was built using Tkinter with a dark theme for better user experience, and the graphs are rendered using Matplotlib. Below are the key highlights:

  - **Lambda Function Input**: The project allows users to enter a lambda function (e.g., `lambda x: x**2 - 4*x + 3`) as a string. This input is evaluated dynamically and validated to ensure it's a callable function before plotting.

  - **User Interface**: I designed a user-friendly GUI using Tkinter with a dark theme, including custom fonts, color schemes, and button styles. This makes the application visually appealing and easy to navigate.

  - **Function Evaluation**: The input function is evaluated over a range of x values using NumPy. The result is a set of y values corresponding to each x, which is then plotted in real time.

  - **Matplotlib Integration**: The graph of the lambda function is rendered directly inside the Tkinter window using the `FigureCanvasTkAgg` class from `matplotlib.backends.backend_tkagg`. The plot includes a styled background, grid lines, axis markers, and a legend.

  - **Error Handling**: The application includes message boxes that handle invalid lambda expressions and evaluation errors gracefully, ensuring a smooth user experience even when incorrect input is provided.

  - **Dynamic Plotting**: Users can instantly see the graph of any valid lambda expression by entering the function and clicking the “Plot Function” button. Previous plots are cleared automatically to avoid clutter.

  - **Custom Theme**: The entire GUI follows a modern dark theme, with consistent styling for all widgets, including buttons, labels, and text fields. This enhances readability and user comfort during prolonged use.

  This project was an excellent opportunity to practice dynamic function evaluation, graphical rendering in GUIs, and interactive design with Python. It reinforced the value of combining functionality with visual appeal for building intuitive and efficient user tools.

* Day 386: Recursive Regex Matcher 

  Today, I worked on building a Recursive Regex Matcher in Python. The focus was on designing a custom function that matches strings against simplified regular expressions using recursion. The project avoids using Python’s built-in `re` module and instead implements core regex logic manually. The supported operators include `*`, `+`, `?`, `.`, and character groups like `[abc]`. Below are the key highlights:

  - **Wildcard Matching**: The matcher supports the `.` operator, which matches any single character. This is useful for handling patterns where any character can appear in a given position.

  - **Character Groups**: I implemented parsing logic to recognize character groups such as `[abc]`. This allows for flexible pattern matching against multiple potential characters.

  - **Quantifier Logic**: The matcher handles the `*`, `+`, and `?` quantifiers, enabling recursive matching of zero or more, one or more, and zero or one occurrences of a character or group, respectively.

  - **Recursive Design**: The entire matcher is built using recursive functions to break down the pattern and the string step by step. This emphasizes the power of recursion in parsing and decision-making.

  - **Edge Case Handling**: The code gracefully handles edge cases like unclosed brackets and empty strings, providing error messages or correct base case behavior as needed.

  - **Test Cases**: A variety of test cases were created to verify correct behavior across different combinations of patterns and input strings. These help ensure that the matcher behaves as expected.

  - **Readable Structure**: The code is modular and well-commented, with separate functions for matching characters and patterns. This enhances readability and makes it easy to extend functionality in the future.

  This project was an excellent opportunity to deepen my understanding of recursion and string pattern matching in Python. It reinforced how powerful recursive thinking can be when designing algorithms that involve parsing and dynamic control flow.

* 🗓️ Day 387: AVL Tree Balancer 
  Today, I worked on implementing an AVL Tree Balancer using Python. The focus was on recursive insertion of nodes and maintaining balance through rotations to ensure logarithmic height. The project also includes a visual representation of the AVL Tree using Matplotlib and NetworkX. Below are the key highlights:

  - **Recursive Insertion**: The project includes a function that performs recursive insertion of nodes into the AVL tree. During each insertion, the height of nodes is updated, and balance factors are calculated to determine if rotations are needed.

  - **Balance Factor Check**: After each insertion, the code checks the balance factor of the affected nodes to identify imbalances (Left-Left, Right-Right, Left-Right, Right-Left). This is essential to maintain the self-balancing nature of the AVL tree.

  - **Rotations**: The implementation includes left and right rotation functions to fix imbalances. These rotations are automatically applied during insertion based on the balance factor, ensuring the tree remains balanced.

  - **Pre-order Traversal**: A traversal function is provided to print the keys of the tree in pre-order, which helps verify the structure and correctness of the AVL tree after insertions.

  - **Tree Visualization**: The project includes a visualization module using Matplotlib and NetworkX. This allows for a graphical representation of the AVL tree, displaying node relationships and hierarchy.

  - **Graph Positioning**: The visualizer places nodes dynamically to reflect the hierarchical structure of the AVL tree. This helps in understanding how the tree evolves with each insertion.

  - **User-Friendly Structure**: The project is modular, separating the AVL logic from the visualization code. This improves code clarity and allows for easier maintenance and future expansion.

  This project was an excellent opportunity to deepen my understanding of balanced binary search trees and recursive algorithms in Python. The experience reinforced the importance of maintaining tree balance for optimal performance and visualizing complex data structures to aid in learning and debugging.
* Day 388: 🌍 Global Spice Consumption Analysis [Kaggle](https://www.kaggle.com/datasets/harishthakur995/global-spice-consumption/code)

  Today, I worked on analyzing the Global Spice Consumption dataset from Kaggle using Python. The project focused on exploring global spice trade patterns and consumption trends using Pandas, Seaborn, Matplotlib, and machine learning techniques. Below are the key highlights:

  🔍 Key Analysis Highlights

  - **Dataset Exploration**: Performed initial data exploration including shape, column information, and descriptive statistics. Cleaned column names for better consistency.

  - **Data Visualization**:
    - Created count plots to visualize the distribution of different spice items
    - Generated word clouds to highlight most common spices in the dataset
    - Plotted production and consumption trends over time
    - Visualized top producing areas and most consumed spices
    - Compared import vs export patterns across countries

  - **Feature Analysis**: Examined unique values in each column and checked for missing values to ensure data quality.

  - **Machine Learning Models**:
    - Implemented and evaluated three regression models (Gradient Boosting, LightGBM, and Neural Network) to predict spice production
    - Used cross-validation to compare model performance
    - Generated visualizations of actual vs predicted values

  🌶️ Dataset Overview
  The dataset contains comprehensive information about global spice consumption, including:
  - Production, import, export, and consumption quantities (in tons)
  - Data across multiple countries and years
  - Nine major spice categories including:
    - Chillies & Peppers
    - Cinnamon
    - Cloves
    - Ginger
    - Nutmeg
    - Pepper
    - Vanilla

  📊 Key Insights
  - Visualized global trade patterns and consumption trends for spices
  - Identified top producing countries and most consumed spices
  - Developed predictive models for spice production
  - Analyzed correlations between different trade metrics

  This project provided valuable experience in analyzing global trade data and building predictive models for agricultural commodities. The visualizations helped uncover interesting patterns in spice consumption worldwide.
* Day 389: Recursive Circle Packing Animation

  Today, I worked on creating an animated Recursive Circle Packing visualization using Python and Matplotlib. The focus was on recursion, geometry, and real-time visualization using `matplotlib.animation.FuncAnimation`. The project includes generating non-overlapping circles recursively and visualizing the circle packing process step-by-step. Below are the key highlights:

  - **Recursive Geometry**: The project uses a recursive function to generate circles within circles without overlapping. Each new circle is placed based on polar coordinates and validated against previously drawn circles to maintain spatial integrity.

  - **Overlap Detection**: A custom class was used to represent each circle, with methods to detect overlap using Euclidean distance. This ensures that all new circles are placed without intersecting existing ones.

  - **Dynamic Circle Placement**: The code introduces randomness in direction and size when placing child circles, creating a natural and organic packing layout. This adds variety to each run and simulates biological or physical growth patterns.

  - **Matplotlib Animation**: The use of `FuncAnimation` allows each circle to appear one-by-one in real time, offering a smooth and visually engaging way to observe the recursive structure being built incrementally.

  - **Aspect Ratio and Scaling**: The aspect ratio is fixed to maintain circular shape accuracy, and the axes are hidden to emphasize the visual structure. The initial circle and drawing canvas are centered to allow maximum recursive depth.

  - **Recursive Generator**: A generator function (`yield from`) is used to manage the recursive logic and produce circles lazily, optimizing memory usage and maintaining control over the animation flow.

  - **User-Friendly Design**: The code is modular and well-commented, allowing easy understanding and further experimentation with radius scaling, recursion depth, and animation speed.

  This project was an excellent opportunity to deepen my understanding of recursive algorithms and animation techniques in Python, as well as to explore the visual aesthetics of geometric recursion. The experience reinforced the power of combining mathematical logic with visual feedback to enhance learning and creativity.
* Day 390: Technical Test "canCompleteCircuit" and "candy" [LeetCode](https://leetcode.com/problems/)

  - **canCompleteCircuit**: Implemented a solution for the "Gas Station" problem, where the task is to find the starting gas station index that allows traveling around a circular route once. The approach checks if the total gas is sufficient to cover the total cost first. If possible, it uses a greedy algorithm to determine the starting point by tracking the current tank balance and resetting when negative. The time complexity is O(n), where n is the number of gas stations.
    [Problem Description: canCompleteCircuit](https://leetcode.com/problems/gas-station/description/)

  - **candy**: Solved the "Candy" distribution problem, which requires distributing candies to children based on their ratings while satisfying two rules: each child must get at least one candy, and children with higher ratings than neighbors must receive more candies. The solution uses two passes (left-to-right and right-to-left) to ensure both rules are met with the minimum number of candies. The time complexity is O(n), where n is the number of children.
    [Problem Description: candy](https://leetcode.com/problems/candy/description/)
* Day 391: 🎯 Random Fortune Roulette in Python 🎡

  Today, I built a Random Fortune Roulette wheel using Python and Tkinter for the GUI. This interactive application allows users to spin a virtual wheel to randomly select from customizable options, perfect for contests, prize distributions, or fun decision-making. Here are the key highlights:

  - **Customizable Options**: Users can input their own options in the text box (one per line) with a minimum of 2 options required. Default options are provided for immediate use.

  - **Visual Roulette Wheel**: Features a colorful segmented wheel with clear labeling for each option. The design includes a prominent pointer to indicate the selection.

  - **Realistic Spinning Animation**: The wheel spins with smooth animation and gradually slows down for a realistic roulette experience. The spinning speed decreases naturally until it stops on a random selection.

  - **Result Detection**: Automatically calculates and displays the selected option when the wheel stops spinning. The system accounts for the wheel's final angle to determine the winning segment.

  - **User-Friendly Interface**: Includes clear buttons for updating options and spinning the wheel, with an intuitive layout that makes the application easy to use.

  - **Tkinter GUI**: Utilizes Python's built-in Tkinter library for the graphical interface, making the application lightweight and compatible with most systems without additional dependencies.

  This project was a great opportunity to practice GUI development and animation techniques in Python. I particularly enjoyed implementing the physics-like deceleration of the wheel and the precise angle calculations needed to determine the selected option. The result is a fun, interactive tool that can be adapted for various purposes while demonstrating core Python programming concepts.
* Day 392:🎮 Guess the Word Game in Python 🔠

  Today, I developed a Guess the Word Game in Python, featuring both console and GUI (Tkinter) versions. The project focuses on interactive gameplay where the AI reveals letters gradually and players guess the complete word. Below are the key highlights:

  - **Dual Interface**: The game offers both console and graphical (Tkinter) interfaces, providing flexibility in how users interact with the application. Players can choose their preferred version at startup.

  - **Progressive Hint System**: The AI reveals letters gradually through a hint mechanism that shows 30% of remaining letters randomly, creating a balanced challenge that adapts to the player's progress.

  - **Game State Management**: The `WordGuessingGame` class encapsulates all game logic including word selection, hint generation, and guess validation, demonstrating clean separation of concerns.

  - **Attempt Limit**: Players have 6 attempts to guess the word correctly, adding strategic tension to the gameplay. The system tracks remaining attempts and provides clear feedback.

  - **Word Database**: The game uses a curated list of programming-related words, making it both entertaining and educational for developers. The selection is random for each game session.

  - **Input Validation**: Both versions validate user input, ensuring guesses contain only letters and match the word length. The GUI version additionally provides real-time feedback.

  - **Tkinter Implementation**: The GUI version features responsive design with labels, entry fields, and buttons. It maintains game state while providing visual feedback through color-coded messages.

  This project was an excellent exercise in creating interactive applications with multiple interface options. I particularly enjoyed implementing the progressive hint system that makes the game challenging yet fair. The dual-interface approach allowed me to practice both console programming and GUI development with Tkinter, while maintaining consistent game logic across both versions.

  The game demonstrates how Python can be used to create engaging educational tools, combining programming concepts with vocabulary building in a fun package.
* Day 393: 🏔️ Recursive Landscape Generator in Python 🌄

  Today, I worked on a Recursive Landscape Generator using Python, implementing a midpoint displacement algorithm to create mountainous terrain. The project focuses on recursive algorithms and procedural generation techniques similar to basic Perlin noise concepts. Below are the key highlights:

  - **Midpoint Displacement Algorithm**: The core of the project uses recursive midpoint displacement to generate natural-looking terrain. Starting with a flat line, the algorithm recursively subdivides segments and adds random vertical displacement to create varied landscapes.

  - **Parameter Control**: The generator offers adjustable parameters including terrain roughness (controlling how jagged or smooth the terrain appears), vertical scale (controlling height variations), and recursion depth (controlling the level of detail).

  - **Visualization**: The generated landscape is visualized using matplotlib, with a filled plot that shows elevation changes across the terrain. The visualization includes proper labeling and grid lines for better interpretation.

  - **Recursive Implementation**: The project demonstrates clean recursive programming, with each iteration creating finer details in the terrain by processing smaller segments and reducing the displacement magnitude.

  - **Customizable Output**: Users can easily modify the landscape dimensions (width and height), roughness factor, and number of iterations to create different types of terrain from rolling hills to sharp mountains.

  This project was an excellent exercise in understanding procedural generation techniques and recursive algorithms. I gained practical experience in implementing mathematical concepts to create natural-looking patterns, while also exploring visualization techniques to present the generated data effectively. The recursive approach proved particularly valuable for creating fractal-like terrain with self-similar details at different scales.
* Day 394: Technical Test "singleNumber" and "singleNumberII" [LeetCode](https://leetcode.com/problems/)  

  - **singleNumber**: Implemented a solution for the "Single Number" problem, where the task is to find the element that appears exactly once in an array where every other element appears twice. The approach uses XOR bitwise operation to efficiently cancel out duplicate elements, leaving only the single number. The solution runs in O(n) time with O(1) space complexity.  
    [Problem Description: singleNumber](https://leetcode.com/problems/single-number/description/)  

  - **singleNumberII**: Solved the "Single Number II" problem, which extends the previous challenge by having every element appear three times except for one. The solution uses bitwise counting to track the number of set bits at each position, reconstructing the single number by checking which bits appear a non-multiple-of-three times. The approach maintains O(n) time complexity and O(1) space usage.  
    [Problem Description: singleNumberII](https://leetcode.com/problems/single-number-ii/description/)  
* Day 395: 🏛️ Interactive Museum Guide System in Python 🖼️

  Today, I developed an Interactive Museum Guide System using Python with a Model-View-Controller (MVC) architecture. This comprehensive system allows visitors to explore artifacts, view exhibitions, take virtual tours, and provides administrators with tools to manage museum content. Below are the key highlights:

  - **MVC Architecture**: Implemented a clean separation of concerns with distinct Model, View, and Controller components. The Model handles data persistence in JSON format, the View manages all user interface aspects, and the Controller orchestrates the application flow.

  - **Complete CRUD Operations**: The system supports full Create, Read, Update, and Delete functionality for all museum entities (artifacts, exhibitions, and virtual tours) with proper data validation and error handling.

  - **Interactive User Interface**: Developed a colorful terminal interface with ANSI escape codes for better user experience. The menu system features intuitive navigation and detailed displays for all museum content.

  - **Virtual Tour System**: Implemented a sophisticated virtual tour feature with multiple stops, descriptions, and optional video links, providing an immersive experience for museum visitors.

  - **Admin Authentication**: Created a secure admin section with login functionality to protect sensitive operations. Admins can manage all aspects of the museum's digital presence.

  - **Data Persistence**: Designed a JSON-based storage system that automatically saves all changes and loads data when the application starts, ensuring no data loss between sessions.

  - **Sample Data Initialization**: The system includes automatic population of sample data (like the Rosetta Stone artifact and Ancient Civilizations exhibition) when first launched, demonstrating its capabilities.

  This project was an excellent opportunity to build a complete application using MVC architecture in Python. I deepened my understanding of software design patterns, data persistence, and user interface development while creating a practical tool that could be deployed in real museum environments.

  The system demonstrates professional Python development practices with proper documentation, modular code organization, and attention to user experience - making it a valuable addition to my portfolio of Python applications.
* 🧠 Day 396: Arithmetic Puzzle Solver with Recursion and Visualization 📊 

  Today, I developed an Arithmetic Puzzle Solver in Python that uses recursion and backtracking to find digit permutations that satisfy a given arithmetic expression represented by letters. This project combines recursive algorithms with expression evaluation and visual feedback through matplotlib. Below are the key highlights:

  - **Recursive Backtracking**: Implemented a function to recursively generate all permutations of digits from 1 to 9 without repetition. This forms the core of solving the cryptarithm-like puzzles by trying different digit combinations for each letter.

  - **Expression Evaluation**: Designed a parser that maps each unique character in the pattern to a digit and evaluates whether the resulting numeric expression holds true. This includes support for operators like `+`, `-`, `*`, `/`, and `//`.

  - **Pattern Matching**: The solver handles arithmetic patterns such as `ABC+DEF=GHI`, ensuring that each letter maps to a unique digit and the operation evaluates correctly.

  - **User Interface**: Created a command-line interface that prompts the user to input a pattern and an operator. The system then processes the input, attempts to find a valid digit mapping, and returns the solution if one exists.

  - **Visualization**: Added a bar chart to visually represent the number of solutions found per operator type using dummy data, offering insights into how different operations may yield more or fewer valid results.

  This project was a fantastic exercise in combining recursion with mathematical reasoning and user interaction. It deepened my understanding of problem-solving with permutations, conditional logic, and basic data visualization.
* Day 397: 🌀 Colorful Spiral Art with Python Turtle 🎨  

  Today, I created a mesmerizing spiral art pattern using Python's `turtle` module and the `colorsys` library for dynamic color transitions. This project demonstrates the power of simple geometric loops combined with HSV color cycling to produce visually stunning effects. Below are the key highlights:  

  - **Turtle Graphics**: Utilized Python's built-in `turtle` library to draw intricate shapes programmatically, controlling movement, rotation, and pen color dynamically.  

  - **HSV Color Cycling**: Leveraged the `colorsys` library to convert HSV (Hue-Saturation-Value) colors to RGB, enabling smooth color transitions as the spiral progresses. The hue value increments subtly with each iteration, creating a rainbow-like effect.  

  - **Nested Loops for Complexity**: Used nested loops to layer multiple geometric patterns—drawing smaller concentric circles while rotating and adjusting radii—resulting in a hypnotic, fractal-like design.  

  - **Real-Time Animation**: Set the turtle speed to maximum (`speed(0)`) for instant rendering, allowing the full artwork to appear almost immediately while maintaining precision in the drawing process.  

  - **Mathematical Patterns**: Combined circular arcs (`circle()`) with alternating left (`lt()`) and right (`rt()`) turns to create interwoven spiral segments, each shrinking in radius for a layered depth effect.  

  This project was a fun exploration of algorithmic art, blending mathematical precision with creative coding. The simplicity of the turtle module paired with the richness of color manipeulation proves how a few lines of code can generate captivating visual results.  
* 🧠 Day 398: 🌲 Recursive Trie (Prefix Tree) Implementation in Python 🔍 

  Today, I worked on a Recursive Trie (Prefix Tree) using Python, with a focus on Object-Oriented Programming (OOP) principles such as encapsulation and recursion. The project supports word insertion, complete word search, and prefix checking. Below are the key highlights:

  - **Encapsulation**: The `TrieNode` class encapsulates attributes like `children` and `is_end_of_word`, managing access to each node’s data structure and state. This ensures that each node maintains integrity within the Trie.

  - **Recursion**: The core operations (`insert`, `search`, and `starts_with`) are implemented recursively. Each method breaks down the problem into smaller subproblems, enabling elegant traversal and modification of the Trie’s hierarchical structure.

  - **Word Insertion**: The `insert` method uses recursion to create child nodes for each character in a word. Once all characters are processed, the final node is marked as the end of a word.

  - **Search Functionality**: The `search` method checks if a complete word exists in the Trie by recursively verifying each character. If all characters match and the end-of-word flag is set, the word is found.

  - **Prefix Checking**: The `starts_with` method confirms if any word in the Trie begins with a given prefix. This feature is useful for applications like autocomplete or dictionary-based lookups.

  - **Example Usage**: The code includes examples of inserting multiple words, searching for full words, and checking for valid prefixes, offering a comprehensive test of the Trie’s capabilities.

  This project was an excellent exercise in applying recursion and data structure design to build an efficient word lookup system. It helped reinforce my understanding of how recursive methods can be used to traverse and manipulate hierarchical structures like Tries, while maintaining clean and modular code through encapsulation.
* Day 399: 🔐 Egyptian Code Book in Python 𓁹

  Today, I developed an Egyptian Code Book system using Python, implementing a substitution cipher with Unicode hieroglyphs. The project focuses on text encoding/decoding functionality while demonstrating practical Unicode handling and dictionary-based transformations. Below are the key highlights:

  - **Unicode Handling**: The system utilizes the Egyptian Hieroglyphs Unicode block (U+13000 to U+1302A) to represent characters, demonstrating advanced Unicode support in Python. Each character is carefully mapped to its corresponding hieroglyph.

  - **Dictionary-Based Cipher**: The core functionality relies on dictionary mappings (`HIEROGLYPH_DICT` and `REVERSE_HIEROGLYPH_DICT`) for efficient encoding and decoding operations, showcasing Python's powerful dictionary data structure.

  - **Extended Character Support**: Beyond basic letters, the system includes numbers (0-9) and common punctuation marks, making it more versatile than basic alphabet substitution ciphers.

  - **User-Friendly Interface**: The menu-driven interface provides clear options for encoding, decoding, and viewing the hieroglyph reference chart. Error handling ensures graceful operation even with unsupported characters.

  - **Encoding/Decoding Functions**: The `encode_message()` and `decode_message()` functions demonstrate clean string manipulation techniques, including fallback handling for unknown characters.

  - **Visual Presentation**: The system includes decorative elements using actual hieroglyphs and checks for terminal Unicode support, making it both functional and visually engaging.

  - **Practical Applications**: While primarily educational, the system demonstrates real-world concepts like character encoding systems, substitution ciphers, and user interface design for cryptographic tools.

  This project provided valuable experience in working with Unicode characters, dictionary manipulations, and building interactive console applications. I particularly enjoyed researching the Egyptian Hieroglyphs Unicode block and implementing a system that brings ancient writing into modern cryptography.
* Day 400: 🏛️ Babylonian Sexagesimal Calculator in Python 🔢

  Today, I built a Babylonian Calculator that performs arithmetic operations using the ancient sexagesimal (base 60) number system, implemented with Python and Tkinter for the graphical interface. This project combines historical mathematics with modern programming, featuring:

  - **Sexagesimal Arithmetic**: The calculator performs all basic operations (addition, subtraction, multiplication, division) using the base 60 system that was used in ancient Mesopotamia.

  - **Number System Conversion**: Includes conversion functions between our modern decimal system and the Babylonian sexagesimal notation, with "Sex→Dec" and "Dec→Sex" buttons for easy switching.

  - **Historical Accuracy**: Implements the authentic Babylonian notation using commas (,) to separate place values and semicolons (;) for fractional parts, just as ancient scribes would have recorded numbers on clay tablets.

  - **Dark Theme GUI**: Features a sleek, dark-themed interface built with Tkinter, making it visually appealing while reducing eye strain during extended calculations.

  - **Error Handling**: Robust error management for division by zero and invalid inputs, ensuring the calculator remains stable even with incorrect operations.

  - **User-Friendly Design**: Includes standard calculator functions like clear (C), backspace (←), and full reset (⌫), making it practical for both educational and historical research purposes.

  This project provided fascinating insights into how ancient civilizations performed complex mathematical operations without our modern number system. Implementing the base 60 arithmetic challenged my understanding of positional number systems and deepened my appreciation for the sophistication of ancient Babylonian mathematics. The Tkinter implementation allowed me to create an accessible tool that makes this ancient calculation method available to modern users with a clean, intuitive interface.

  The calculator not only serves as a functional mathematical tool but also as an educational resource for understanding one of humanity's earliest and most enduring numerical systems - a system that still influences our measurement of time (60 seconds in a minute, 60 minutes in an hour) and angles (360 degrees in a circle) today.
* Day 401: 🏰 Roman Catapult Game in Python 🪨

  Today, I built a Roman Catapult physics game using Pygame, focusing on realistic projectile motion and intuitive controls. The game challenges players to adjust angle and power to hit randomly generated targets. Below are the key highlights:

  - **Physics Simulation**: The game implements realistic projectile physics with gravity (9.8 m/s²) and parabolic trajectories, providing an authentic catapult experience. Velocity vectors are calculated using trigonometric functions for accurate angle-based launches.

  - **Game Mechanics**: Players control both the launch angle (10°-80°) and power (10-100) to hit targets. The scoring system rewards precision - smaller targets give more points (inverse to target size), adding strategic depth.

  - **Dynamic Targets**: The system generates targets at random positions and sizes after each successful hit, ensuring continuous challenge. Target collision detection uses pygame.Rect for accurate hitbox calculations.

  - **Visual Feedback**: The catapult arm dynamically rotates to reflect the current angle setting, and projectiles leave visible trails. The dark-themed interface with gold accents maintains visibility while being easy on the eyes.

  - **Intuitive Controls**: Simple keyboard controls (arrows for adjustments, F to fire) make the game accessible. The UI clearly displays current angle, power, and score during gameplay.

  - **Game States**: The system manages different game states (menu vs active play) with appropriate visual cues, including start instructions that disappear when gameplay begins.

  This project was an excellent exercise in game physics implementation and user-friendly design. I gained valuable experience in:
  - Vector mathematics for game development
  - Pygame's rendering system
  - Collision detection techniques
  - Game state management
  - User interface design for games

  The result is a satisfying physics-based challenge that captures the mechanical fun of ancient siege weapons while providing clean, maintainable code structure.
* Day 402: ❄️ FrozenLake AI Agent with Q-Learning 🏆

  Today, I developed an AI agent to solve the FrozenLake environment using Q-Learning, a fundamental reinforcement learning algorithm. The project demonstrates key RL concepts like exploration vs exploitation, value iteration, and policy optimization. Here are the main highlights:

  - **Q-Learning Implementation**: Built from scratch the core Q-learning algorithm that enables the agent to learn optimal actions through trial and error, using a reward-based system to navigate the frozen lake.

  - **Exploration Strategies**: Implemented an epsilon-greedy policy with custom decay scheduling, balancing exploration of new actions with exploitation of known good paths as training progresses.

  - **Hyperparameter Optimization**: Created a grid search system to automatically find the optimal learning rate, discount factor, and exploration rate for maximum performance.

  - **Training Visualization**: Developed professional training progress visualizations using Seaborn, showing the agent's improvement over episodes with a 100-episode moving average success rate.

  - **Model Evaluation**: Built a robust evaluation system to test the trained agent's performance across multiple episodes, with options for real-time rendering to observe the agent's behavior.

  - **Interactive Demo**: Designed a user-friendly menu system allowing interactive testing of the trained model, with options to change map sizes (4x4 or 8x8) and watch the agent navigate in real-time.

  Key technical aspects:
  - **Custom Epsilon Decay**: Implemented an exponential decay schedule for the exploration rate that automatically adjusts based on total training episodes.
  - **Early Stopping**: The training process automatically stops when the agent achieves >80% success rate over 100 consecutive episodes.
  - **Best Model Saving**: The system continuously saves the best-performing model during training to ensure optimal results are preserved.

  This project provided valuable hands-on experience with reinforcement learning fundamentals, particularly in understanding how agents learn from environmental feedback. I gained deeper insights into the practical challenges of RL training, including the importance of proper hyperparameter tuning and the exploration-exploitation tradeoff.

  The end result is a robust FrozenLake solver that demonstrates clear learning progress and achieves high success rates, serving as a strong foundation for more complex reinforcement learning applications.
* Day 403: 🌿 Barnsley Fern Fractal Generator in Python 🖥️

  Today, I created an interactive Barnsley Fern fractal generator using Python, with a focus on mathematical visualization, probabilistic algorithms, and GUI development. The project generates the famous fractal fern through iterative transformations and provides multiple visualization options. Below are the key highlights:

  - **Probabilistic Algorithms**: The fern is generated using four affine transformations selected via weighted probabilities (1%, 85%, 7%, 7%). This creates the organic fractal structure from simple mathematical rules.

  - **Optimized Generation**: Uses NumPy for vectorized operations, enabling efficient generation of up to 100,000 points while maintaining clean code through functional decomposition.

  - **Multiple Visualization Modes**:
    - **Color Gradients**: Points are colored by generation sequence using matplotlib colormaps
    - **Growth Animation**: Animated construction showing the fern's emergent structure
    - **3D Projection**: Experimental Z-axis extension creating depth effects

  - **Dark Theme GUI**: Built with Tkinter featuring:
    - Interactive controls for iteration count (1,000-100,000 points)
    - Color mode selection (solid/gradient/random)
    - One-click animation toggle
    - Dedicated 3D view button

  - **Mathematical Foundation**: Implements the iterated function system:
    ```
    f1(x,y) = (0, 0.16y)                         # Stem
    f2(x,y) = (0.85x + 0.04y, -0.04x + 0.85y + 1.6) # Leaflets
    f3(x,y) = (0.2x - 0.26y, 0.23x + 0.22y + 1.6)   # Left leaf
    f4(x,y) = (-0.15x + 0.28y, 0.26x + 0.24y + 0.44) # Right leaf
    ```

  - **User Experience**: The interface balances advanced functionality with simplicity:
    - Clean dark theme reduces eye strain
    - Instant visual feedback on parameter changes
    - Responsive design handles heavy computations gracefully

  This project deepened my understanding of how simple mathematical rules can generate complex natural patterns. The challenge of creating an interactive visualization while maintaining performance taught me valuable lessons about algorithmic optimization and GUI design principles. The end result is both a beautiful mathematical artifact and a practical demonstration of Python's scientific visualization capabilities.
* Day 404: 🎲 Lost Link - Network Dice Game 🌐

  Today, I built a graphical dice game called **Lost Link** using Pygame, where players navigate through a network path while avoiding 404 traps that send them backward. The game features a clean, dark-themed interface with programmatically generated graphics (no external assets needed). Below are the key highlights:

  - **Game Board System**: Implemented a dynamic board with different tile types (normal, traps, powerups) that affect player movement. The board scrolls to keep the current player visible at all times.

  - **Player Management**: Supports 2-4 players with color-coded tokens. Each player's position and status are clearly displayed in the UI.

  - **Dice Mechanics**: Features an animated dice roll with visual feedback. Players take turns rolling the dice to move along the network path.

  - **Tile Effects**:
    - **404 Traps**: Send players backward 3 spaces when landed on
    - **Powerups**: Provide special abilities (extra rolls, etc.)
    - **Finish Tile**: The goal that ends the game when reached

  - **State Management**: Clean separation of game states (menu, playing, game over) with appropriate UI for each state.

  - **Visual Feedback**: 
    - Highlighting of current player's position
    - Message system for game events (traps, powerups)
    - Animated dice rolling effect

  - **User Interface**:
    - Dark theme with clean, readable text
    - All graphics generated programmatically
    - Intuitive controls (space to roll, Q to quit)

  This project was a great exercise in game development fundamentals using Pygame. I focused on creating a polished, self-contained experience without relying on external assets, which challenged me to make the most of Pygame's drawing primitives. The game demonstrates solid state management, clean UI implementation, and engaging gameplay mechanics.
* Day 405: 🧺 Laundry Service Management System in Python 🚿

  Today, I built a comprehensive Laundry Service Management System using Python with Model-View-Controller (MVC) architecture. The system handles order management, garment types, special wash options, and delivery tracking. Here are the key highlights:

  - **MVC Architecture**: The project follows strict separation of concerns with Model, View, and Controller components. The Model handles data and business logic, the View manages user interface, and the Controller mediates between them.

  - **Order Management**: The system allows creating new orders with multiple garment items, each with optional special wash treatments. Orders track customer details, pickup/delivery addresses, and status through the entire workflow.

  - **Garment Types**: Different garment types (T-Shirts, Jeans, Dresses, etc.) are managed with their base prices and standard wash times, making pricing consistent and predictable.

  - **Special Wash Options**: Customers can select from various special treatments like Eco Wash, Quick Wash, or Stain Removal, each affecting both price and processing time.

  - **Data Persistence**: All orders are automatically saved to a JSON file and reloaded when the system starts, ensuring no data loss between sessions.

  - **Comprehensive Reporting**: The system provides various reports including orders by status, orders by customer, and revenue analytics, giving valuable business insights.

  - **Intuitive Interface**: A clear menu-driven interface makes the system easy to use with proper error handling and confirmation for critical actions.

  This project was an excellent opportunity to implement MVC architecture in Python, demonstrating how to properly separate data, presentation, and control logic. I gained valuable experience in designing a complete business management system with persistent storage and professional user interaction flows.

  The system is built to be easily extendable - potential future enhancements could include user authentication, more detailed analytics, or integration with payment systems and delivery tracking APIs.
* Day 406: Technical Test "copyRandomList" and "wordBreak" [LeetCode](https://leetcode.com/problems/)  

  - **copyRandomList**: Implemented a solution for the "Copy List with Random Pointer" problem, which involves creating a deep copy of a linked list where each node contains an additional random pointer that could point to any node in the list or `null`. The solution uses an interweaving approach to create copies of nodes and set their random pointers efficiently, achieving O(n) time complexity with O(1) space complexity (excluding the space for the new list).  
    [Problem Description: copyRandomList](https://leetcode.com/problems/copy-list-with-random-pointer/description/)  

  - **wordBreak**: Solved the "Word Break" problem, where the task is to determine if a given string can be segmented into a sequence of one or more words from a provided dictionary. The solution uses dynamic programming to efficiently check all possible segmentations, ensuring optimal performance with a time complexity of O(n^2), where `n` is the length of the string.  
    [Problem Description: wordBreak](https://leetcode.com/problems/word-break/description/)  
* Day 407: 🕵️ Alan Turing's Enigma Machine Simulator in Python  

  Today, I built a simulator of Alan Turing's famous Enigma machine used during WWII, focusing on historical accuracy and cryptographic principles. This Python implementation demonstrates how the German encryption device worked and how Turing's team at Bletchley Park broke its codes. Below are the key highlights:  

  - **Rotor Mechanism**: The `Rotor` class accurately models the wiring and notch behavior of historical Enigma rotors (I, II, III), including their stepping mechanism and character substitution patterns.  

  - **Plugboard Simulation**: The `Plugboard` class implements the letter-swapping functionality that provided an extra layer of encryption before and after rotor processing.  

  - **Reflector System**: The `Reflector` class mimics the fixed reflector that sent signals back through the rotors, a critical component of the encryption process.  

  - **Full Encryption Cycle**: The `EnigmaMachine` class combines all components to perform the complete encryption/decryption process exactly as the original machine did, including proper rotor stepping and double-stepping anomalies.  

  - **Interactive Menu System**: A user-friendly interface allows configuration of rotor positions, plugboard settings, and message processing - mirroring how operators would have used the actual machine.  

  - **Message History**: All encrypted/decrypted messages are stored with their settings, enabling analysis of cryptographic patterns just like Turing's team would have done.  

  - **Historical Accuracy**: Uses actual WWII wiring configurations (ROTOR_I, ROTOR_II, ROTOR_III) and reflector mappings (REFLECTOR_B) to demonstrate the exact encryption behavior Allied cryptanalysts faced.  

  This project deepened my understanding of both cryptography and Python's object-oriented capabilities. By reconstructing the Enigma's mechanical operations in code, I gained new appreciation for Turing's groundbreaking work in computer science and cryptography. The simulator serves as an educational tool to demonstrate one of history's most important encryption systems and the conceptual foundations of modern computing.
* Day 408: 📊 Precious Metals Analysis [Kaggle](https://www.kaggle.com/datasets/romanfonel/precious-metals-history-since-2000-with-news/code)

  Today, I conducted an in-depth analysis of historical precious metals data (Gold, Silver, Platinum, and Palladium) from Kaggle. The project focuses on time series analysis, sentiment analysis of related news headlines, and comparative market performance using Python's data science stack including Pandas, Plotly, Seaborn, and NLTK. Below are the key highlights:

  - **Comprehensive Data Overview**: Created a detailed exploration function that provides shape, data types, descriptive statistics, and unique value counts for each metal dataset (Gold, Silver, Platinum, Palladium).

  - **Interactive Time Series Visualization**: Implemented Plotly visualizations to analyze price trends over time, including:
    - Closing price evolution
    - Volume vs. price relationships
    - Comparative performance across all four metals

  - **Sentiment Analysis**: Applied VADER sentiment analysis to news headlines to:
    - Calculate daily sentiment scores
    - Visualize sentiment trends over time
    - Correlate sentiment with price movements

  - **Advanced Financial Analysis**:
    - Daily return calculations
    - Volatility analysis with rolling standard deviations
    - Price distribution comparisons (open, high, low, close)
    - Correlation matrices between different metals

  - **Technical Analysis Tools**:
    - Time series decomposition (trend, seasonality, residuals)
    - Annualized volatility calculations with different time windows
    - Comparative cumulative return analysis

  - **Natural Language Processing**:
    - TF-IDF analysis to identify key topics in news headlines
    - Word cloud generation from aggregated headlines
    - Sentiment distribution and proportion analysis

  This project provided valuable insights into precious metals market dynamics and demonstrated how news sentiment can be quantitatively analyzed alongside financial metrics. The interactive visualizations offer an intuitive way to explore complex financial time series data.
* Day 409: ✨ Magic Squares Generator in Python 🔢

  Today, I worked on a Magic Squares Generator using Python, implementing a recursive backtracking algorithm to create NxN magic squares. The project focuses on constraint satisfaction problems and recursive problem-solving techniques. Below are the key highlights:

  - **Recursive Backtracking Algorithm**: The core of the project uses recursive backtracking to systematically try number placements while maintaining the magic square properties. The algorithm backtracks when it hits dead-ends, ensuring all constraints are satisfied.

  - **Magic Square Properties**: The generator enforces the fundamental magic square rule where the sums of numbers in each row, each column, and both main diagonals must be equal to the magic constant (N(N²+1)/2).

  - **Validation System**: The implementation includes a comprehensive validation system that checks partial solutions at each step, ensuring the placed numbers don't violate any magic square constraints.

  - **Numpy Implementation**: The grid is implemented using NumPy arrays for efficient numerical operations and easy manipulation of rows, columns, and diagonals during the validation process.

  - **Customizable Size**: The generator can create magic squares of any size N ≥ 3, though solution time increases significantly with larger sizes due to the NP-hard nature of the problem.

  This project was an excellent exercise in understanding constraint satisfaction problems and recursive algorithms. I gained practical experience in implementing systematic search techniques while maintaining multiple constraints. The recursive approach proved particularly valuable for exploring the solution space methodically, and the validation checks helped optimize the search process by pruning invalid paths early.
* Day 410: 🧩 Cross Sums Puzzle Game in Python 🎲

  Today I developed a Cross Sums puzzle game using Python and Pygame, implementing logical deduction mechanics with a dark mode interface. The project focuses on creating a challenging number puzzle where players must eliminate incorrect numbers to match row and column sums. Key features include:

  - **Puzzle Mechanics**: Players eliminate numbers by clicking cells, leaving only those that correctly sum to the target values shown on the right (rows) and bottom (columns) of the grid.

  - **Difficulty Levels**: Three distinct challenge modes:
    - Easy (3×3 grid)
    - Normal (5×5 grid)
    - Hard (6×6 grid)

  - **Life System**: Players have 3 lives - incorrect eliminations (removing numbers that should stay) cost one life each.

  - **Dark Mode UI**: Custom dark-themed interface with:
    - Gray-scale color scheme
    - Red accent for sum numbers
    - Clean cell borders and button design

  - **Game Logic**: The generator creates puzzles with guaranteed solutions by:
    - Randomly selecting cells to keep (40% probability)
    - Ensuring at least one cell remains per row/column
    - Calculating valid row/column sums from kept cells

  - **Interactive Elements**:
    - Click to eliminate/restore cells
    - New game and difficulty selection buttons
    - Win/lose screens with retry options

  This project strengthened my understanding of puzzle generation algorithms and Pygame's event handling system. The challenge of ensuring unique solutions while maintaining randomness provided valuable insights into procedural puzzle design. The life system adds strategic tension, requiring careful deduction rather than random guessing.
* Day 411: ♟️ Chess Notation Trainer in Python 📝

  Today, I worked on a Chess Notation Trainer using Python, implementing a tool to practice converting between descriptive and algebraic chess notation. The project focuses on chess move validation and notation conversion. Below are the key highlights:

  - **Notation Conversion**: The program handles basic conversion between descriptive notation ("e2 to e4") and algebraic notation ("e4"), helping users practice this essential chess skill.

  - **Move Validation**: Implemented validation for algebraic notation, checking pawn moves (e4), captures (dxe4), promotions (e8=Q), and basic piece moves (Nf3, Bxe5).

  - **Interactive Training**: The trainer randomly alternates between showing descriptive notation (asking for algebraic) and showing algebraic notation (asking for descriptive), providing balanced practice.

  - **Random Move Generation**: The system generates random chess moves for training purposes, covering all files (a-h) and ranks (1-8) to ensure varied practice.

  - **User Feedback**: Provides immediate feedback on user answers, showing correct solutions when mistakes are made, reinforcing learning.

  This project was a great exercise in string manipulation, input validation, and interactive programming. I gained practical experience in implementing chess-specific logic while creating an educational tool. The random generation aspect proved particularly valuable for creating varied training scenarios, and the validation system helped solidify my understanding of chess notation rules.
* Day 412: 📂 SmartFolder - Automated File Organizer 🤖

  Today I developed **SmartFolder**, an automated file organization tool that intelligently categorizes files into subfolders based on their extensions. The project focuses on practical file management with a user-friendly interface. Key features include:

  - **Custom Folder Selection**: Unlike basic organizers, SmartFolder lets you choose ANY target directory through a graphical interface (using tkinter), not just the Downloads folder.

  - **Comprehensive Categorization**: Automatically sorts files into 8 intuitive categories:
    - 📄 Documents (PDF, Word, Excel)
    - 🖼️ Images (JPG, PNG, GIF)
    - 🎬 Videos (MP4, MOV, AVI)
    - 🎵 Music (MP3, WAV, FLAC)
    - 🗄️ Archives (ZIP, RAR, 7z)
    - ⚙️ Installers (EXE, DMG, PKG)
    - 💻 Code (Python, JS, HTML)
    - ❓ Others (unclassified extensions)

  - **Extension Tracking**: Identifies and reports unclassified file extensions for future configuration.

  - **Non-Destructive Operation**: Uses Python's shutil.move() to safely relocate files while maintaining folder structure.

  The project was built with:
  - `os` for path operations
  - `shutil` for file moving
  - `tkinter` for folder selection GUI
  - `time` for performance tracking

  This organizer solves real-world clutter problems with clean, maintainable code. The graphical folder picker makes it accessible to non-technical users, while the detailed console output provides transparency during operation.
* Day 413: 📂 Recent File Finder with Tkinter 🔍  

  Today, I developed a **Recent File Finder** application using Python and Tkinter, which helps users quickly locate and analyze recently modified files in any directory. The project focuses on file system operations and GUI development with a clean, functional interface.  

  - **Directory Selection**: Users can browse and select any directory using a native file dialog  
  - **Customizable Search**: Adjustable number of recent files to display (1-100)  
  - **Comprehensive File Info**: Displays file path, modification timestamp, and size in KB  
  - **Sortable Results**: Clickable column headers to sort by file attributes  
  - **Error Handling**: Validates directory existence and handles file system errors gracefully  

  - **Tkinter GUI**: Uses `ttk` widgets for a native-looking, responsive interface  
  - **File System Operations**: Leverages `os` module to retrieve file metadata  
  - **Tabular Display**: Organizes results in a scrollable Treeview widget  
  - **Human-Readable Formatting**: Converts timestamps and file sizes for better readability  

  This project provided valuable experience in building practical desktop utilities with Python. I gained deeper understanding of file system operations, GUI layout management, and user-friendly data presentation. The application solves a real-world need for quickly accessing recent files while demonstrating clean Python implementation.
* Day 414: 🛒 Customer Retention Analysis with UCI Online Retail Dataset 📊

  Today, I worked on a Customer Retention Analysis project using the UCI Online Retail dataset, implementing RFM (Recency, Frequency, Monetary) analysis to segment customers and calculate retention metrics. The project focuses on retail analytics and customer behavior insights. Below are the key highlights:

  - **RFM Segmentation**: The core of the project uses RFM analysis to categorize customers based on their purchase recency, frequency, and monetary value. This helps identify valuable customer segments like Champions, Loyal Customers, and At-Risk customers.

  - **Retention Rate Calculation**: Implemented cohort analysis to track how many customers return over time, with visualizations showing monthly retention patterns across different customer cohorts.

  - **Data Preparation**: Cleaned and transformed raw transaction data, handling missing values and creating essential features like customer tenure and purchase frequency.

  - **Visualization**: Created heatmaps to visualize retention rates across different cohorts and time periods, along with interactive dashboards showing customer segment distributions.

  - **Practical Applications**: The analysis provides actionable insights for customer retention strategies, helping identify which customer segments need attention and which are performing well.

  This project was an excellent exercise in understanding customer behavior patterns in retail data. I gained practical experience in implementing RFM analysis, cohort analysis techniques, and creating meaningful visualizations to present customer retention metrics. The segmentation approach proved particularly valuable for identifying different customer lifecycle stages and tailoring retention strategies accordingly.
* Day 415: 🖥️ Comprehensive Windows Inspector in Python 🔍

  Today, I developed a Comprehensive Windows Inspector using Python, implementing real-time window tracking and management capabilities. The project focuses on system monitoring and window management techniques using Windows API. Below are the key highlights:

  - **Active Window Tracking**: The inspector continuously monitors and displays information about the currently active window, including title, process ID, position, and size. It detects window changes in real-time.

  - **Process Information**: For each window, the tool retrieves detailed process information including process name, executable path, CPU usage, and memory consumption using psutil.

  - **Window Statistics**: The inspector tracks window usage statistics, recording activation counts and time spent in each window. Statistics are displayed with percentages of total tracked time.

  - **Activity History**: Maintains a log of the last 100 window switches, allowing users to review recent window activity patterns.

  - **Window Management**: Provides control functions to minimize, close, or bring windows to the foreground programmatically using Windows API calls.

  - **Complete System View**: Shows all visible windows in the system with their current state (active, minimized, etc.), position, and size.

  This project was an excellent exercise in understanding Windows system programming and process management. I gained practical experience with win32gui and psutil libraries, while implementing a useful system utility that combines monitoring and control capabilities. The statistics tracking feature provides valuable insights into window usage patterns, and the real-time monitoring demonstrates efficient event handling in Python.
* Day 416: 🔐 Shamir's Secret Sharing System in Python 

  Today, I implemented Shamir's Secret Sharing scheme in Python, a cryptographic method for secure secret distribution. The project focuses on splitting secrets into multiple shares and reconstructing them from a subset. Below are the key highlights:

  - **Secret Splitting Algorithm**: The core of the project uses polynomial interpolation to divide secrets into multiple shares. A secret number is encoded as the constant term in a random polynomial, with shares generated as points on this curve.

  - **Threshold Scheme**: The system implements a (k,n) threshold scheme where only k out of n shares are required to reconstruct the original secret, providing both security and redundancy.

  - **Mathematical Foundations**: The implementation uses finite field arithmetic with a large prime modulus (Mersenne prime 2¹²⁷-1) to ensure cryptographic security and proper polynomial reconstruction.

  - **Interactive Menu System**: The project features a user-friendly menu interface with options to split secrets, reconstruct from shares, view current shares, and run demo examples.

  - **Verification Mechanism**: During reconstruction, the system can verify if the recovered secret matches the original (when available), providing immediate feedback on successful recovery.

  This project was an excellent exercise in understanding cryptographic principles and finite field mathematics. I gained practical experience implementing advanced mathematical concepts like polynomial interpolation and modular arithmetic, while creating a functional security tool. The threshold scheme implementation demonstrated how cryptographic systems can balance security with practical usability requirements.
* Day 417: ⛓️ Minimalist Blockchain in Python 🔗

  Today, I built a Minimalist Blockchain implementation in Python, focusing on core blockchain concepts like proof-of-work, hashing, and chain validation. The project demonstrates the fundamental mechanics behind blockchain technology in a clean, understandable way. Here are the key components:

  - **SHA-256 Hashing**: The blockchain uses cryptographic hashing (SHA-256) to secure each block's contents, creating immutable links between blocks.

  - **Proof-of-Work System**: Implemented a mining mechanism where blocks must meet a difficulty target (leading zeros in the hash) to be added to the chain.

  - **Block Validation**: The system includes integrity checks to detect any tampering by verifying both individual block hashes and inter-block relationships.

  - **Interactive Menu**: A user-friendly console interface allows for:
    - Adding new blocks with custom data
    - Viewing the complete chain
    - Validating chain integrity
    - Running tamper-detection demos

  - **Educational Demonstrations**: Special demo modes show:
    - How proof-of-work protects the chain
    - What happens when blocks are altered
    - The self-healing nature of valid blockchain systems

  This project provided hands-on experience with blockchain's core security mechanisms and data structures. I gained practical understanding of how blocks are cryptographically linked, why proof-of-work is computationally expensive, and how distributed systems can verify data integrity without central authority. The clean Python implementation makes these concepts accessible while maintaining the essential security properties of real blockchain systems.
* Day 418: 🏗️ Distinct Paths Counter in Grid with Visualization 📊

  Today, I worked on a Distinct Paths Counter in Grid using Python, implementing both combinatorial mathematics and dynamic programming approaches to count all valid paths from top-left to bottom-right in a grid. The project focuses on algorithmic problem-solving with visualization. Below are the key highlights:

  - **Dual Algorithm Implementation**: The project features two distinct calculation methods - a combinatorial approach using binomial coefficients and a dynamic programming solution that builds up the path count progressively. Both methods yield identical results but demonstrate different problem-solving perspectives.

  - **Grid Visualization**: Using matplotlib, the program generates clear visualizations of the grid structure, highlighting start and end points in green and red respectively. A sample path is displayed in orange to demonstrate valid movement patterns (right and down only).

  - **Mathematical Foundations**: The combinatorial solution applies the "n choose k" principle (binomial coefficients) to calculate path counts efficiently, while the DP approach showcases classic bottom-up tabulation techniques for grid traversal problems.

  - **Interactive Parameters**: Users can input any grid dimensions (n×m) to explore how path counts scale with grid size. The visualization automatically adjusts to display grids of different proportions while maintaining clarity.

  - **Educational Visualization**: The plot includes coordinate labels, proper grid scaling, and a legend to make the path-counting concept immediately understandable. The title dynamically displays the total path count for the current grid size.

  This project provided excellent practice in implementing mathematical concepts through code and creating effective visualizations to demonstrate algorithmic solutions. Working through both combinatorial and DP approaches deepened my understanding of their respective strengths in different problem contexts. The visualization component proved particularly valuable for intuitively grasping how path counts grow exponentially with grid size.
* Day 419: Technical Test "wordBreakII" and "hasCycle" [LeetCode](https://leetcode.com/problems/)  

  - **wordBreakII**: Implemented a solution for the "Word Break II" problem, where the task is to construct sentences by adding spaces to a string `s` such that each word exists in a given dictionary. The solution uses backtracking with memoization to efficiently explore all possible valid word breaks. The time complexity is O(n^2 * 2^n) in the worst case, where `n` is the length of the string, due to the recursive exploration of all possible segmentations.  
    [Problem Description: wordBreakII](https://leetcode.com/problems/word-break-ii/description/)  

  - **hasCycle**: Solved the "Linked List Cycle" problem, which determines if a linked list contains a cycle using Floyd's Tortoise and Hare algorithm. The solution efficiently detects cycles with O(n) time complexity and O(1) space complexity by using two pointers moving at different speeds through the list.  
    [Problem Description: hasCycle](https://leetcode.com/problems/linked-list-cycle/description/)   
* Day 420: 🥞 Pancake Sorting Algorithm in Python 🔄

  Today, I implemented the Pancake Sorting algorithm using Python, focusing on recursive operations to sort arrays by strategically flipping portions of the data. This project demonstrates fundamental algorithm concepts and recursive problem-solving techniques. Below are the key highlights:

  - **Recursive Flip Operations**: The core of the project uses recursive flipping to position the largest unsorted element in its correct place with each iteration. The algorithm efficiently sorts by only performing flip operations on the array.

  - **Interactive Menu System**: The implementation includes a user-friendly menu that allows testing the algorithm with different input methods: manual entry, random generation, and visualization options.

  - **Step-by-Step Visualization**: When enabled, the program displays each flip operation, showing how the array transforms during the sorting process, which helps understand the algorithm's mechanics.

  - **Dual Mode Implementation**: The sorter offers both verbose (with visual steps) and silent modes, making it suitable for both educational demonstrations and efficient sorting.

  - **Clean Recursive Logic**: The project demonstrates proper recursive programming, with each recursion handling a smaller subset of the array until the base case (single element) is reached.

  This project provided excellent practice in implementing a classic algorithm with recursive techniques. I gained deeper understanding of how to approach sorting problems with constrained operations (only flips allowed), and how to effectively visualize algorithmic processes. The recursive approach proved particularly elegant for this problem, naturally handling the decreasing problem size with each iteration.
* Day 421: 🏚️ Virtual Post-Apocalypse Community Simulator 🌆

  Today, I developed a Virtual Post-Apocalypse Community Simulator in Python, implementing a comprehensive MVC architecture to simulate survival in a resource-limited world. The project focuses on managing survivors, resources, and community dynamics in a post-apocalyptic setting. Below are the key highlights:

  - **MVC Architecture**: The project follows a strict Model-View-Controller pattern, with clear separation between data management (Model), user interface (View), and game logic (Controller). This demonstrates professional-grade application structure.

  - **Survivor System**: Each survivor has detailed attributes including health, hunger, morale, and skills. The system tracks individual status changes over time, with realistic consequences like starvation or injuries affecting community dynamics.

  - **Resource Management**: The simulator includes four key resources (food, water, medicine, building materials) with different replenishment rates, requiring strategic allocation and prioritization.

  - **Day Advancement System**: Time progresses in discrete days, with automatic status updates for all survivors and resources. Each day brings potential random events that can help or hinder the community.

  - **Multiple Game Actions**: Players can assign work, organize rest periods, scavenge for supplies, improve shelter, and manage food distribution - each with different risk/reward tradeoffs.

  - **Comprehensive Reporting**: The system provides detailed status reports on community resources, survivor conditions, and event logs to inform player decisions.

  This project was an excellent exercise in complex system modeling and user interface design. I gained valuable experience implementing game mechanics with real consequences, managing interdependent systems, and creating an intuitive menu-driven interface. The object-oriented approach proved particularly effective for tracking multiple entities with complex relationships and behaviors.
* Day 422: 🏀 Player Jersey Number Checker System 🔢

  Today, I developed a comprehensive Player Jersey Number Checker System in Python, implementing a full-featured application to manage player databases with jersey numbers. The project focuses on data management, input validation, and persistent storage. Below are the key highlights:

  - **Player Management System**: The core of the project handles all CRUD operations (Create, Read, Update, Delete) for player records, storing both names and jersey numbers with proper validation.

  - **Search Functionality**: The system offers dual search capabilities - by player name (supporting partial matches) and by exact jersey number, making it versatile for different lookup needs.

  - **Data Persistence**: Implemented JSON-based storage to maintain player records between sessions, with automatic loading on startup and saving after modifications.

  - **Input Validation**: Robust validation ensures jersey numbers are within the valid range (1-99), prevents duplicate numbers, and checks for empty names.

  - **User-Friendly Interface**: Features an intuitive menu system with clear prompts and feedback for all operations, including confirmation messages and error handling.

  - **Object-Oriented Design**: The project demonstrates clean Python OOP principles with separate classes for player data and management logic, along with type hints for better code quality.

  This project was an excellent exercise in building complete data management applications with proper error handling and persistence. I gained practical experience in implementing input validation, file I/O operations, and user interface design. The system's architecture demonstrates how to organize code for maintainability while providing all essential features expected in a professional application.
* Day 423: 📊 Bank Marketing Analysis with Decision Trees in Python 🌐 [Bank Marketing Dataset - UCI](https://archive.ics.uci.edu/dataset/222/bank+marketing)

  Today, I worked on a Bank Marketing Analysis project using Python, leveraging a dataset from the UCI Machine Learning Repository that contains marketing campaign data of a Portuguese banking institution. The project focuses on decision tree algorithms and classification techniques to predict client subscription to term deposits. Below are the key highlights:

  * **Dataset Overview**: The dataset includes attributes related to customer information, campaign details, and socio-economic context. This data provides a comprehensive foundation for building predictive models in the financial domain.

  * **Decision Tree Classifier**: The core of the project uses the DecisionTreeClassifier from scikit-learn to model client behavior. The tree recursively splits data based on feature thresholds to separate classes, aiming to minimize impurity and maximize information gain.

  * **Feature Preprocessing**: Categorical variables were encoded using techniques like One-Hot Encoding and Label Encoding. Missing data handling and feature normalization were applied where needed to prepare the data for effective training.

  * **Model Evaluation**: Model performance was assessed using metrics such as accuracy, precision, recall, and F1-score. A confusion matrix was generated to provide insight into the classifier’s ability to distinguish between positive and negative classes.

  * **Visualization**: The decision tree was visualized using `plot_tree` from scikit-learn, showing the structure of splits and class probabilities. This helped interpret the model's logic and assess which features had the highest influence on predictions.

  * **Customizable Parameters**: The decision tree depth, criterion (Gini or entropy), and minimum sample split were configurable, enabling experiments with model complexity and overfitting control.

  This project was an excellent exercise in exploring supervised learning algorithms and understanding decision-making structures in machine learning. I gained practical experience in data preprocessing, model training, and result interpretation, while working with a real-world dataset.
* Day 424: 🐍 Mamba Mentality Motivator for Windows 💜💛  

  Today, I developed a **Mamba Mentality Motivator** in Python that delivers Kobe Bryant's inspirational quotes through Windows notifications at random intervals. The project focuses on combating impostor syndrome with unexpected bursts of motivation. Key highlights:  

  - **Randomized Notifications**: The motivator delivers quotes at unpredictable intervals (30 min to 4 hours by default), making each notification feel like a genuine surprise.  
  - **Mamba Mentality Collection**: Features 15+ handpicked quotes from Kobe Bryant about perseverance, self-belief, and overcoming challenges.  
  - **Smart Timing**: Avoids late-night interruptions (8AM–10PM only) to ensure notifications arrive during productive hours.  
  - **Windows Integration**: Uses `win10toast` for native Windows notifications that appear in the action center.  
  - **Adjustable Frequency**: Customizable minimum/maximum wait times between messages.  

  This project was a practical exercise in:  
  - **System notifications** with Python  
  - **Time-based randomization** for behavioral impact  
  - **Lightweight background processes**  

  The random delivery mimics Kobe's own relentless, unpredictable work ethic—keeping motivation fresh when it's needed most.  
* Day 425: Technical Test "detectCycle" and "reorderList" [LeetCode](https://leetcode.com/problems/)  

    - **detectCycle**: Implemented a solution for the "Linked List Cycle II" problem, where the task is to detect if there is a cycle in a linked list and return the node where the cycle begins. The approach uses Floyd's Tortoise and Hare algorithm with two pointers to detect the cycle and then find the starting node. The time complexity is O(N), where N is the number of nodes in the linked list.  
      [Problem Description: detectCycle](https://leetcode.com/problems/linked-list-cycle-ii/description/)  

    - **reorderList**: Solved the "Reorder List" problem, which involves reordering a singly linked list such that the nodes are interleaved in a specific way: the first node is followed by the last node, the second node by the second last node, and so on. The solution involves finding the middle of the list, reversing the second half, and then merging the two halves alternately. The time complexity is O(N), where N is the number of nodes in the linked list.  
      [Problem Description: reorderList](https://leetcode.com/problems/reorder-list/)
* Day 426: 🏀 Hot Hand Effect Simulation in Python 🔥

  Today, I worked on a Hot Hand Effect Simulation using Python, implementing recursive algorithms to analyze basketball shooting streaks. The project examines whether players experience statistically significant streaks of successful shots. Below are the key highlights:

  - **Recursive Streak Analysis**: The core of the project uses recursive functions to identify and analyze sequences of consecutive successful shots ('H' for hit) in simulated shooting data. The algorithm tracks shot streaks of specified minimum lengths.

  - **Probability Calculations**: The simulation calculates both the baseline shooting probability and the conditional probability of making a shot following a streak of hits, comparing them to detect potential Hot Hand effects.

  - **Parameter Control**: The generator offers adjustable parameters including sequence length (number of shots), success probability (baseline shooting percentage), and minimum streak length to analyze.

  - **Statistical Comparison**: The analysis compares observed streak probabilities against expected values, highlighting potential Hot Hand effects when observed probabilities exceed expectations.

  - **Clear Visualization**: Results are presented in an organized format showing total shots, expected vs observed success rates, streak counts, and conditional probabilities with clear indicators of potential Hot Hand effects.

  This project provided valuable experience in implementing recursive algorithms for pattern detection in sequences and analyzing statistical phenomena in sports. The recursive approach proved particularly effective for identifying and evaluating shooting streaks of varying lengths within the data. The simulation offers a practical framework for examining the psychological concept of the Hot Hand effect through statistical analysis.
* Day 427: 🏀 Automatic Basketball Game Summarizer with NER 🏆

  Today, I built an Automatic Basketball Game Summarizer using Named Entity Recognition (NER) in Python. The system processes lengthy game chronicles to extract key information about players, teams, and statistics. Here are the main features:

  - **Named Entity Recognition**: Implemented custom entity recognition rules using spaCy to identify basketball-specific entities like players, teams, and statistics within game texts.

  - **Key Information Extraction**: The system automatically detects:
    - MVP candidates (players scoring >20 points)
    - Top scorers (ranked by points)
    - Winning team (identified through contextual analysis)
    - Individual player statistics (points, rebounds, assists, etc.)

  - **Rule-based Patterns**: Created specialized patterns for recognizing basketball entities, including player names (typically capitalized first/last names), team names (city+mascot format), and statistics (numeric values followed by terms like "points" or "rebounds").

  - **Contextual Analysis**: The summarizer examines sentence context to properly associate statistics with players and determine game outcomes from victory/defeat mentions.

  - **Summary Generation**: Produces structured, human-readable reports that highlight the most important game information in a clear format.

  This project provided valuable experience in natural language processing techniques for sports analytics. I learned how to combine rule-based and statistical approaches for entity recognition in domain-specific contexts. The system demonstrates how NLP can transform unstructured game reports into actionable insights, with potential applications in sports journalism and analytics.
* Day 428: ♟️ Chess Legal Move Highlighter in Python

  Today, I worked on a Chess Legal Move Highlighter using Python, implementing a console-based chess board that displays legal moves for selected pieces. The project focuses on chess piece movement rules and board visualization. Below are the key highlights:

  - **Chess Board Representation**: The program uses a standard 8x8 chess board with pieces in their starting positions, represented by traditional notation (e.g., 'P' for white pawn, 'r' for black rook).

  - **Piece Movement Logic**: Implemented complete movement rules for all chess pieces including pawns (with forward moves and diagonal captures), knights (L-shaped moves), bishops (diagonal movement), rooks (straight movement), queens (combination of bishop and rook), and kings (one square in any direction).

  - **Interactive Display**: The board is displayed in console with proper labeling (files a-h and ranks 1-8). Legal moves are highlighted with asterisks (*) for empty squares or by showing the piece if it's a capture.

  - **Algebraic Notation Support**: The program accepts and outputs positions in standard algebraic notation (e.g., "e2") and can display legal moves in this notation for better chess readability.

  - **Input Validation**: Includes robust input validation to ensure users enter valid chess positions and handles edge cases like empty squares or pieces with no legal moves.

  This project was an excellent exercise in understanding chess rules and implementing game logic. I gained practical experience in board game programming, movement validation, and console-based visualization techniques. The piece-by-piece implementation approach helped solidify my understanding of how different chess pieces interact with the board.
* Day 429: 🔢 Euclidean Algorithm Visualizer in Python 📐

  Today, I worked on a Euclidean Algorithm Visualizer using Python, implementing a recursive approach to demonstrate how the algorithm finds the greatest common divisor (GCD) of two numbers. The project focuses on visualizing the mathematical steps through geometric representations. Below are the key highlights:

  - **Recursive GCD Calculation**: The core of the project uses the Euclidean algorithm's recursive implementation to break down the problem of finding GCD into smaller subproblems, recording each division step for visualization.

  - **Geometric Visualization**: The algorithm is visualized through a series of rectangles representing the division steps, with squares showing how the larger number contains multiples of the smaller number plus a remainder.

  - **Interactive Navigation**: The visualization includes interactive buttons to step through each stage of the algorithm, allowing users to see the progression from initial numbers to the final GCD solution.

  - **Color-Coded Steps**: Each division operation is represented with distinct colors, making it easy to follow the transformation of the problem at each recursive step.

  - **Mathematical Annotation**: The visualization clearly displays the mathematical operation (a = q × b + r) at each step, reinforcing the connection between the geometric representation and the underlying mathematics.

  This project was an excellent exercise in combining mathematical algorithms with visual representation. I gained practical experience in implementing recursive solutions while developing an intuitive way to demonstrate a fundamental number theory concept. The visualization approach proved particularly valuable for understanding the relationship between the algebraic operations and their geometric interpretation.
* Day 430: 🚌 Bus Ticket Simulator with MVC Architecture 🎫

  Today, I built a complete Bus Ticket Simulator using Python with a proper Model-View-Controller (MVC) architecture. This project demonstrates professional software design patterns and comprehensive system implementation. Below are the key highlights:

  - **MVC Architecture**: The project strictly follows the Model-View-Controller pattern, with clear separation between data handling (Model), user interface (View), and business logic (Controller).

  - **Core Classes**: Implemented three main classes - Bus (representing vehicles and routes), Passenger (storing traveler information), and Ticket (managing bookings and cancellations).

  - **Complete Functionality**: The system supports all essential ticket operations including viewing available buses, purchasing tickets with seat selection, viewing ticket details, and cancellations with confirmation.

  - **Data Validation**: Robust input validation ensures data integrity throughout the system, from passenger details to seat selection.

  - **User-Friendly Interface**: The console-based interface features intuitive menus, clear prompts, and well-formatted output displays for all operations.

  - **Professional Implementation**: The codebase includes comprehensive type hints, detailed docstrings, and thorough comments demonstrating production-quality Python development.

  This project provided excellent practice in implementing proper software architecture patterns and handling complex business logic in a clean, maintainable way. I gained valuable experience in designing class relationships, managing application state, and creating user-friendly console interfaces. The MVC approach proved particularly effective for organizing the different system components while maintaining clear separation of concerns.
* Day 431: 🧩 Scrabble Word Finder in Python 🔍

  Today, I built a Scrabble Word Finder using Python, implementing a recursive search algorithm with pruning to efficiently find all valid words from a given set of letters. The project focuses on dictionary processing and optimization techniques for word games. Here are the key highlights:

  - **Recursive Search with Pruning**: The core of the project uses a recursive approach with early termination to explore possible word combinations efficiently, avoiding unnecessary paths in the search tree.

  - **Trie Data Structure**: Implemented a trie (prefix tree) for the dictionary to enable fast prefix checking, allowing the algorithm to prune invalid branches early in the search process.

  - **Wildcard Support**: The system handles blank tiles/wildcards (represented by '?') that can substitute for any letter, expanding the search possibilities while maintaining validity checks.

  - **Multi-language Support**: Designed the architecture to support multiple languages (English/Spanish) with separate letter scoring systems and dictionaries for each language.

  - **Scoring System**: Integrated proper Scrabble scoring calculations based on language-specific letter values, displaying both the words and their point values.

  - **User Interface**: Developed an intuitive console menu system with options to input letters, set word length constraints, change languages, and save results.

  This project provided excellent practice in recursive algorithm design and optimization techniques. I gained valuable experience working with tree data structures for efficient searching, implementing language-specific game rules, and creating user-friendly interfaces for game applications. The pruning strategy proved particularly effective in reducing the search space for longer letter combinations.
* Day 432: 🎮 Steam Game Review Analyzer with NLP 📊

  Today, I developed a comprehensive Steam Game Review Analyzer using Python and NLP techniques. This tool extracts and analyzes player reviews from Steam to provide insights about game reception, common issues, and sentiment trends. Below are the key highlights:

  - **Steam API Integration**: The analyzer connects directly to Steam's API to fetch game details and player reviews, supporting both AppID searches and name-based lookups.

  - **NLP Entity Recognition**: Utilizes spaCy with custom entity patterns to identify game features, platforms, reported issues, and genres mentioned in reviews.

  - **Sentiment Analysis**: Incorporates TextBlob to measure sentiment polarity of each review, providing an overall sentiment score and distribution analysis.

  - **Comprehensive Reporting**: Generates detailed text reports including:
    - Overall sentiment metrics (average, variability)
    - Top mentioned features/issues with associated sentiment
    - Key review examples (most positive/negative/neutral)
    - Entity frequency analysis

  - **Visual Dashboard**: Creates a professional 6-panel visualization including:
    - Sentiment distribution histogram
    - Review length vs sentiment scatter plot
    - Rolling sentiment trend
    - Sentiment by review length category
    - Word cloud of frequent terms

  - **Custom Entity Patterns**: Enhanced spaCy's NER with game-specific patterns to better identify gaming terminology (features like "gameplay" or "graphics", issues like "bugs" or "crashes").

  This project provided valuable experience in API integration, NLP pipeline customization, and sentiment analysis applied to real-world game data. The analysis helps identify both strengths (positively received features) and pain points (common complaints) in game reviews, making it useful for both developers and players. The visualization dashboard effectively communicates complex sentiment data through multiple complementary perspectives.
* Day 433: � Neural Network Structure Visualizer in Python 🧠

  Today, I developed a Neural Network Structure Visualizer using Python, implementing a recursive algorithm to generate and display the layer and node architecture of neural networks. The project focuses on visualization techniques and recursive pattern generation for network structures. Below are the key highlights:

  - **Recursive Layer Generation**: The core of the project uses recursive methods to build network layers, handling both the vertical positioning of neurons and the connections between layers. Each recursive call processes one layer of the network, creating the appropriate number of neurons and connecting them to the previous layer.

  - **Parameter Control**: The visualizer offers adjustable parameters including number of network layers (controlling the depth of the network) and neurons per layer (controlling the width at each level). Users can configure these values through an intuitive GUI interface.

  - **Visualization**: The generated network structure is visualized using matplotlib, with circles representing neurons and lines showing connections between layers. The visualization includes proper spacing and scaling to maintain clarity regardless of network size.

  - **Recursive Implementation**: The project demonstrates clean recursive programming, with each iteration handling one network layer and its connections to the previous layer. The recursion naturally handles the hierarchical nature of neural network architectures.

  - **Customizable Output**: Users can easily modify the network architecture through interactive controls, creating everything from simple perceptrons to deep multi-layer networks. The visualizer automatically adjusts the layout to accommodate different configurations.

  This project was an excellent exercise in understanding both neural network architectures and recursive visualization techniques. I gained practical experience in implementing mathematical layouts for network structures while exploring GUI development for parameter control. The recursive approach proved particularly valuable for handling the self-similar nature of network layers and their connections.