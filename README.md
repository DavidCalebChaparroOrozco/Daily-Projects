# Daily-Projects
This repository contains my daily projects, challenging me to create something new every day. From small utilities to full-fledged applications, they reflect my growth as a developer. Each project has a brief description of technologies, challenges and lessons. It is a record of my progress and a constantly evolving portfolio.
* Day 01:  Polar Plots in Python with Matplotlib by Neural Nine
  * Today we learn how to work with polar coordinates and how to create polar plots in Python using Matplotlib.
* Day 02: Spotify Oldies Dataset 🎶: A Treasury of Classics [Kaggle](https://www.kaggle.com/datasets/kanchana1990/spotify-oldies-dataset/data)
  * Today I'm going to work with a dataset called Spotify Oldies Dataset: A Treasury of Classics.
* Day 03: Pomodoro Timer GUI
  * In this project, I developed a graphical user interface (GUI) for a Pomodoro Timer using Tkinter in Python. The Pomodoro Technique is a time management method that uses a timer to break down work into intervals, traditionally 25 minutes in length, separated by short breaks. This GUI application allows users to start, reset, and skip timers for Pomodoro sessions, short breaks, and long breaks, providing visual feedback on the remaining time for each interval. It serves as a practical tool for enhancing productivity and focus during work or study sessions.
* Day 04: To Do App
  * Today, I created a To Do application using Flask and SQLAlchemy. This app allows users to add, edit, and delete tasks, as well as mark them as completed or in progress. Users can also search and filter tasks by various criteria such as title, completion status, priority, and due date. Additionally, the app supports sorting tasks by ID, title, or completion status, and offers bulk actions to mark tasks as completed, in progress, or not completed. It's a simple yet practical tool for managing daily tasks efficiently.
* Day 05: ContactManager
  * This project involves creating a contact manager application using Python's Tkinter library. The ContactManager allows users to add, edit, view, and delete contacts. It provides features such as pagination, searching, importing/exporting contacts from/to CSV files, and input validation for contact details. It offers a user-friendly interface for managing contact information effectively.
* Day 06: Income Prediction Adult Income [Kaggle](https://www.kaggle.com/datasets/wenruliu/adult-income-dataset)
  * In today's project, I implemented a machine learning model to predict adult income using the Adult Income dataset. The dataset contains various demographic and employment-related features such as age, education level, occupation, and work hours per week, along with the target variable indicating whether an individual earns more than $50,000 annually. I utilized the Random Forest algorithm to train the model and extracted feature importance scores to identify the key factors influencing income prediction. The model achieved an accuracy of  0.86%, demonstrating its capability to classify individuals into different income groups. This project enhances my understanding of supervised learning techniques and their application in real-world scenarios.
* Day 07: Pokedex GUI Application
  * In this project, I developed a graphical user interface (GUI) application for a Pokedex using Python's Tkinter library. The Pokedex is a digital encyclopedia that catalogues information about different species of Pokémon, a popular franchise of fictional creatures.
* Day 08: Flet Chat Application
  * Created a chat application using Flet library in Python. This application allows users to join a chat room, send and receive messages in real-time. It features a graphical user interface (GUI) for displaying chat messages, input field for sending messages, and user authentication. The application utilizes Flet components for UI design and integrates functionalities for sending, receiving, and displaying messages efficiently. It serves as a practical tool for real-time communication and collaboration among users.
* Day 09: Video Game Sales [Kaggle](https://www.kaggle.com/datasets/gregorut/videogamesales/data)
  * Today's project delves into the world of video game sales analysis. Leveraging the Video Game Sales dataset from Kaggle, I explore trends and patterns in the gaming industry. This dataset contains information on video game sales across different platforms, regions, genres, and years, providing valuable insights into consumer preferences and market dynamics. Through data exploration, visualization, and potentially predictive modeling, I aim to uncover hidden gems and understand what makes a successful video game title. Stay tuned for the journey through pixels and polygons! 🎮✨
* Day 10: Summarize News Articles
  * Worked on a project to summarize news articles using web scraping and natural language processing libraries like newspaper3k and TextBlob.
* Day 11: Sudoku Solver
  * In this project, I've crafted a Sudoku solver leveraging the backtracking algorithm in Python. This application empowers users to input incomplete Sudoku puzzles, generating a valid solution for the board. To enhance user experience, I integrated the Tkinter graphical library to craft an interactive interface. Through this interface, users can input Sudoku numbers and witness the solution unfold step by step. This project not only offers an efficient solution for Sudoku puzzles but also serves as an educational tool to delve into backtracking algorithms and Python-based interactive user interfaces.
* Day 12: Snake Pygame
  * In today's project, I built a classic Snake game using Pygame, a popular Python library for creating 2D games. The Snake game is a timeless arcade classic where the player controls a snake that moves around the screen, eating food to grow longer while avoiding collisions with itself and the boundaries of the game area.
* Day 13: Titanic Dataset 🚢 [Kaggle](https://www.kaggle.com/c/titanic)
  * Today, we delve into the exciting world of data analysis with the famous Titanic dataset. This dataset, available on Kaggle, provides information about the passengers aboard the Titanic, including details such as age, gender, ticket class, fare paid, and more. Our task is to explore this dataset, understand its key features, and possibly develop predictive models to determine the likelihood of a passenger's survival based on various factors. Through this project, we will not only enhance our data analysis skills but also honor the memory of the Titanic passengers by extracting meaningful insights from this historic dataset.
* Day 14: Email Python
  * Today's project involves creating a Python script for sending automated emails. Leveraging libraries such as smtplib, schedule, and dotenv, we develop a script capable of sending daily inspirational emails to a specified email address. The script reads quotes from a file, selects a random quote, and sends it via SMTP protocol. Utilizing environment variables for storing email credentials ensures security and flexibility. By scheduling the script to run periodically using the schedule library, we automate the process of sending daily inspiration to recipients, fostering motivation and positivity. This project not only demonstrates practical use cases of Python for automation but also serves as a reminder of the power of uplifting messages in our daily lives.
* Day 15: Guess the Number
  * Today's project involves creating a number guessing game using Python's Tkinter library for building the graphical user interface (GUI). The game prompts the player to guess a randomly generated number between 1 and 99 within a limited number of attempts. Through input validation and dynamic feedback, the game guides the player to adjust their guesses until they either correctly identify the number or exhaust their attempts. This project not only showcases interactive GUI development with Tkinter but also reinforces concepts of random number generation, user input handling, and game logic implementation. It provides an entertaining and engaging experience for players while honing programming skills in Python. Can you beat the odds and guess the secret number? Let the guessing game begin! 🎲
* Day 16: Virtual Bookshelves
  * In this project, I'll create a virtual bookshelf management system using Python and SQLite. The application will allow users to add, remove, update, and view books in their virtual bookshelves. Each book will have attributes such as title, author, year published, and genre. The system will utilize SQLite for database management and provide a user-friendly interface for interacting with the bookshelves. This project aims to simulate real-world bookshelf management scenarios and provide users with a convenient way to organize their reading materials. Let's embark on the journey of building virtual bookshelves to enhance our reading experiences! 📚✨
* Day 17: RSS Feed Reader
  * In this project, I'll develop an RSS feed reader using Python and BeautifulSoup. The RSS feed reader will be capable of fetching and parsing RSS feeds from various sources. It will extract relevant information such as titles, descriptions, and links from the feeds, presenting them in a user-friendly format. By implementing this RSS feed reader, I aim to enhance my skills in web scraping, XML parsing, and data presentation. Stay tuned for an efficient tool to stay updated with the latest news and content from your favorite websites! 📰🚀
* Day 18: Customer Manager JSON
  * In this project, I've developed a customer management system using Python and JSON. The system allows users to store and manage information about customers, including names, email addresses, cities, etc. It implements functionalities such as searching for customers by name, updating contact information, deleting customers, and adding new customers. Leveraging JSON as the data storage format ensures portability and simplicity in data management. This project enhances my skills in file handling, data manipulation, and user interface design. It serves as a practical tool for organizing customer data efficiently and facilitating effective communication and interaction with clients. Let's embark on the journey of customer management and streamline the process of customer engagement! 📊👥
* Day 19: Expense Tracking App
  * Created an expense tracking application using Python's Tkinter library. This app allows users to record their expenses, including item name, price, and purchase date. Users can add, edit, delete, and view expense records, providing a convenient way to manage their finances. Additionally, the app calculates the total expense and remaining balance, offering insights into spending habits. It serves as a practical tool for budgeting and financial management. 📊💰
* Day 20: Hangman
  * Implemented the classic Hangman game using Python and Flask. Players can guess letters to reveal a hidden word within a limited number of attempts. The game features a user-friendly interface and supports error handling for invalid inputs. Test your vocabulary and strategic thinking in this timeless word-guessing challenge! 🎩🔤
* Day 21: Image Editor
  * In this project, I developed an image editor using Python and Tkinter. The Image Editor allows users to open image files, apply filters such as black and white, blur, sharpen, and more, flip and rotate images, draw lines over the images, change pen color, erase drawn lines, and save edited images. It provides a user-friendly interface for basic image editing tasks and serves as a practical tool for enhancing and modifying images. Let your creativity flow with the Image Editor! 🎨🖼️
* Day 22: Faker User
  * In this project, I utilized the Faker library in Python to generate synthetic user data. From names and email addresses to phone numbers and job titles, Faker User creates realistic user profiles effortlessly. Whether for testing, prototyping, or data augmentation, Faker User streamlines the process of generating diverse and customizable datasets.
* Day 23: Simple Stock Price (Steamlit)
  * Today's project revolves around creating a Simple Stock Price application using Streamlit. This application enables users to visualize stock price data, including closing prices, volume, and candlestick charts, for various companies. Leveraging the yfinance library, the app fetches historical stock data and presents it in an interactive and user-friendly manner. Users can select a company from a dropdown menu, view different metrics, and analyze performance metrics such as returns, volatility, and Sharpe ratio. With its intuitive interface and insightful visualizations, this project serves as a valuable tool for investors and enthusiasts alike to track and analyze stock market trends.
* Day 24: Quality Of Wine [Kaggle](https://www.kaggle.com/datasets/uciml/red-wine-quality-cortez-et-al-2009)
  * Exploring the quality of wine dataset from Kaggle, I aim to analyze factors influencing the quality of red wine. Leveraging data analysis and visualization techniques, I seek to uncover patterns and relationships among various chemical properties and wine quality ratings. By applying machine learning algorithms, I intend to develop predictive models to classify wine quality based on its attributes. This project provides insights into the intricate world of wine quality assessment and demonstrates the application of data science in the domain of viticulture. Cheers to discovering the essence of fine wine! 🍷📊
* Day 25: Extract Dominant Colors
  * In this project, I'll delve into the fascinating realm of image processing to extract the dominant colors from images. Utilizing Python libraries such as ColorThief and Matplotlib, I'll develop a script capable of identifying the primary colors present in an image. By analyzing color palettes and visualizing dominant hues, this endeavor aims to provide insights into the aesthetic composition of images. Join me as I explore the vibrant spectrum of colors and uncover the beauty hidden within digital imagery. 🎨🖼️
* Day 26: Tree Node
  * On day 26, I focused on the implementation of a fundamental data structure, the tree node. Through Python, I constructed a TreeNode class capable of representing nodes within a binary search tree. With the aid of methods like insertion and various traversal techniques (preorder, inorder, and postorder), I delved into the intricacies of managing and navigating through binary trees. This exploration lays the groundwork for comprehending more complex tree-based algorithms and data structures, providing a solid foundation for further study in computer science and programming. 🌳🔍
* Day 27: ML with FastAPI
  * Today we learn how to easily turn machine learning models into usable APIs using FastAPI in Python.
* Day 28: Tutorial Guide (Python Types Intro) [FastAPI](https://fastapi.tiangolo.com/python-types/)
  * On day 28, we delve into an essential aspect of Python programming - types. This tutorial guide provides an introduction to Python types, focusing particularly on their usage within the FastAPI framework. Understanding Python types is crucial for developing robust and maintainable code, and integrating this knowledge with FastAPI facilitates the creation of efficient and scalable web APIs. By exploring the intricacies of Python types within the context of FastAPI, we equip ourselves with powerful tools for building robust and type-safe applications. 🐍✨
* Day 29: Parking Space Counter
  * We implemented a parking space counter application using Python and OpenCV. This project enables users to define parking spaces on an image, count full and empty parking spots, and visualize the counts in real-time. The application leverages computer vision techniques to identify parking space boundaries and utilizes event handling to interactively mark full and empty spaces. This project serves as a practical example of applying Python and OpenCV for image processing and computer vision tasks, demonstrating their utility in real-world applications such as parking management systems. 🅿️🚗🅿️
* Day 30: [TensorFlow](https://www.tensorflow.org/tutorials/keras/classification) Guide (Beginner ~ ML Basics with Keras)
  * Explore the fundamentals of machine learning with TensorFlow and Keras in this beginner's guide. This guide provides a comprehensive overview of TensorFlow, a powerful open-source machine learning framework developed by Google. Through practical examples and step-by-step tutorials, you'll learn how to build and train neural networks using Keras, a high-level neural networks API that runs on top of TensorFlow. From basic concepts to hands-on implementation, this guide is designed to introduce you to the essentials of machine learning and empower you to start building your own ML models with TensorFlow and Keras. 🤖📚🔍
* Day 31: Spam Emails Dataset [Kaggle](https://www.kaggle.com/datasets/venky73/spam-mails-dataset/code)
  * We explored a Spam Emails Dataset available on Kaggle. This dataset contains a collection of emails labeled as spam or ham (not spam). Leveraging this dataset, we embarked on a data analysis and preprocessing journey using Python and pandas. Through this process, we gained insights into the structure of the data and performed necessary preprocessing steps to prepare it for machine learning tasks. By delving into real-world data and preparing it for analysis, we honed our data manipulation and preprocessing skills, essential for any data science or machine learning project. 📧🔍🛠️
* Day 32: Dijkstra's Algorithm Implementation
  * We implemented the Dijkstra algorithm, which is a design algorithm used to find the shortest path between nodes in a graph. The implementation is made in Python and uses a linear array to precisely search the graph and calculate the shortest distance from the starting point to all other points. Dijkstra's algorithm is widely used in a variety of applications, including network protocol routing  and  video game routing. By applying this algorithm, we increased 's design understanding  and strengthened our algorithmic problem-solving skills. 📈🔍💡
* Day 33: Technical Test "Add Two Numbers" and "FizzBuzz" [LeetCode](https://leetcode.com/problems/)
  * Add Two Numbers: We tackled the "Add Two Numbers" problem from LeetCode, which involves adding two non-empty linked lists representing non-negative integers. The digits are stored in reverse order, and each node contains a single digit. We implemented a Python solution that traverses both linked lists simultaneously, summing the corresponding digits and handling any carry. This problem enhances our understanding of linked list manipulation and problem-solving skills.
  [Problem Description](https://leetcode.com/problems/add-two-numbers/description/?source=submission-ac)
  * FizzBuzz: The second problem we solved was "FizzBuzz," also from LeetCode. This classic programming problem requires generating the FizzBuzz sequence up to a given number. We crafted a Python solution that iterates through the numbers from 1 to the given number, appending "Fizz" for multiples of 3, "Buzz" for multiples of 5, "FizzBuzz" for multiples of both 3 and 5, and the number itself if none of the conditions are met. This exercise reinforces our ability to write concise and efficient code to solve common programming challenges.
  [Problem Description](https://leetcode.com/problems/fizz-buzz/description/)
* Day 34: Quicksort
  * We implemented Quicksort, a divide-and-conquer algorithm used for sorting arrays or lists. Quicksort selects a pivot element, partitions the other elements into two sub-arrays based on whether they are less than or greater than the pivot, and recursively sorts the sub-arrays. Known for its efficiency, Quicksort is often used as a benchmark for comparison with other sorting algorithms, enhancing our understanding of algorithmic efficiency and problem-solving skills. 🔄📊🔍
* Day 35: Live Weather Forecast Flask App
  * In today's project, we'll develop a live weather forecast Flask app. This app will take a city name as input and provide various weather characteristics such as temperature in Celsius and Fahrenheit, humidity, wind speed, and more.
* Day 36: Random Passwords Generator
  * Today, we created a Random Passwords Generator program. This program prompts the user to specify the desired length of the password and generates a strong password consisting of a mix of lowercase and uppercase letters, digits, and special characters. Additionally, we implemented a function to save the generated passwords to a CSV file for later use. This project enhances our understanding of string manipulation, random number generation, and file handling in Python, while also providing practical utility by creating a tool for generating secure passwords. 🔒💡💻
* Day 37: Site Connectivity Checker
  * Today, we developed a Site Connectivity Checker application using Flask. This application allows users to input a URL and checks its connectivity by sending a request to the specified website. We enhanced the functionality by adding URL validation, error handling for various connection issues, and logging of activity to track the status of site connections over time. By building this project, we gained practical experience in web development with Flask, handling HTTP requests, error management, and logging, all of which are essential skills for creating robust web applications. 🌐🔍🚀
* Day 38: Heart Attack Analysis & Prediction Dataset [Kaggle](https://www.kaggle.com/datasets/rashikrahmanpritom/heart-attack-analysis-prediction-dataset/data)
  * We explored the Heart Attack Analysis & Prediction Dataset available on Kaggle. This dataset provides valuable insights into factors contributing to heart attacks and includes various health parameters such as age, sex, cholesterol levels, blood pressure, and more. By analyzing this dataset, we aim to gain a deeper understanding of the relationships between different risk factors and the likelihood of a heart attack occurrence. Leveraging statistical analysis and machine learning techniques, we strive to develop predictive models that can assist in early detection and prevention efforts for cardiovascular diseases. This project underscores the importance of data-driven approaches in healthcare and reinforces our skills in data analysis, predictive modeling, and domain knowledge application. ❤️📊🔬
* Day 39: [TensorFlow](https://www.tensorflow.org/tutorials/keras/classification) Guide Basic text Classification (Beginner ~ ML Basics with Keras)
  * Continuing from Day 30, delve deeper into machine learning with TensorFlow and Keras by exploring basic text classification. In this guide, you'll learn how to apply machine learning concepts to classify text data using TensorFlow and Keras. By following step-by-step tutorials and practical examples, you'll understand the fundamentals of text classification, including preprocessing text data, building neural network models, and evaluating model performance. Whether you're new to machine learning or looking to expand your knowledge, this guide provides valuable insights and hands-on experience to enhance your skills in natural language processing and text classification tasks. 🤖📚🔍
* Day 40: Technical Test "Minimum Height Trees" and "Zigzag Conversion" [LeetCode](https://leetcode.com/problems/)
  * Minimum Height Trees: Today, we encountered the "Minimum Height Trees" problem on LeetCode. This problem revolves around identifying the roots of minimum height trees in an undirected graph, given the number of nodes and an array of edges representing connections between nodes. We crafted a Python solution employing graph traversal and manipulation techniques to determine the roots with minimum height efficiently. This challenge enhances our ability to work with graphs, analyze graph structures, and devise optimal algorithms for graph-related problems. [Problem Description](https://leetcode.com/problems/minimum-height-trees/description/)
  * Zigzag Conversion: In addition, we tackled the "Zigzag Conversion" problem on LeetCode. This problem involves converting a given string into a zigzag pattern with a specified number of rows and then reading the string line by line. We devised a Python solution that constructs the zigzag pattern by iteratively placing characters in the appropriate rows, simulating the pattern formation and reading process. Solving this problem reinforces our understanding of string manipulation techniques and enhances our problem-solving skills in handling complex pattern-based challenges. [Problem Description](https://leetcode.com/problems/zigzag-conversion/description/)
* Day 41: Tkinter - Map View
  * Explore Tkinter's capabilities in displaying interactive maps with the Tkinter MapView project. This Tkinter-based application allows users to visualize maps, search for addresses, and adjust zoom levels seamlessly within a GUI interface. By integrating functionalities such as address lookup, zoom control, and map display, this project showcases the potential of Tkinter for creating dynamic and user-friendly applications. Dive into the world of Tkinter and enhance your skills in GUI development with the MapView project. 🗺️🖥️🔍